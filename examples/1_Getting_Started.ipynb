{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Example 1: Simple `MeanRisk` optimisation\n",
    "\n",
    "Here we show a simple example of how to use `PortfolioOptimisers`. We will perform the classic Markowitz optimisation."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using PortfolioOptimisers"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "PrettyTables is used to format the example output."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using PrettyTables\n",
    "\n",
    "# Format for pretty tables.\n",
    "tsfmt = (v, i, j) -> begin\n",
    "    if j == 1\n",
    "        return Date(v)\n",
    "    else\n",
    "        return v\n",
    "    end\n",
    "end;\n",
    "resfmt = (v, i, j) -> begin\n",
    "    if j == 1\n",
    "        return v\n",
    "    else\n",
    "        return isa(v, Number) ? \"$(round(v*100, digits=3)) %\" : v\n",
    "    end\n",
    "end;\n",
    "mipresfmt = (v, i, j) -> begin\n",
    "    if j ∈ (1, 2, 3)\n",
    "        return v\n",
    "    else\n",
    "        return isa(v, Number) ? \"$(round(v*100, digits=3)) %\" : v\n",
    "    end\n",
    "end;"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load the data\n",
    "\n",
    "Import the S&P500 data from a compressed `.csv` file. We will only use the last 253 observations."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐\n",
      "│  timestamp │    AAPL │     AMD │     BAC │     BBY │     CVX │      GE │      HD │     JNJ │     JPM │      KO │     LLY │     MRK │    MSFT │     PEP │     PFE │      PG │     RRC │     UNH │     WMT │     XOM │\n",
      "│       Date │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │\n",
      "├────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│ 2022-12-20 │ 131.916 │   65.05 │  31.729 │  77.371 │ 169.497 │  62.604 │ 310.342 │ 173.109 │ 127.844 │  61.841 │  357.55 │ 108.229 │  240.67 │ 178.765 │  49.754 │ 147.661 │   25.65 │ 516.245 │ 142.919 │ 104.964 │\n",
      "│ 2022-12-21 │ 135.057 │   67.68 │  32.212 │  78.729 │  171.49 │   64.67 │ 314.798 │  175.09 │ 129.282 │  62.836 │ 365.872 │ 109.611 │ 243.287 │ 180.017 │  50.084 │ 149.015 │  26.574 │ 523.519 │  144.04 │ 106.312 │\n",
      "│ 2022-12-22 │ 131.846 │   63.86 │  31.927 │  78.563 │ 168.918 │  63.727 │ 311.604 │  174.45 │ 127.814 │  62.383 │ 363.187 │ 109.739 │ 237.077 │ 178.627 │  50.065 │ 149.359 │  25.232 │ 523.072 │ 142.354 │ 104.168 │\n",
      "│ 2022-12-23 │ 131.477 │   64.52 │  32.005 │  79.432 │  174.14 │  63.742 │ 314.177 │ 174.893 │ 128.421 │  62.855 │ 365.762 │  110.35 │ 237.614 │ 179.781 │  50.249 │ 149.781 │  26.226 │  527.26 │ 142.641 │ 106.922 │\n",
      "│ 2022-12-27 │ 129.652 │   63.27 │  32.065 │   79.93 │ 176.329 │  64.561 │ 314.985 │ 174.844 │ 128.871 │   63.24 │  362.76 │ 110.607 │ 235.852 │  180.58 │   49.57 │ 151.086 │  26.375 │ 527.935 │ 142.681 │ 108.408 │\n",
      "│ 2022-12-28 │ 125.674 │   62.57 │  32.301 │  78.279 │ 173.728 │  63.883 │  311.22 │ 174.085 │ 129.575 │  62.609 │ 363.098 │ 109.581 │ 233.434 │ 179.278 │   49.25 │ 149.133 │  24.497 │ 524.422 │ 140.181 │ 106.627 │\n",
      "└────────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using CSV, TimeSeries, DataFrames\n",
    "\n",
    "X = TimeArray(CSV.File(joinpath(@__DIR__, \"SP500.csv.gz\")); timestamp = :Date)[(end - 252):end]\n",
    "pretty_table(X[(end - 5):end]; formatters = tsfmt)"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we must compute the returns from the prices. The `ReturnsResult` struct stores the asset names in `nx`, asset returns in `X`, and timestamps in `ts`. The other fields are used in other applications which we will not be showcasing here."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ReturnsResult\n    nx | 20-element Vector{String}\n     X | 252×20 Matrix{Float64}\n    nf | nothing\n     F | nothing\n    ts | 252-element Vector{Date}\n    iv | nothing\n  ivpa | nothing\n"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "rd = prices_to_returns(X)"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. MeanRisk optimisation\n",
    "\n",
    "### 2.1 Creating a solver instance\n",
    "\n",
    "All optimisations require some prior statistics to be computed. This can either be done before the optimisation function, or within it. For certain optimisations, precomputing the prior is more efficient, but it makes no difference here so we'll do it within the optimisation.\n",
    "\n",
    "The `MeanRisk` estimator defines a mean-risk optimisation problem. It is a `JuMPOptimisationEstimator`, which means it requires a `JuMP`-compatible optimiser, which in this case will be `Clarabel`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Clarabel"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have to define a `Solver` object, which contains the optimiser we wish to use, an optional name for logging purposes, optional solver settings, and optional kwargs for [`JuMP.assert_is_solved_and_feasible`](https://jump.dev/JuMP.jl/stable/api/JuMP/#assert_is_solved_and_feasible).\n",
    "\n",
    "Given the vast range of optimisation options and types, it is often useful to try different solver and settings combinations. To this aim, it is also possible to provide a vector of `Solver` objects, which is iterated over until one succeeds or all fail. The classic Markowitz optimisation is rather simple, so we will use a single solver instance."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Solver\n         name | Symbol: :clarabel1\n       solver | UnionAll: Clarabel.MOIwrapper.Optimizer\n     settings | Dict{String, Bool}: Dict{String, Bool}(\"verbose\" => 0)\n    check_sol | @NamedTuple{allow_local::Bool, allow_almost::Bool}: (allow_local = true, allow_almost = true)\n  add_bridges | Bool: true\n"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "slv = Solver(; name = :clarabel1, solver = Clarabel.Optimizer,\n",
    "             settings = Dict(\"verbose\" => false),\n",
    "             check_sol = (; allow_local = true, allow_almost = true))"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Defining the optimisation estimator\n",
    "\n",
    "`PortfolioOptimisers` is designed to heavily leverage composition. The first hint of this design ethos in the examples comes in the form of `JuMPOptimiser`, which is the structure defining the optimiser parameters used in all `JuMPOptimisationEstimator`s.\n",
    "\n",
    "Let's create a `MeanRisk` estimator. As you can see from the output, `JuMPOptimiser` and `MeanRisk` contain myriad properties that we will not showcase in this example."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MeanRisk\n       opt | JuMPOptimiser\n           |       pe | EmpiricalPrior\n           |          |        ce | PortfolioOptimisersCovariance\n           |          |           |   ce | Covariance\n           |          |           |      |    me | SimpleExpectedReturns\n           |          |           |      |       |   w | nothing\n           |          |           |      |    ce | GeneralCovariance\n           |          |           |      |       |   ce | SimpleCovariance: SimpleCovariance(true)\n           |          |           |      |       |    w | nothing\n           |          |           |      |   alg | Full()\n           |          |           |   mp | DefaultMatrixProcessing\n           |          |           |      |       pdm | Posdef\n           |          |           |      |           |   alg | UnionAll: NearestCorrelationMatrix.Newton\n           |          |           |      |   denoise | nothing\n           |          |           |      |    detone | nothing\n           |          |           |      |       alg | nothing\n           |          |        me | SimpleExpectedReturns\n           |          |           |   w | nothing\n           |          |   horizon | nothing\n           |      slv | Solver\n           |          |          name | Symbol: :clarabel1\n           |          |        solver | UnionAll: Clarabel.MOIwrapper.Optimizer\n           |          |      settings | Dict{String, Bool}: Dict{String, Bool}(\"verbose\" => 0)\n           |          |     check_sol | @NamedTuple{allow_local::Bool, allow_almost::Bool}: (allow_local = true, allow_almost = true)\n           |          |   add_bridges | Bool: true\n           |       wb | WeightBounds\n           |          |   lb | Float64: 0.0\n           |          |   ub | Float64: 1.0\n           |      bgt | Float64: 1.0\n           |     sbgt | nothing\n           |       lt | nothing\n           |       st | nothing\n           |      lcs | nothing\n           |     cent | nothing\n           |    gcard | nothing\n           |   sgcard | nothing\n           |     smtx | nothing\n           |    sgmtx | nothing\n           |      slt | nothing\n           |      sst | nothing\n           |     sglt | nothing\n           |     sgst | nothing\n           |     sets | nothing\n           |      plg | nothing\n           |       tn | nothing\n           |       te | nothing\n           |     fees | nothing\n           |      ret | ArithmeticReturn\n           |          |   ucs | nothing\n           |          |    lb | nothing\n           |      sce | SumScalariser: SumScalariser()\n           |     ccnt | nothing\n           |     cobj | nothing\n           |       sc | Int64: 1\n           |       so | Int64: 1\n           |     card | nothing\n           |    scard | nothing\n           |      nea | nothing\n           |       l1 | nothing\n           |       l2 | nothing\n           |       ss | nothing\n           |   strict | Bool: false\n         r | Variance\n           |   settings | RiskMeasureSettings\n           |            |   scale | Float64: 1.0\n           |            |      ub | nothing\n           |            |     rke | Bool: true\n           |      sigma | nothing\n           |         rc | nothing\n           |        alg | SOCRiskExpr()\n       obj | MinimumRisk()\n        wi | nothing\n  fallback | nothing\n"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "mr = MeanRisk(; opt = JuMPOptimiser(; slv = slv))"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Performing the optimisation\n",
    "\n",
    "The `optimise` function is used to perform all optimisations in `PortfolioOptimisers`. Each method returns an `AbstractResult` object containing the optimisation results, which include a return code, a solution object, and relevant statistics (precomputed or otherwise) used in the optimisation.\n",
    "\n",
    "The field `retcode` informs us that our optimisation was successful because it contains an `OptimisationSuccess` return code."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "JuMPOptimisation\n        oe | DataType: DataType\n        pa | ProcessedJuMPOptimiserAttributes\n           |       pr | LowOrderPrior\n           |          |         X | 252×20 Matrix{Float64}\n           |          |        mu | 20-element Vector{Float64}\n           |          |     sigma | 20×20 Matrix{Float64}\n           |          |      chol | nothing\n           |          |         w | nothing\n           |          |       ens | nothing\n           |          |       kld | nothing\n           |          |        ow | nothing\n           |          |        rr | nothing\n           |          |      f_mu | nothing\n           |          |   f_sigma | nothing\n           |          |       f_w | nothing\n           |       wb | WeightBounds\n           |          |   lb | 20-element StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}\n           |          |   ub | 20-element StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}\n           |       lt | nothing\n           |       st | nothing\n           |      lcs | nothing\n           |     cent | nothing\n           |    gcard | nothing\n           |   sgcard | nothing\n           |     smtx | nothing\n           |    sgmtx | nothing\n           |      slt | nothing\n           |      sst | nothing\n           |     sglt | nothing\n           |     sgst | nothing\n           |      plg | nothing\n           |       tn | nothing\n           |     fees | nothing\n           |      ret | ArithmeticReturn\n           |          |   ucs | nothing\n           |          |    lb | nothing\n   retcode | OptimisationSuccess\n           |   res | Dict{Any, Any}: Dict{Any, Any}()\n       sol | JuMPOptimisationSolution\n           |   w | 20-element Vector{Float64}\n     model | A JuMP Model\n           | ├ solver: Clarabel\n           | ├ objective_sense: MIN_SENSE\n           | │ └ objective_function_type: QuadExpr\n           | ├ num_variables: 21\n           | ├ num_constraints: 4\n           | │ ├ AffExpr in MOI.EqualTo{Float64}: 1\n           | │ ├ Vector{AffExpr} in MOI.Nonnegatives: 1\n           | │ ├ Vector{AffExpr} in MOI.Nonpositives: 1\n           | │ └ Vector{AffExpr} in MOI.SecondOrderCone: 1\n           | └ Names registered in the model\n           |   └ :G, :bgt, :dev_1, :dev_1_soc, :k, :lw, :obj_expr, :ret, :risk, :risk_vec, :sc, :so, :variance_flag, :variance_risk_1, :w, :w_lb, :w_ub\n  attempts | nothing\n"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "res = optimise(mr, rd)"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's view the solution results as a pretty table. For convenience, we have ensured all `AbstractResult` have a property called `w`, which directly accesses `sol.w`. The optimisations don't shuffle the asset order, so we can simply view the asset names and weights side by side."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────┬──────────┐\n",
      "│ assets │  weights │\n",
      "│ String │  Float64 │\n",
      "├────────┼──────────┤\n",
      "│   AAPL │    0.0 % │\n",
      "│    AMD │    0.0 % │\n",
      "│    BAC │    0.0 % │\n",
      "│    BBY │    0.0 % │\n",
      "│    CVX │  7.432 % │\n",
      "│     GE │  0.806 % │\n",
      "│     HD │    0.0 % │\n",
      "│    JNJ │ 36.974 % │\n",
      "│    JPM │  0.749 % │\n",
      "│     KO │ 11.161 % │\n",
      "│    LLY │    0.0 % │\n",
      "│    MRK │ 17.467 % │\n",
      "│   MSFT │    0.0 % │\n",
      "│    PEP │  8.978 % │\n",
      "│    PFE │    0.0 % │\n",
      "│     PG │  2.353 % │\n",
      "│    RRC │    0.0 % │\n",
      "│    UNH │    0.0 % │\n",
      "│    WMT │  9.355 % │\n",
      "│    XOM │  4.725 % │\n",
      "└────────┴──────────┘\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "pretty_table(DataFrame(:assets => rd.nx, :weights => res.w); formatters = resfmt)"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Finite allocation\n",
    "\n",
    "We have the optimal solution, but most people don't have access to effectively unlimited funds. Given the optimised weights, current prices and a finite cash amount, it is possible to perform a finite allocation. We will use a discrete allocation method which uses mixed-integer programming to find the best allocation. We have another finite allocation method which uses a greedy algorithm that can deal with fractional shares, but we will reserve it for a later example.\n",
    "\n",
    "For the discrete allocation, we need a solver capable of handling mixed-integer programming problems, we will use `HiGHS`."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DiscreteAllocation\n       slv | Solver\n           |          name | Symbol: :highs1\n           |        solver | DataType: DataType\n           |      settings | Dict{String, Bool}: Dict{String, Bool}(\"log_to_console\" => 0)\n           |     check_sol | @NamedTuple{allow_local::Bool, allow_almost::Bool}: (allow_local = true, allow_almost = true)\n           |   add_bridges | Bool: true\n        sc | Int64: 1\n        so | Int64: 1\n  fallback | GreedyAllocation\n           |       unit | Int64: 1\n           |       args | Tuple{}: ()\n           |     kwargs | @NamedTuple{}: NamedTuple()\n           |   fallback | nothing\n"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "using HiGHS\n",
    "\n",
    "mip_slv = Solver(; name = :highs1, solver = HiGHS.Optimizer,\n",
    "                 settings = Dict(\"log_to_console\" => false),\n",
    "                 check_sol = (; allow_local = true, allow_almost = true))\n",
    "da = DiscreteAllocation(; slv = mip_slv)"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "Luckily, we have the optimal weights, the latest prices are the last entry of our original time array `X`, and let's say we have `4206.9` USD to invest.\n",
    "\n",
    "The function can optionally take extra positional arguments to account for a variety of fees, but we will not use them here."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DiscreteAllocationOptimisation\n         oe | DataType: DataType\n     shares | 20-element SubArray{Float64, 1, Matrix{Float64}, Tuple{Base.Slice{Base.OneTo{Int64}}, Int64}, true}\n       cost | 20-element SubArray{Float64, 1, Matrix{Float64}, Tuple{Base.Slice{Base.OneTo{Int64}}, Int64}, true}\n          w | 20-element SubArray{Float64, 1, Matrix{Float64}, Tuple{Base.Slice{Base.OneTo{Int64}}, Int64}, true}\n    retcode | OptimisationSuccess\n            |   res | nothing\n  s_retcode | nothing\n  l_retcode | OptimisationSuccess\n            |   res | Dict{Any, Any}: Dict{Any, Any}()\n    s_model | nothing\n    l_model | A JuMP Model\n            | ├ solver: HiGHS\n            | ├ objective_sense: MIN_SENSE\n            | │ └ objective_function_type: AffExpr\n            | ├ num_variables: 21\n            | ├ num_constraints: 42\n            | │ ├ AffExpr in MOI.GreaterThan{Float64}: 1\n            | │ ├ Vector{AffExpr} in MOI.NormOneCone: 1\n            | │ ├ VariableRef in MOI.GreaterThan{Float64}: 20\n            | │ └ VariableRef in MOI.Integer: 20\n            | └ Names registered in the model\n            |   └ :eta, :r, :u, :x\n       cash | Float64: 8.47199999999711\n   attempts | nothing\n"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "cell_type": "code",
   "source": [
    "mip_res = optimise(da, res.w, vec(values(X[end])), 4206.9)"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "The result of this optimisation contains different pieces of information to the previous one. The reason various fields are prefixed by `l_`or `s_` is because the discrete allocation method splits the assets into long and short positions, which are recombined in the final result.\n",
    "\n",
    "Let's see the results in another pretty table."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────┬─────────┬─────────┬─────────────┬─────────────┐\n",
      "│ assets │  shares │    cost │ opt_weights │ mip_weights │\n",
      "│ String │ Float64 │ Float64 │     Float64 │     Float64 │\n",
      "├────────┼─────────┼─────────┼─────────────┼─────────────┤\n",
      "│   AAPL │     0.0 │     0.0 │       0.0 % │       0.0 % │\n",
      "│    AMD │     0.0 │     0.0 │       0.0 % │       0.0 % │\n",
      "│    BAC │     0.0 │     0.0 │       0.0 % │       0.0 % │\n",
      "│    BBY │     0.0 │     0.0 │       0.0 % │       0.0 % │\n",
      "│    CVX │     2.0 │ 347.456 │     7.432 % │     8.276 % │\n",
      "│     GE │     0.0 │     0.0 │     0.806 % │       0.0 % │\n",
      "│     HD │     0.0 │     0.0 │       0.0 % │       0.0 % │\n",
      "│    JNJ │     9.0 │ 1566.77 │    36.974 % │    37.318 % │\n",
      "│    JPM │     0.0 │     0.0 │     0.749 % │       0.0 % │\n",
      "│     KO │     6.0 │ 375.654 │    11.161 % │     8.947 % │\n",
      "│    LLY │     0.0 │     0.0 │       0.0 % │       0.0 % │\n",
      "│    MRK │     7.0 │ 767.067 │    17.467 % │     18.27 % │\n",
      "│   MSFT │     0.0 │     0.0 │       0.0 % │       0.0 % │\n",
      "│    PEP │     2.0 │ 358.556 │     8.978 % │      8.54 % │\n",
      "│    PFE │     0.0 │     0.0 │       0.0 % │       0.0 % │\n",
      "│     PG │     1.0 │ 149.133 │     2.353 % │     3.552 % │\n",
      "│    RRC │     0.0 │     0.0 │       0.0 % │       0.0 % │\n",
      "│    UNH │     0.0 │     0.0 │       0.0 % │       0.0 % │\n",
      "│    WMT │     3.0 │ 420.543 │     9.355 % │    10.017 % │\n",
      "│    XOM │     2.0 │ 213.254 │     4.725 % │     5.079 % │\n",
      "└────────┴─────────┴─────────┴─────────────┴─────────────┘\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "pretty_table(DataFrame(:assets => rd.nx, :shares => mip_res.shares, :cost => mip_res.cost,\n",
    "                       :opt_weights => res.w, :mip_weights => mip_res.w);\n",
    "             formatters = mipresfmt)"
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the mip weights do not exactly match the optimal ones, but that is because we only have finite resources. Note that the sum of the costs minus the initial cash is equal to the `cash` property of the result. This changes when we introduce fees, which will be shown in a future example."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used cash ≈ available cash: true\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "println(\"used cash ≈ available cash: $(isapprox(mip_res.cash, 4206.9 - sum(mip_res.cost)))\")"
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also see that the cost of each asset is equal to the number of shares times its price."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost of shares ≈ cost of portfolio: true\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "println(\"cost of shares ≈ cost of portfolio: $(all(isapprox.(mip_res.shares .* vec(values(X[end])), mip_res.cost)))\")"
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.0"
  },
  "kernelspec": {
   "name": "julia-1.12",
   "display_name": "Julia 1.12.0",
   "language": "julia"
  }
 },
 "nbformat": 4
}
