{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Example 6: Multiple risk measures\n",
        "\n",
        "This example shows how to use multiple risk measures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "using PortfolioOptimisers, PrettyTables\n",
        "# Format for pretty tables.\n",
        "tsfmt = (v, i, j) -> begin\n",
        "    if j == 1\n",
        "        return Date(v)\n",
        "    else\n",
        "        return v\n",
        "    end\n",
        "end;\n",
        "resfmt = (v, i, j) -> begin\n",
        "    if j == 1\n",
        "        return v\n",
        "    else\n",
        "        return isa(v, Number) ? \"$(round(v*100, digits=3)) %\" : v\n",
        "    end\n",
        "end;\n",
        "mipresfmt = (v, i, j) -> begin\n",
        "    if j \u2208 (1, 2, 3)\n",
        "        return v\n",
        "    else\n",
        "        return isa(v, Number) ? \"$(round(v*100, digits=3)) %\" : v\n",
        "    end\n",
        "end;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ReturnsResult data\n",
        "\n",
        "We will use the same data as the previous example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\n",
            "\u2502  timestamp \u2502    AAPL \u2502     AMD \u2502     BAC \u2502     BBY \u2502     CVX \u2502      GE \u2502     \u22ef\n",
            "\u2502 Dates.Date \u2502 Float64 \u2502 Float64 \u2502 Float64 \u2502 Float64 \u2502 Float64 \u2502 Float64 \u2502 Flo \u22ef\n",
            "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\n",
            "\u2502 2022-12-20 \u2502 131.916 \u2502   65.05 \u2502  31.729 \u2502  77.371 \u2502 169.497 \u2502  62.604 \u2502 310 \u22ef\n",
            "\u2502 2022-12-21 \u2502 135.057 \u2502   67.68 \u2502  32.212 \u2502  78.729 \u2502  171.49 \u2502   64.67 \u2502 314 \u22ef\n",
            "\u2502 2022-12-22 \u2502 131.846 \u2502   63.86 \u2502  31.927 \u2502  78.563 \u2502 168.918 \u2502  63.727 \u2502 311 \u22ef\n",
            "\u2502 2022-12-23 \u2502 131.477 \u2502   64.52 \u2502  32.005 \u2502  79.432 \u2502  174.14 \u2502  63.742 \u2502 314 \u22ef\n",
            "\u2502 2022-12-27 \u2502 129.652 \u2502   63.27 \u2502  32.065 \u2502   79.93 \u2502 176.329 \u2502  64.561 \u2502 314 \u22ef\n",
            "\u2502 2022-12-28 \u2502 125.674 \u2502   62.57 \u2502  32.301 \u2502  78.279 \u2502 173.728 \u2502  63.883 \u2502  31 \u22ef\n",
            "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\n",
            "                                                              14 columns omitted\n"
          ]
        },
        {
          "data": {
            "text/plain": "ReturnsResult\n    nx \u253c 20-element Vector{String}\n     X \u253c 252\u00d720 Matrix{Float64}\n    nf \u253c nothing\n     F \u253c nothing\n    ts \u253c 252-element Vector{Dates.Date}\n    iv \u253c nothing\n  ivpa \u2534 nothing\n"
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "using CSV, TimeSeries, DataFrames\n",
        "\n",
        "X = TimeArray(CSV.File(joinpath(@__DIR__, \"SP500.csv.gz\")); timestamp = :Date)[(end - 252):end]\n",
        "pretty_table(X[(end - 5):end]; formatters = [tsfmt])\n",
        "\n",
        "# Compute the returns\n",
        "rd = prices_to_returns(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Preparatory steps\n",
        "\n",
        "We'll provide a vector of continuous solvers as a failsafe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "using Clarabel\n",
        "slv = [Solver(; name = :clarabel1, solver = Clarabel.Optimizer,\n",
        "              settings = Dict(\"verbose\" => false),\n",
        "              check_sol = (; allow_local = true, allow_almost = true)),\n",
        "       Solver(; name = :clarabel3, solver = Clarabel.Optimizer,\n",
        "              settings = Dict(\"verbose\" => false, \"max_step_fraction\" => 0.9),\n",
        "              check_sol = (; allow_local = true, allow_almost = true)),\n",
        "       Solver(; name = :clarabel5, solver = Clarabel.Optimizer,\n",
        "              settings = Dict(\"verbose\" => false, \"max_step_fraction\" => 0.8),\n",
        "              check_sol = (; allow_local = true, allow_almost = true)),\n",
        "       Solver(; name = :clarabel7, solver = Clarabel.Optimizer,\n",
        "              settings = Dict(\"verbose\" => false, \"max_step_fraction\" => 0.70),\n",
        "              check_sol = (; allow_local = true, allow_almost = true))];"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Multiple risk measures\n",
        "\n",
        "### 3.1 Equally weighted sum\n",
        "\n",
        "Some risk measures can use precomputed prior statistics which take precedence over the ones in `PriorResult`. We can make use of this to minimise the variance with different covariance matrices simultaneously.\n",
        "\n",
        "We will also precompute the prior statistics to minimise redundant work. First lets create a vector of Variances onto which we will push the different variances. We'll use 5 variance estimators, and their equally weighted sum.\n",
        "\n",
        "  1. Denoised covariance using the spectral algorithm.\n",
        "  2. Gerber 1 covariance.\n",
        "  3. Smyth Broby 1 covariance.\n",
        "  4. Mutual Information covariance.\n",
        "  5. Distance covariance.\n",
        "  6. Equally weighted sum of all the above covariances.\n",
        "\n",
        "For the multi risk measure optimisation, we will weigh each risk measure equally. It should give the same result as adding all covariances together, but not the same as averaging the weights of the individual optimisations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "5-element Vector{PortfolioOptimisersCovariance}:\n PortfolioOptimisersCovariance\n  ce \u253c Covariance\n     \u2502    me \u253c SimpleExpectedReturns\n     \u2502       \u2502   w \u2534 nothing\n     \u2502    ce \u253c GeneralCovariance\n     \u2502       \u2502   ce \u253c SimpleCovariance: SimpleCovariance(true)\n     \u2502       \u2502    w \u2534 nothing\n     \u2502   alg \u2534 Full()\n  mp \u253c DenoiseDetoneAlgMatrixProcessing\n     \u2502     pdm \u253c Posdef\n     \u2502         \u2502      alg \u253c UnionAll: NearestCorrelationMatrix.Newton\n     \u2502         \u2502   kwargs \u2534 @NamedTuple{}: NamedTuple()\n     \u2502      dn \u253c Denoise\n     \u2502         \u2502      alg \u253c SpectralDenoise()\n     \u2502         \u2502     args \u253c Tuple{}: ()\n     \u2502         \u2502   kwargs \u253c @NamedTuple{}: NamedTuple()\n     \u2502         \u2502   kernel \u253c typeof(AverageShiftedHistograms.Kernels.gaussian): AverageShiftedHistograms.Kernels.gaussian\n     \u2502         \u2502        m \u253c Int64: 10\n     \u2502         \u2502        n \u253c Int64: 1000\n     \u2502         \u2502      pdm \u253c Posdef\n     \u2502         \u2502          \u2502      alg \u253c UnionAll: NearestCorrelationMatrix.Newton\n     \u2502         \u2502          \u2502   kwargs \u2534 @NamedTuple{}: NamedTuple()\n     \u2502      dt \u253c nothing\n     \u2502     alg \u253c nothing\n     \u2502   order \u2534 DenoiseDetoneAlg()\n\n PortfolioOptimisersCovariance\n  ce \u253c GerberCovariance\n     \u2502    ve \u253c SimpleVariance\n     \u2502       \u2502          me \u253c SimpleExpectedReturns\n     \u2502       \u2502             \u2502   w \u2534 nothing\n     \u2502       \u2502           w \u253c nothing\n     \u2502       \u2502   corrected \u2534 Bool: true\n     \u2502   pdm \u253c Posdef\n     \u2502       \u2502      alg \u253c UnionAll: NearestCorrelationMatrix.Newton\n     \u2502       \u2502   kwargs \u2534 @NamedTuple{}: NamedTuple()\n     \u2502     t \u253c Float64: 0.5\n     \u2502   alg \u2534 Gerber1()\n  mp \u253c DenoiseDetoneAlgMatrixProcessing\n     \u2502     pdm \u253c Posdef\n     \u2502         \u2502      alg \u253c UnionAll: NearestCorrelationMatrix.Newton\n     \u2502         \u2502   kwargs \u2534 @NamedTuple{}: NamedTuple()\n     \u2502      dn \u253c nothing\n     \u2502      dt \u253c nothing\n     \u2502     alg \u253c nothing\n     \u2502   order \u2534 DenoiseDetoneAlg()\n\n PortfolioOptimisersCovariance\n  ce \u253c SmythBrobyCovariance\n     \u2502    me \u253c SimpleExpectedReturns\n     \u2502       \u2502   w \u2534 nothing\n     \u2502    ve \u253c SimpleVariance\n     \u2502       \u2502          me \u253c SimpleExpectedReturns\n     \u2502       \u2502             \u2502   w \u2534 nothing\n     \u2502       \u2502           w \u253c nothing\n     \u2502       \u2502   corrected \u2534 Bool: true\n     \u2502   pdm \u253c Posdef\n     \u2502       \u2502      alg \u253c UnionAll: NearestCorrelationMatrix.Newton\n     \u2502       \u2502   kwargs \u2534 @NamedTuple{}: NamedTuple()\n     \u2502     t \u253c Float64: 0.5\n     \u2502    c1 \u253c Float64: 0.5\n     \u2502    c2 \u253c Float64: 0.5\n     \u2502    c3 \u253c Int64: 4\n     \u2502     n \u253c Int64: 2\n     \u2502   alg \u253c SmythBroby1()\n     \u2502    ex \u2534 Transducers.ThreadedEx{@NamedTuple{}}: Transducers.ThreadedEx()\n  mp \u253c DenoiseDetoneAlgMatrixProcessing\n     \u2502     pdm \u253c Posdef\n     \u2502         \u2502      alg \u253c UnionAll: NearestCorrelationMatrix.Newton\n     \u2502         \u2502   kwargs \u2534 @NamedTuple{}: NamedTuple()\n     \u2502      dn \u253c nothing\n     \u2502      dt \u253c nothing\n     \u2502     alg \u253c nothing\n     \u2502   order \u2534 DenoiseDetoneAlg()\n\n PortfolioOptimisersCovariance\n  ce \u253c MutualInfoCovariance\n     \u2502          ve \u253c SimpleVariance\n     \u2502             \u2502          me \u253c SimpleExpectedReturns\n     \u2502             \u2502             \u2502   w \u2534 nothing\n     \u2502             \u2502           w \u253c nothing\n     \u2502             \u2502   corrected \u2534 Bool: true\n     \u2502        bins \u253c HacineGharbiRavier()\n     \u2502   normalise \u2534 Bool: true\n  mp \u253c DenoiseDetoneAlgMatrixProcessing\n     \u2502     pdm \u253c Posdef\n     \u2502         \u2502      alg \u253c UnionAll: NearestCorrelationMatrix.Newton\n     \u2502         \u2502   kwargs \u2534 @NamedTuple{}: NamedTuple()\n     \u2502      dn \u253c nothing\n     \u2502      dt \u253c nothing\n     \u2502     alg \u253c nothing\n     \u2502   order \u2534 DenoiseDetoneAlg()\n\n PortfolioOptimisersCovariance\n  ce \u253c DistanceCovariance\n     \u2502     dist \u253c Distances.Euclidean: Distances.Euclidean(0.0)\n     \u2502     args \u253c Tuple{}: ()\n     \u2502   kwargs \u253c @NamedTuple{}: NamedTuple()\n     \u2502        w \u253c nothing\n     \u2502       ex \u2534 Transducers.ThreadedEx{@NamedTuple{}}: Transducers.ThreadedEx()\n  mp \u253c DenoiseDetoneAlgMatrixProcessing\n     \u2502     pdm \u253c Posdef\n     \u2502         \u2502      alg \u253c UnionAll: NearestCorrelationMatrix.Newton\n     \u2502         \u2502   kwargs \u2534 @NamedTuple{}: NamedTuple()\n     \u2502      dn \u253c nothing\n     \u2502      dt \u253c nothing\n     \u2502     alg \u253c nothing\n     \u2502   order \u2534 DenoiseDetoneAlg()\n"
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pr = prior(HighOrderPriorEstimator(), rd.X)\n",
        "\n",
        "ces = [PortfolioOptimisersCovariance(;\n",
        "                                     mp = DenoiseDetoneAlgMatrixProcessing(;\n",
        "                                                                           dn = Denoise(;\n",
        "                                                                                        alg = SpectralDenoise()))),\n",
        "       PortfolioOptimisersCovariance(; ce = GerberCovariance()),\n",
        "       PortfolioOptimisersCovariance(; ce = SmythBrobyCovariance(; alg = SmythBroby1())),\n",
        "       PortfolioOptimisersCovariance(; ce = MutualInfoCovariance()),\n",
        "       PortfolioOptimisersCovariance(; ce = DistanceCovariance())]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets define a vector of variance risk measure using each of the different covariance matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "6-element Vector{Variance{RiskMeasureSettings{Float64, Nothing, Bool}, Matrix{Float64}, Nothing, Nothing, SquaredSOCRiskExpr}}:\n Variance\n  settings \u253c RiskMeasureSettings\n           \u2502   scale \u253c Float64: 1.0\n           \u2502      ub \u253c nothing\n           \u2502     rke \u2534 Bool: true\n     sigma \u253c 20\u00d720 Matrix{Float64}\n      chol \u253c nothing\n        rc \u253c nothing\n       alg \u2534 SquaredSOCRiskExpr()\n\n Variance\n  settings \u253c RiskMeasureSettings\n           \u2502   scale \u253c Float64: 1.0\n           \u2502      ub \u253c nothing\n           \u2502     rke \u2534 Bool: true\n     sigma \u253c 20\u00d720 Matrix{Float64}\n      chol \u253c nothing\n        rc \u253c nothing\n       alg \u2534 SquaredSOCRiskExpr()\n\n Variance\n  settings \u253c RiskMeasureSettings\n           \u2502   scale \u253c Float64: 1.0\n           \u2502      ub \u253c nothing\n           \u2502     rke \u2534 Bool: true\n     sigma \u253c 20\u00d720 Matrix{Float64}\n      chol \u253c nothing\n        rc \u253c nothing\n       alg \u2534 SquaredSOCRiskExpr()\n\n Variance\n  settings \u253c RiskMeasureSettings\n           \u2502   scale \u253c Float64: 1.0\n           \u2502      ub \u253c nothing\n           \u2502     rke \u2534 Bool: true\n     sigma \u253c 20\u00d720 Matrix{Float64}\n      chol \u253c nothing\n        rc \u253c nothing\n       alg \u2534 SquaredSOCRiskExpr()\n\n Variance\n  settings \u253c RiskMeasureSettings\n           \u2502   scale \u253c Float64: 1.0\n           \u2502      ub \u253c nothing\n           \u2502     rke \u2534 Bool: true\n     sigma \u253c 20\u00d720 Matrix{Float64}\n      chol \u253c nothing\n        rc \u253c nothing\n       alg \u2534 SquaredSOCRiskExpr()\n\n Variance\n  settings \u253c RiskMeasureSettings\n           \u2502   scale \u253c Float64: 1.0\n           \u2502      ub \u253c nothing\n           \u2502     rke \u2534 Bool: true\n     sigma \u253c 20\u00d720 Matrix{Float64}\n      chol \u253c nothing\n        rc \u253c nothing\n       alg \u2534 SquaredSOCRiskExpr()\n"
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rs = [Variance(; sigma = cov(ce, rd.X)) for ce in ces]\n",
        "all_sigmas = zeros(length(rd.nx), length(rd.nx))\n",
        "for r in rs\n",
        "    all_sigmas .+= r.sigma\n",
        "end\n",
        "push!(rs, Variance(; sigma = all_sigmas))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll minimise the variance for each individual risk measure and then we'll minimise the equally weighted sum of all risk measures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
            "\u2502 assets \u2502  denoise \u2502  gerber1 \u2502 smyth_broby1 \u2502 mutual_info \u2502 distance \u2502   mea \u22ef\n",
            "\u2502 String \u2502  Float64 \u2502  Float64 \u2502      Float64 \u2502     Float64 \u2502  Float64 \u2502  Floa \u22ef\n",
            "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
            "\u2502   AAPL \u2502    0.0 % \u2502    0.0 % \u2502        0.0 % \u2502     1.263 % \u2502    0.0 % \u2502  0.25 \u22ef\n",
            "\u2502    AMD \u2502    0.0 % \u2502    0.0 % \u2502        0.0 % \u2502       0.0 % \u2502    0.0 % \u2502    0. \u22ef\n",
            "\u2502    BAC \u2502    0.0 % \u2502  2.988 % \u2502        0.0 % \u2502     2.166 % \u2502  2.279 % \u2502  1.48 \u22ef\n",
            "\u2502    BBY \u2502    0.0 % \u2502    0.0 % \u2502        0.0 % \u2502      0.74 % \u2502    0.0 % \u2502  0.14 \u22ef\n",
            "\u2502    CVX \u2502 17.488 % \u2502  9.462 % \u2502     15.048 % \u2502     4.007 % \u2502  9.961 % \u2502 11.19 \u22ef\n",
            "\u2502     GE \u2502    0.0 % \u2502  2.287 % \u2502        0.0 % \u2502     2.702 % \u2502  4.347 % \u2502  1.86 \u22ef\n",
            "\u2502     HD \u2502    0.0 % \u2502    0.0 % \u2502        0.0 % \u2502     2.713 % \u2502  3.792 % \u2502  1.30 \u22ef\n",
            "\u2502    JNJ \u2502 76.031 % \u2502 23.934 % \u2502     56.706 % \u2502    17.458 % \u2502  17.28 % \u2502 38.28 \u22ef\n",
            "\u2502    JPM \u2502    0.0 % \u2502    0.0 % \u2502        0.0 % \u2502     2.859 % \u2502  1.284 % \u2502  0.82 \u22ef\n",
            "\u2502     KO \u2502    0.0 % \u2502 14.145 % \u2502        0.0 % \u2502     9.807 % \u2502  9.243 % \u2502  6.63 \u22ef\n",
            "\u2502    LLY \u2502    0.0 % \u2502    0.0 % \u2502        0.0 % \u2502     4.874 % \u2502  0.241 % \u2502  1.02 \u22ef\n",
            "\u2502    MRK \u2502    0.0 % \u2502 17.816 % \u2502        0.0 % \u2502    14.056 % \u2502  18.66 % \u2502 10.10 \u22ef\n",
            "\u2502   MSFT \u2502    0.0 % \u2502    0.0 % \u2502        0.0 % \u2502     0.805 % \u2502    0.0 % \u2502  0.16 \u22ef\n",
            "\u2502    PEP \u2502    0.0 % \u2502 13.315 % \u2502     28.245 % \u2502     8.543 % \u2502  8.089 % \u2502 11.63 \u22ef\n",
            "\u2502    PFE \u2502    0.0 % \u2502  1.735 % \u2502        0.0 % \u2502     4.166 % \u2502    0.0 % \u2502   1.1 \u22ef\n",
            "\u2502      \u22ee \u2502        \u22ee \u2502        \u22ee \u2502            \u22ee \u2502           \u22ee \u2502        \u22ee \u2502       \u22f1\n",
            "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
            "                                                    3 columns and 5 rows omitted\n"
          ]
        }
      ],
      "source": [
        "results = [optimise(MeanRisk(; r = r, opt = JuMPOptimiser(; pr = pr, slv = slv)))\n",
        "           for r in rs]\n",
        "mean_w = zeros(length(results[1].w))\n",
        "for res in results[1:5]\n",
        "    mean_w .+= res.w\n",
        "end\n",
        "mean_w ./= 5\n",
        "res = optimise(MeanRisk(; r = rs, opt = JuMPOptimiser(; pr = pr, slv = slv)))\n",
        "pretty_table(DataFrame(:assets => rd.nx, :denoise => results[1].w, :gerber1 => results[2].w,\n",
        "                       :smyth_broby1 => results[3].w, :mutual_info => results[4].w,\n",
        "                       :distance => results[5].w, :mean_w => mean_w,\n",
        "                       :sum_covs => results[6].w, :multi_risk => res.w);\n",
        "             formatters = [resfmt])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For extra credit we can do the same but maximising the ratio of return to risk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
            "\u2502 assets \u2502  denoise \u2502  gerber1 \u2502 smyth_broby1 \u2502 mutual_info \u2502 distance \u2502   mea \u22ef\n",
            "\u2502 String \u2502  Float64 \u2502  Float64 \u2502      Float64 \u2502     Float64 \u2502  Float64 \u2502  Floa \u22ef\n",
            "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
            "\u2502   AAPL \u2502    0.0 % \u2502    0.0 % \u2502        0.0 % \u2502       0.0 % \u2502    0.0 % \u2502    0. \u22ef\n",
            "\u2502    AMD \u2502    0.0 % \u2502    0.0 % \u2502        0.0 % \u2502       0.0 % \u2502    0.0 % \u2502    0. \u22ef\n",
            "\u2502    BAC \u2502    0.0 % \u2502    0.0 % \u2502        0.0 % \u2502       0.0 % \u2502    0.0 % \u2502    0. \u22ef\n",
            "\u2502    BBY \u2502    0.0 % \u2502    0.0 % \u2502        0.0 % \u2502       0.0 % \u2502    0.0 % \u2502    0. \u22ef\n",
            "\u2502    CVX \u2502    0.0 % \u2502  3.321 % \u2502        0.0 % \u2502     9.888 % \u2502    0.0 % \u2502  2.64 \u22ef\n",
            "\u2502     GE \u2502    0.0 % \u2502    0.0 % \u2502        0.0 % \u2502       0.0 % \u2502    0.0 % \u2502    0. \u22ef\n",
            "\u2502     HD \u2502    0.0 % \u2502    0.0 % \u2502        0.0 % \u2502       0.0 % \u2502    0.0 % \u2502    0. \u22ef\n",
            "\u2502    JNJ \u2502    0.0 % \u2502    0.0 % \u2502        0.0 % \u2502       0.0 % \u2502    0.0 % \u2502    0. \u22ef\n",
            "\u2502    JPM \u2502    0.0 % \u2502    0.0 % \u2502        0.0 % \u2502       0.0 % \u2502    0.0 % \u2502    0. \u22ef\n",
            "\u2502     KO \u2502    0.0 % \u2502  0.002 % \u2502        0.0 % \u2502     5.688 % \u2502    0.0 % \u2502  1.13 \u22ef\n",
            "\u2502    LLY \u2502    0.0 % \u2502  8.099 % \u2502        0.0 % \u2502    14.783 % \u2502  1.936 % \u2502  4.96 \u22ef\n",
            "\u2502    MRK \u2502 67.803 % \u2502 59.727 % \u2502     69.393 % \u2502    46.763 % \u2502 50.398 % \u2502 58.81 \u22ef\n",
            "\u2502   MSFT \u2502    0.0 % \u2502    0.0 % \u2502        0.0 % \u2502       0.0 % \u2502    0.0 % \u2502    0. \u22ef\n",
            "\u2502    PEP \u2502    0.0 % \u2502  0.001 % \u2502        0.0 % \u2502     0.002 % \u2502    0.0 % \u2502  0.00 \u22ef\n",
            "\u2502    PFE \u2502    0.0 % \u2502    0.0 % \u2502        0.0 % \u2502       0.0 % \u2502    0.0 % \u2502    0. \u22ef\n",
            "\u2502      \u22ee \u2502        \u22ee \u2502        \u22ee \u2502            \u22ee \u2502           \u22ee \u2502        \u22ee \u2502       \u22f1\n",
            "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
            "                                                    3 columns and 5 rows omitted\n"
          ]
        }
      ],
      "source": [
        "results = [optimise(MeanRisk(; r = r, obj = MaximumRatio(),\n",
        "                             opt = JuMPOptimiser(; pr = pr, slv = slv))) for r in rs]\n",
        "mean_w = zeros(length(results[1].w))\n",
        "for res in results[1:5]\n",
        "    mean_w .+= res.w\n",
        "end\n",
        "mean_w ./= 5\n",
        "res = optimise(MeanRisk(; r = rs, obj = MaximumRatio(),\n",
        "                        opt = JuMPOptimiser(; pr = pr, slv = slv)))\n",
        "\n",
        "pretty_table(DataFrame(:assets => rd.nx, :denoise => results[1].w, :gerber1 => results[2].w,\n",
        "                       :smyth_broby1 => results[3].w, :mutual_info => results[4].w,\n",
        "                       :distance => results[5].w, :mean_w => mean_w,\n",
        "                       :sum_covs => results[6].w, :multi_risk => res.w);\n",
        "             formatters = [resfmt])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Different weights and scalarisers\n",
        "\n",
        "All optimisations accept multiple risk measures in the same way. We can also provide different weights for each measure and four different scalarisers, `SumScalariser`, `MaxScalariser`, `LogSumExpScalariser` which work for all optimisation estimators, and `MinScalariser` which only works for hierarchical ones.\n",
        "\n",
        "For clustering optimisations, the scalarisers apply to each sub-optimisation, so what may be the choice of risk to \"minimise\" for one cluster may not be the minimal risk for others, or the overall portfolio. This inconsistency is unavoidable but should not be a problem in practice as the point of hierarchical optimisations is not to provide the absolute minimum risk, but a good trade-off between risk and diversification.\n",
        "\n",
        "It is also possible to mix any and all compatible risk measures. We will demonstrate this by mixing the variance with the negative skewness.\n",
        "\n",
        "In this example we have tuned the weight of the negative skewness to demonstrate how clusters may end up with different risk measures due to the choice of scalariser.\n",
        "\n",
        "We will use the heirarchical equal risk contribution optimisation, precomputing the clustering results using the direct bubble hierarchy tree algorithm.\n",
        "\n",
        "The [`HierarchicalEqualRiskContribution`]-(@ref) optimisation estimator accepts inner and outer risk measures and inner and outer scalarisers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
            "\u2502 assets \u2502 variance \u2502 neg_skew \u2502  sum_sca \u2502 max_sca \u2502  min_sca \u2502 log_sum_exp \u2502\n",
            "\u2502 String \u2502  Float64 \u2502  Float64 \u2502  Float64 \u2502 Float64 \u2502  Float64 \u2502     Float64 \u2502\n",
            "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
            "\u2502   AAPL \u2502  1.847 % \u2502  4.367 % \u2502  2.949 % \u2502 3.286 % \u2502  2.571 % \u2502     3.152 % \u2502\n",
            "\u2502    AMD \u2502  0.627 % \u2502    2.3 % \u2502  1.056 % \u2502 1.115 % \u2502  1.354 % \u2502     1.069 % \u2502\n",
            "\u2502    BAC \u2502  2.221 % \u2502  6.575 % \u2502  3.636 % \u2502  3.95 % \u2502  3.871 % \u2502     3.789 % \u2502\n",
            "\u2502    BBY \u2502  1.138 % \u2502  2.166 % \u2502  1.781 % \u2502 2.024 % \u2502  1.275 % \u2502     1.942 % \u2502\n",
            "\u2502    CVX \u2502  4.525 % \u2502   4.41 % \u2502  5.338 % \u2502 6.436 % \u2502  3.246 % \u2502    11.606 % \u2502\n",
            "\u2502     GE \u2502  1.924 % \u2502  2.356 % \u2502  2.923 % \u2502 3.423 % \u2502  1.387 % \u2502     3.284 % \u2502\n",
            "\u2502     HD \u2502  2.386 % \u2502  2.995 % \u2502  3.629 % \u2502 4.244 % \u2502  1.763 % \u2502     4.071 % \u2502\n",
            "\u2502    JNJ \u2502 10.746 % \u2502  7.487 % \u2502 10.587 % \u2502 7.821 % \u2502 10.413 % \u2502     6.708 % \u2502\n",
            "\u2502    JPM \u2502  2.623 % \u2502  5.682 % \u2502  4.153 % \u2502 4.666 % \u2502  3.345 % \u2502     4.476 % \u2502\n",
            "\u2502     KO \u2502  13.86 % \u2502  7.188 % \u2502  9.593 % \u2502 7.509 % \u2502 13.431 % \u2502     9.748 % \u2502\n",
            "\u2502    LLY \u2502  4.388 % \u2502  7.217 % \u2502  4.727 % \u2502 7.539 % \u2502  4.253 % \u2502     2.739 % \u2502\n",
            "\u2502    MRK \u2502  8.205 % \u2502   7.77 % \u2502  8.283 % \u2502 8.117 % \u2502  7.951 % \u2502     5.122 % \u2502\n",
            "\u2502   MSFT \u2502  1.886 % \u2502    4.4 % \u2502  3.008 % \u2502 3.356 % \u2502   2.59 % \u2502     3.219 % \u2502\n",
            "\u2502    PEP \u2502 14.175 % \u2502  6.616 % \u2502  9.727 % \u2502 6.911 % \u2502 13.736 % \u2502     9.969 % \u2502\n",
            "\u2502    PFE \u2502  4.473 % \u2502   5.51 % \u2502  4.639 % \u2502 5.756 % \u2502  4.334 % \u2502     2.792 % \u2502\n",
            "\u2502      \u22ee \u2502        \u22ee \u2502        \u22ee \u2502        \u22ee \u2502       \u22ee \u2502        \u22ee \u2502           \u22ee \u2502\n",
            "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
            "                                                                5 rows omitted\n"
          ]
        }
      ],
      "source": [
        "clr = clusterise(ClustersEstimator(; alg = DBHT()), pr.X)\n",
        "r = [Variance(), NegativeSkewness(; settings = RiskMeasureSettings(; scale = 0.1))]\n",
        "\n",
        "results = [optimise(HierarchicalEqualRiskContribution(; ri = r[1],# inner (intra-cluster) risk measure\n",
        "                                                      ro = r[1],# outer (inter-cluster) risk measure\n",
        "                                                      opt = HierarchicalOptimiser(; pe = pr,\n",
        "                                                                                  cle = clr))),\n",
        "           optimise(HierarchicalEqualRiskContribution(; ri = r[2], ro = r[2],\n",
        "                                                      opt = HierarchicalOptimiser(; pe = pr,\n",
        "                                                                                  cle = clr))),\n",
        "           optimise(HierarchicalEqualRiskContribution(; ri = r, ro = r,#\n",
        "                                                      scai = SumScalariser(),# inner (intra-cluster)\n",
        "                                                      scao = SumScalariser(),# outer (inter-cluster)\n",
        "                                                      opt = HierarchicalOptimiser(; pe = pr,\n",
        "                                                                                  cle = clr))),\n",
        "           optimise(HierarchicalEqualRiskContribution(; ri = r, ro = r,\n",
        "                                                      scai = MaxScalariser(),\n",
        "                                                      scao = MaxScalariser(),\n",
        "                                                      opt = HierarchicalOptimiser(; pe = pr,\n",
        "                                                                                  cle = clr))),\n",
        "           optimise(HierarchicalEqualRiskContribution(; ri = r, ro = r,\n",
        "                                                      scai = MinScalariser(),\n",
        "                                                      scao = MinScalariser(),\n",
        "                                                      opt = HierarchicalOptimiser(; pe = pr,\n",
        "                                                                                  cle = clr))),\n",
        "           optimise(HierarchicalEqualRiskContribution(; ri = r, ro = r,\n",
        "                                                      scai = LogSumExpScalariser(),\n",
        "                                                      scao = LogSumExpScalariser(),\n",
        "                                                      opt = HierarchicalOptimiser(; pe = pr,\n",
        "                                                                                  cle = clr)))]\n",
        "\n",
        "pretty_table(DataFrame(:assets => rd.nx, :variance => results[1].w,\n",
        "                       :neg_skew => results[2].w, :sum_sca => results[3].w,\n",
        "                       :max_sca => results[4].w, :min_sca => results[5].w,\n",
        "                       :log_sum_exp => results[6].w); formatters = [resfmt])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When the weights are different enough that one risk measure domintes over the other in all contexts, then the results of the max and min scalarisers will be as expected, i.e. they will be as if only one risk measure was used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
            "\u2502 assets \u2502 variance \u2502 neg_skew \u2502 sum_sca \u2502 max_sca \u2502  min_sca \u2502 log_sum_exp \u2502\n",
            "\u2502 String \u2502  Float64 \u2502  Float64 \u2502 Float64 \u2502 Float64 \u2502  Float64 \u2502     Float64 \u2502\n",
            "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
            "\u2502   AAPL \u2502  1.847 % \u2502  4.367 % \u2502 3.946 % \u2502 4.367 % \u2502  1.847 % \u2502     3.155 % \u2502\n",
            "\u2502    AMD \u2502  0.627 % \u2502    2.3 % \u2502  1.73 % \u2502   2.3 % \u2502  0.627 % \u2502      1.07 % \u2502\n",
            "\u2502    BAC \u2502  2.221 % \u2502  6.575 % \u2502 5.377 % \u2502 6.575 % \u2502  2.221 % \u2502     3.792 % \u2502\n",
            "\u2502    BBY \u2502  1.138 % \u2502  2.166 % \u2502 2.181 % \u2502 2.166 % \u2502  1.138 % \u2502     1.943 % \u2502\n",
            "\u2502    CVX \u2502  4.525 % \u2502   4.41 % \u2502 4.959 % \u2502  4.41 % \u2502  4.525 % \u2502    11.589 % \u2502\n",
            "\u2502     GE \u2502  1.924 % \u2502  2.356 % \u2502 3.063 % \u2502 2.356 % \u2502  1.924 % \u2502     3.286 % \u2502\n",
            "\u2502     HD \u2502  2.386 % \u2502  2.995 % \u2502 3.833 % \u2502 2.995 % \u2502  2.386 % \u2502     4.074 % \u2502\n",
            "\u2502    JNJ \u2502 10.746 % \u2502  7.487 % \u2502 8.942 % \u2502 7.487 % \u2502 10.746 % \u2502     6.714 % \u2502\n",
            "\u2502    JPM \u2502  2.623 % \u2502  5.682 % \u2502 5.356 % \u2502 5.682 % \u2502  2.623 % \u2502     4.479 % \u2502\n",
            "\u2502     KO \u2502  13.86 % \u2502  7.188 % \u2502 7.697 % \u2502 7.188 % \u2502  13.86 % \u2502     9.745 % \u2502\n",
            "\u2502    LLY \u2502  4.388 % \u2502  7.217 % \u2502  5.76 % \u2502 7.217 % \u2502  4.388 % \u2502     2.742 % \u2502\n",
            "\u2502    MRK \u2502  8.205 % \u2502   7.77 % \u2502 7.869 % \u2502  7.77 % \u2502  8.205 % \u2502     5.127 % \u2502\n",
            "\u2502   MSFT \u2502  1.886 % \u2502    4.4 % \u2502 4.002 % \u2502   4.4 % \u2502  1.886 % \u2502     3.221 % \u2502\n",
            "\u2502    PEP \u2502 14.175 % \u2502  6.616 % \u2502 7.491 % \u2502 6.616 % \u2502 14.175 % \u2502     9.967 % \u2502\n",
            "\u2502    PFE \u2502  4.473 % \u2502   5.51 % \u2502 4.935 % \u2502  5.51 % \u2502  4.473 % \u2502     2.795 % \u2502\n",
            "\u2502      \u22ee \u2502        \u22ee \u2502        \u22ee \u2502       \u22ee \u2502       \u22ee \u2502        \u22ee \u2502           \u22ee \u2502\n",
            "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
            "                                                               5 rows omitted\n"
          ]
        }
      ],
      "source": [
        "r = [Variance(), NegativeSkewness()]\n",
        "\n",
        "results = [optimise(HierarchicalEqualRiskContribution(; ri = r[1],# inner (intra-cluster) risk measure\n",
        "                                                      ro = r[1],# outer (inter-cluster) risk measure\n",
        "                                                      opt = HierarchicalOptimiser(; pe = pr,\n",
        "                                                                                  cle = clr))),\n",
        "           optimise(HierarchicalEqualRiskContribution(; ri = r[2], ro = r[2],\n",
        "                                                      opt = HierarchicalOptimiser(; pe = pr,\n",
        "                                                                                  cle = clr))),\n",
        "           optimise(HierarchicalEqualRiskContribution(; ri = r, ro = r,#\n",
        "                                                      scai = SumScalariser(),# inner (intra-cluster)\n",
        "                                                      scao = SumScalariser(),# outer (inter-cluster)\n",
        "                                                      opt = HierarchicalOptimiser(; pe = pr,\n",
        "                                                                                  cle = clr))),\n",
        "           optimise(HierarchicalEqualRiskContribution(; ri = r, ro = r,\n",
        "                                                      scai = MaxScalariser(),\n",
        "                                                      scao = MaxScalariser(),\n",
        "                                                      opt = HierarchicalOptimiser(; pe = pr,\n",
        "                                                                                  cle = clr))),\n",
        "           optimise(HierarchicalEqualRiskContribution(; ri = r, ro = r,\n",
        "                                                      scai = MinScalariser(),\n",
        "                                                      scao = MinScalariser(),\n",
        "                                                      opt = HierarchicalOptimiser(; pe = pr,\n",
        "                                                                                  cle = clr))),\n",
        "           optimise(HierarchicalEqualRiskContribution(; ri = r, ro = r,\n",
        "                                                      scai = LogSumExpScalariser(),\n",
        "                                                      scao = LogSumExpScalariser(),\n",
        "                                                      opt = HierarchicalOptimiser(; pe = pr,\n",
        "                                                                                  cle = clr)))]\n",
        "\n",
        "pretty_table(DataFrame(:assets => rd.nx, :variance => results[1].w,\n",
        "                       :neg_skew => results[2].w, :sum_sca => results[3].w,\n",
        "                       :max_sca => results[4].w, :min_sca => results[5].w,\n",
        "                       :log_sum_exp => results[6].w); formatters = [resfmt])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note how the max scalariser produced the same weights as the negative skewness and the min scalariser produced the same weights as the variance. This is because in all cases, the same the value of the negative skewness was greater than that of the variance. A similar behaviour can be observed with other clustering optimisers. [`NearOptimalCentering`]-(@ref) can also have unintuitive behaviour when computing the risk bounds with an effective frontier `MaxScalariser` and `MinScalariser` due to the fact that each point in the efficient frontier can have a different risk measure dominating the others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Julia 1.12.4",
      "language": "julia",
      "name": "julia-1.12"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 3
}
