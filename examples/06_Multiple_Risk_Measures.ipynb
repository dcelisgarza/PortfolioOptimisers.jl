{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Example 6: Multiple risk measures\n",
    "\n",
    "This example shows how to use multiple risk measures."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using PortfolioOptimisers, PrettyTables\n",
    "# Format for pretty tables.\n",
    "tsfmt = (v, i, j) -> begin\n",
    "    if j == 1\n",
    "        return Date(v)\n",
    "    else\n",
    "        return v\n",
    "    end\n",
    "end;\n",
    "resfmt = (v, i, j) -> begin\n",
    "    if j == 1\n",
    "        return v\n",
    "    else\n",
    "        return isa(v, Number) ? \"$(round(v*100, digits=3)) %\" : v\n",
    "    end\n",
    "end;\n",
    "mipresfmt = (v, i, j) -> begin\n",
    "    if j ∈ (1, 2, 3)\n",
    "        return v\n",
    "    else\n",
    "        return isa(v, Number) ? \"$(round(v*100, digits=3)) %\" : v\n",
    "    end\n",
    "end;"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. ReturnsResult data\n",
    "\n",
    "We will use the same data as the previous example."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬──────\n",
      "│  timestamp │    AAPL │     AMD │     BAC │     BBY │     CVX │      GE │     ⋯\n",
      "│ Dates.Date │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Flo ⋯\n",
      "├────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼──────\n",
      "│ 2022-12-20 │ 131.916 │   65.05 │  31.729 │  77.371 │ 169.497 │  62.604 │ 310 ⋯\n",
      "│ 2022-12-21 │ 135.057 │   67.68 │  32.212 │  78.729 │  171.49 │   64.67 │ 314 ⋯\n",
      "│ 2022-12-22 │ 131.846 │   63.86 │  31.927 │  78.563 │ 168.918 │  63.727 │ 311 ⋯\n",
      "│ 2022-12-23 │ 131.477 │   64.52 │  32.005 │  79.432 │  174.14 │  63.742 │ 314 ⋯\n",
      "│ 2022-12-27 │ 129.652 │   63.27 │  32.065 │   79.93 │ 176.329 │  64.561 │ 314 ⋯\n",
      "│ 2022-12-28 │ 125.674 │   62.57 │  32.301 │  78.279 │ 173.728 │  63.883 │  31 ⋯\n",
      "└────────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴──────\n",
      "                                                              14 columns omitted\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ReturnsResult\n    nx ┼ 20-element Vector{String}\n     X ┼ 252×20 Matrix{Float64}\n    nf ┼ nothing\n     F ┼ nothing\n    ts ┼ 252-element Vector{Dates.Date}\n    iv ┼ nothing\n  ivpa ┴ nothing\n"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "using CSV, TimeSeries, DataFrames\n",
    "\n",
    "X = TimeArray(CSV.File(joinpath(@__DIR__, \"SP500.csv.gz\")); timestamp = :Date)[(end - 252):end]\n",
    "pretty_table(X[(end - 5):end]; formatters = [tsfmt])\n",
    "\n",
    "# Compute the returns\n",
    "rd = prices_to_returns(X)"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Preparatory steps\n",
    "\n",
    "We'll provide a vector of continuous solvers as a failsafe."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Clarabel\n",
    "slv = [Solver(; name = :clarabel1, solver = Clarabel.Optimizer,\n",
    "              settings = Dict(\"verbose\" => false),\n",
    "              check_sol = (; allow_local = true, allow_almost = true)),\n",
    "       Solver(; name = :clarabel3, solver = Clarabel.Optimizer,\n",
    "              settings = Dict(\"verbose\" => false, \"max_step_fraction\" => 0.9),\n",
    "              check_sol = (; allow_local = true, allow_almost = true)),\n",
    "       Solver(; name = :clarabel5, solver = Clarabel.Optimizer,\n",
    "              settings = Dict(\"verbose\" => false, \"max_step_fraction\" => 0.8),\n",
    "              check_sol = (; allow_local = true, allow_almost = true)),\n",
    "       Solver(; name = :clarabel7, solver = Clarabel.Optimizer,\n",
    "              settings = Dict(\"verbose\" => false, \"max_step_fraction\" => 0.70),\n",
    "              check_sol = (; allow_local = true, allow_almost = true))];"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Multiple risk measures\n",
    "\n",
    "### 3.1 Equally weighted sum\n",
    "\n",
    "Some risk measures can use precomputed prior statistics which take precedence over the ones in `PriorResult`. We can make use of this to minimise the variance with different covariance matrices simultaneously.\n",
    "\n",
    "We will also precompute the prior statistics to minimise redundant work. First lets create a vector of Variances onto which we will push the different variances. We'll use 5 variance estimators, and their equally weighted sum.\n",
    "\n",
    "  1. Denoised covariance using the spectral algorithm.\n",
    "  2. Gerber 1 covariance.\n",
    "  3. Smyth Broby 1 covariance.\n",
    "  4. Mutual Information covariance.\n",
    "  5. Distance covariance.\n",
    "  6. Equally weighted sum of all the above covariances.\n",
    "\n",
    "For the multi risk measure optimisation, we will weigh each risk measure equally. It should give the same result as adding all covariances together, but not the same as averaging the weights of the individual optimisations."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5-element Vector{PortfolioOptimisersCovariance}:\n PortfolioOptimisersCovariance\n  ce ┼ Covariance\n     │    me ┼ SimpleExpectedReturns\n     │       │   w ┴ nothing\n     │    ce ┼ GeneralCovariance\n     │       │   ce ┼ SimpleCovariance: SimpleCovariance(true)\n     │       │    w ┴ nothing\n     │   alg ┴ Full()\n  mp ┼ DenoiseDetoneAlgMatrixProcessing\n     │     pdm ┼ Posdef\n     │         │      alg ┼ UnionAll: NearestCorrelationMatrix.Newton\n     │         │   kwargs ┴ @NamedTuple{}: NamedTuple()\n     │      dn ┼ Denoise\n     │         │      alg ┼ SpectralDenoise()\n     │         │     args ┼ Tuple{}: ()\n     │         │   kwargs ┼ @NamedTuple{}: NamedTuple()\n     │         │   kernel ┼ typeof(AverageShiftedHistograms.Kernels.gaussian): AverageShiftedHistograms.Kernels.gaussian\n     │         │        m ┼ Int64: 10\n     │         │        n ┼ Int64: 1000\n     │         │      pdm ┼ Posdef\n     │         │          │      alg ┼ UnionAll: NearestCorrelationMatrix.Newton\n     │         │          │   kwargs ┴ @NamedTuple{}: NamedTuple()\n     │      dt ┼ nothing\n     │     alg ┼ nothing\n     │   order ┴ DenoiseDetoneAlg()\n\n PortfolioOptimisersCovariance\n  ce ┼ GerberCovariance\n     │    ve ┼ SimpleVariance\n     │       │          me ┼ SimpleExpectedReturns\n     │       │             │   w ┴ nothing\n     │       │           w ┼ nothing\n     │       │   corrected ┴ Bool: true\n     │   pdm ┼ Posdef\n     │       │      alg ┼ UnionAll: NearestCorrelationMatrix.Newton\n     │       │   kwargs ┴ @NamedTuple{}: NamedTuple()\n     │     t ┼ Float64: 0.5\n     │   alg ┴ Gerber1()\n  mp ┼ DenoiseDetoneAlgMatrixProcessing\n     │     pdm ┼ Posdef\n     │         │      alg ┼ UnionAll: NearestCorrelationMatrix.Newton\n     │         │   kwargs ┴ @NamedTuple{}: NamedTuple()\n     │      dn ┼ nothing\n     │      dt ┼ nothing\n     │     alg ┼ nothing\n     │   order ┴ DenoiseDetoneAlg()\n\n PortfolioOptimisersCovariance\n  ce ┼ SmythBrobyCovariance\n     │    me ┼ SimpleExpectedReturns\n     │       │   w ┴ nothing\n     │    ve ┼ SimpleVariance\n     │       │          me ┼ SimpleExpectedReturns\n     │       │             │   w ┴ nothing\n     │       │           w ┼ nothing\n     │       │   corrected ┴ Bool: true\n     │   pdm ┼ Posdef\n     │       │      alg ┼ UnionAll: NearestCorrelationMatrix.Newton\n     │       │   kwargs ┴ @NamedTuple{}: NamedTuple()\n     │     t ┼ Float64: 0.5\n     │    c1 ┼ Float64: 0.5\n     │    c2 ┼ Float64: 0.5\n     │    c3 ┼ Int64: 4\n     │     n ┼ Int64: 2\n     │   alg ┼ SmythBroby1()\n     │    ex ┴ Transducers.ThreadedEx{@NamedTuple{}}: Transducers.ThreadedEx()\n  mp ┼ DenoiseDetoneAlgMatrixProcessing\n     │     pdm ┼ Posdef\n     │         │      alg ┼ UnionAll: NearestCorrelationMatrix.Newton\n     │         │   kwargs ┴ @NamedTuple{}: NamedTuple()\n     │      dn ┼ nothing\n     │      dt ┼ nothing\n     │     alg ┼ nothing\n     │   order ┴ DenoiseDetoneAlg()\n\n PortfolioOptimisersCovariance\n  ce ┼ MutualInfoCovariance\n     │          ve ┼ SimpleVariance\n     │             │          me ┼ SimpleExpectedReturns\n     │             │             │   w ┴ nothing\n     │             │           w ┼ nothing\n     │             │   corrected ┴ Bool: true\n     │        bins ┼ HacineGharbiRavier()\n     │   normalise ┴ Bool: true\n  mp ┼ DenoiseDetoneAlgMatrixProcessing\n     │     pdm ┼ Posdef\n     │         │      alg ┼ UnionAll: NearestCorrelationMatrix.Newton\n     │         │   kwargs ┴ @NamedTuple{}: NamedTuple()\n     │      dn ┼ nothing\n     │      dt ┼ nothing\n     │     alg ┼ nothing\n     │   order ┴ DenoiseDetoneAlg()\n\n PortfolioOptimisersCovariance\n  ce ┼ DistanceCovariance\n     │     dist ┼ Distances.Euclidean: Distances.Euclidean(0.0)\n     │     args ┼ Tuple{}: ()\n     │   kwargs ┼ @NamedTuple{}: NamedTuple()\n     │        w ┼ nothing\n     │       ex ┴ Transducers.ThreadedEx{@NamedTuple{}}: Transducers.ThreadedEx()\n  mp ┼ DenoiseDetoneAlgMatrixProcessing\n     │     pdm ┼ Posdef\n     │         │      alg ┼ UnionAll: NearestCorrelationMatrix.Newton\n     │         │   kwargs ┴ @NamedTuple{}: NamedTuple()\n     │      dn ┼ nothing\n     │      dt ┼ nothing\n     │     alg ┼ nothing\n     │   order ┴ DenoiseDetoneAlg()\n"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "pr = prior(HighOrderPriorEstimator(), rd.X)\n",
    "\n",
    "ces = [PortfolioOptimisersCovariance(;\n",
    "                                     mp = DenoiseDetoneAlgMatrixProcessing(;\n",
    "                                                                           dn = Denoise(;\n",
    "                                                                                        alg = SpectralDenoise()))),\n",
    "       PortfolioOptimisersCovariance(; ce = GerberCovariance()),\n",
    "       PortfolioOptimisersCovariance(; ce = SmythBrobyCovariance(; alg = SmythBroby1())),\n",
    "       PortfolioOptimisersCovariance(; ce = MutualInfoCovariance()),\n",
    "       PortfolioOptimisersCovariance(; ce = DistanceCovariance())]"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets define a vector of variance risk measure using each of the different covariance matrices."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6-element Vector{Variance{RiskMeasureSettings{Float64, Nothing, Bool}, Matrix{Float64}, Nothing, Nothing, SquaredSOCRiskExpr}}:\n Variance\n  settings ┼ RiskMeasureSettings\n           │   scale ┼ Float64: 1.0\n           │      ub ┼ nothing\n           │     rke ┴ Bool: true\n     sigma ┼ 20×20 Matrix{Float64}\n      chol ┼ nothing\n        rc ┼ nothing\n       alg ┴ SquaredSOCRiskExpr()\n\n Variance\n  settings ┼ RiskMeasureSettings\n           │   scale ┼ Float64: 1.0\n           │      ub ┼ nothing\n           │     rke ┴ Bool: true\n     sigma ┼ 20×20 Matrix{Float64}\n      chol ┼ nothing\n        rc ┼ nothing\n       alg ┴ SquaredSOCRiskExpr()\n\n Variance\n  settings ┼ RiskMeasureSettings\n           │   scale ┼ Float64: 1.0\n           │      ub ┼ nothing\n           │     rke ┴ Bool: true\n     sigma ┼ 20×20 Matrix{Float64}\n      chol ┼ nothing\n        rc ┼ nothing\n       alg ┴ SquaredSOCRiskExpr()\n\n Variance\n  settings ┼ RiskMeasureSettings\n           │   scale ┼ Float64: 1.0\n           │      ub ┼ nothing\n           │     rke ┴ Bool: true\n     sigma ┼ 20×20 Matrix{Float64}\n      chol ┼ nothing\n        rc ┼ nothing\n       alg ┴ SquaredSOCRiskExpr()\n\n Variance\n  settings ┼ RiskMeasureSettings\n           │   scale ┼ Float64: 1.0\n           │      ub ┼ nothing\n           │     rke ┴ Bool: true\n     sigma ┼ 20×20 Matrix{Float64}\n      chol ┼ nothing\n        rc ┼ nothing\n       alg ┴ SquaredSOCRiskExpr()\n\n Variance\n  settings ┼ RiskMeasureSettings\n           │   scale ┼ Float64: 1.0\n           │      ub ┼ nothing\n           │     rke ┴ Bool: true\n     sigma ┼ 20×20 Matrix{Float64}\n      chol ┼ nothing\n        rc ┼ nothing\n       alg ┴ SquaredSOCRiskExpr()\n"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "rs = [Variance(; sigma = cov(ce, rd.X)) for ce in ces]\n",
    "all_sigmas = zeros(length(rd.nx), length(rd.nx))\n",
    "for r in rs\n",
    "    all_sigmas .+= r.sigma\n",
    "end\n",
    "push!(rs, Variance(; sigma = all_sigmas))"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll minimise the variance for each individual risk measure and then we'll minimise the equally weighted sum of all risk measures."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────┬──────────┬──────────┬──────────────┬─────────────┬──────────┬────────\n",
      "│ assets │  denoise │  gerber1 │ smyth_broby1 │ mutual_info │ distance │   mea ⋯\n",
      "│ String │  Float64 │  Float64 │      Float64 │     Float64 │  Float64 │  Floa ⋯\n",
      "├────────┼──────────┼──────────┼──────────────┼─────────────┼──────────┼────────\n",
      "│   AAPL │    0.0 % │    0.0 % │        0.0 % │     1.263 % │    0.0 % │  0.25 ⋯\n",
      "│    AMD │    0.0 % │    0.0 % │        0.0 % │       0.0 % │    0.0 % │    0. ⋯\n",
      "│    BAC │    0.0 % │  2.988 % │        0.0 % │     2.166 % │  2.279 % │  1.48 ⋯\n",
      "│    BBY │    0.0 % │    0.0 % │        0.0 % │      0.74 % │    0.0 % │  0.14 ⋯\n",
      "│    CVX │ 17.488 % │  9.462 % │     15.048 % │     4.007 % │  9.961 % │ 11.19 ⋯\n",
      "│     GE │    0.0 % │  2.287 % │        0.0 % │     2.702 % │  4.347 % │  1.86 ⋯\n",
      "│     HD │    0.0 % │    0.0 % │        0.0 % │     2.713 % │  3.792 % │  1.30 ⋯\n",
      "│    JNJ │ 76.031 % │ 23.934 % │     56.706 % │    17.458 % │  17.28 % │ 38.28 ⋯\n",
      "│    JPM │    0.0 % │    0.0 % │        0.0 % │     2.859 % │  1.284 % │  0.82 ⋯\n",
      "│     KO │    0.0 % │ 14.145 % │        0.0 % │     9.807 % │  9.243 % │  6.63 ⋯\n",
      "│    LLY │    0.0 % │    0.0 % │        0.0 % │     4.874 % │  0.241 % │  1.02 ⋯\n",
      "│    MRK │    0.0 % │ 17.816 % │        0.0 % │    14.056 % │  18.66 % │ 10.10 ⋯\n",
      "│   MSFT │    0.0 % │    0.0 % │        0.0 % │     0.805 % │    0.0 % │  0.16 ⋯\n",
      "│    PEP │    0.0 % │ 13.315 % │     28.245 % │     8.543 % │  8.089 % │ 11.63 ⋯\n",
      "│    PFE │    0.0 % │  1.735 % │        0.0 % │     4.166 % │    0.0 % │   1.1 ⋯\n",
      "│      ⋮ │        ⋮ │        ⋮ │            ⋮ │           ⋮ │        ⋮ │       ⋱\n",
      "└────────┴──────────┴──────────┴──────────────┴─────────────┴──────────┴────────\n",
      "                                                    3 columns and 5 rows omitted\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "results = [optimise(MeanRisk(; r = r, opt = JuMPOptimiser(; pr = pr, slv = slv)))\n",
    "           for r in rs]\n",
    "mean_w = zeros(length(results[1].w))\n",
    "for res in results[1:5]\n",
    "    mean_w .+= res.w\n",
    "end\n",
    "mean_w ./= 5\n",
    "res = optimise(MeanRisk(; r = rs, opt = JuMPOptimiser(; pr = pr, slv = slv)))\n",
    "pretty_table(DataFrame(:assets => rd.nx, :denoise => results[1].w, :gerber1 => results[2].w,\n",
    "                       :smyth_broby1 => results[3].w, :mutual_info => results[4].w,\n",
    "                       :distance => results[5].w, :mean_w => mean_w,\n",
    "                       :sum_covs => results[6].w, :multi_risk => res.w);\n",
    "             formatters = [resfmt])"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "For extra credit we can do the same but maximising the ratio of return to risk."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────┬──────────┬──────────┬──────────────┬─────────────┬──────────┬────────\n",
      "│ assets │  denoise │  gerber1 │ smyth_broby1 │ mutual_info │ distance │   mea ⋯\n",
      "│ String │  Float64 │  Float64 │      Float64 │     Float64 │  Float64 │  Floa ⋯\n",
      "├────────┼──────────┼──────────┼──────────────┼─────────────┼──────────┼────────\n",
      "│   AAPL │    0.0 % │    0.0 % │        0.0 % │       0.0 % │    0.0 % │    0. ⋯\n",
      "│    AMD │    0.0 % │    0.0 % │        0.0 % │       0.0 % │    0.0 % │    0. ⋯\n",
      "│    BAC │    0.0 % │    0.0 % │        0.0 % │       0.0 % │    0.0 % │    0. ⋯\n",
      "│    BBY │    0.0 % │    0.0 % │        0.0 % │       0.0 % │    0.0 % │    0. ⋯\n",
      "│    CVX │    0.0 % │  3.321 % │        0.0 % │     9.888 % │    0.0 % │  2.64 ⋯\n",
      "│     GE │    0.0 % │    0.0 % │        0.0 % │       0.0 % │    0.0 % │    0. ⋯\n",
      "│     HD │    0.0 % │    0.0 % │        0.0 % │       0.0 % │    0.0 % │    0. ⋯\n",
      "│    JNJ │    0.0 % │    0.0 % │        0.0 % │       0.0 % │    0.0 % │    0. ⋯\n",
      "│    JPM │    0.0 % │    0.0 % │        0.0 % │       0.0 % │    0.0 % │    0. ⋯\n",
      "│     KO │    0.0 % │  0.002 % │        0.0 % │     5.688 % │    0.0 % │  1.13 ⋯\n",
      "│    LLY │    0.0 % │  8.099 % │        0.0 % │    14.783 % │  1.936 % │  4.96 ⋯\n",
      "│    MRK │ 67.803 % │ 59.727 % │     69.393 % │    46.763 % │ 50.398 % │ 58.81 ⋯\n",
      "│   MSFT │    0.0 % │    0.0 % │        0.0 % │       0.0 % │    0.0 % │    0. ⋯\n",
      "│    PEP │    0.0 % │  0.001 % │        0.0 % │     0.002 % │    0.0 % │  0.00 ⋯\n",
      "│    PFE │    0.0 % │    0.0 % │        0.0 % │       0.0 % │    0.0 % │    0. ⋯\n",
      "│      ⋮ │        ⋮ │        ⋮ │            ⋮ │           ⋮ │        ⋮ │       ⋱\n",
      "└────────┴──────────┴──────────┴──────────────┴─────────────┴──────────┴────────\n",
      "                                                    3 columns and 5 rows omitted\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "results = [optimise(MeanRisk(; r = r, obj = MaximumRatio(),\n",
    "                             opt = JuMPOptimiser(; pr = pr, slv = slv))) for r in rs]\n",
    "mean_w = zeros(length(results[1].w))\n",
    "for res in results[1:5]\n",
    "    mean_w .+= res.w\n",
    "end\n",
    "mean_w ./= 5\n",
    "res = optimise(MeanRisk(; r = rs, obj = MaximumRatio(),\n",
    "                        opt = JuMPOptimiser(; pr = pr, slv = slv)))\n",
    "\n",
    "pretty_table(DataFrame(:assets => rd.nx, :denoise => results[1].w, :gerber1 => results[2].w,\n",
    "                       :smyth_broby1 => results[3].w, :mutual_info => results[4].w,\n",
    "                       :distance => results[5].w, :mean_w => mean_w,\n",
    "                       :sum_covs => results[6].w, :multi_risk => res.w);\n",
    "             formatters = [resfmt])"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Different weights and scalarisers\n",
    "\n",
    "All optimisations accept multiple risk measures in the same way. We can also provide different weights for each measure and four different scalarisers, `SumScalariser`, `MaxScalariser`, `LogSumExpScalariser` which work for all optimisation estimators, and `MinScalariser` which only works for hierarchical ones.\n",
    "\n",
    "For clustering optimisations, the scalarisers apply to each sub-optimisation, so what may be the choice of risk to \"minimise\" for one cluster may not be the minimal risk for others, or the overall portfolio. This inconsistency is unavoidable but should not be a problem in practice as the point of hierarchical optimisations is not to provide the absolute minimum risk, but a good trade-off between risk and diversification.\n",
    "\n",
    "It is also possible to mix any and all compatible risk measures. We will demonstrate this by mixing the variance with the negative skewness.\n",
    "\n",
    "In this example we have tuned the weight of the negative skewness to demonstrate how clusters may end up with different risk measures due to the choice of scalariser.\n",
    "\n",
    "We will use the heirarchical equal risk contribution optimisation, precomputing the clustering results using the direct bubble hierarchy tree algorithm.\n",
    "\n",
    "The [`HierarchicalEqualRiskContribution`]-(@ref) optimisation estimator accepts inner and outer risk measures and inner and outer scalarisers."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────┬──────────┬──────────┬──────────┬─────────┬──────────┬─────────────┐\n",
      "│ assets │ variance │ neg_skew │  sum_sca │ max_sca │  min_sca │ log_sum_exp │\n",
      "│ String │  Float64 │  Float64 │  Float64 │ Float64 │  Float64 │     Float64 │\n",
      "├────────┼──────────┼──────────┼──────────┼─────────┼──────────┼─────────────┤\n",
      "│   AAPL │  1.847 % │  4.367 % │  2.949 % │ 3.286 % │  2.571 % │     3.152 % │\n",
      "│    AMD │  0.627 % │    2.3 % │  1.056 % │ 1.115 % │  1.354 % │     1.069 % │\n",
      "│    BAC │  2.221 % │  6.575 % │  3.636 % │  3.95 % │  3.871 % │     3.789 % │\n",
      "│    BBY │  1.138 % │  2.166 % │  1.781 % │ 2.024 % │  1.275 % │     1.942 % │\n",
      "│    CVX │  4.525 % │   4.41 % │  5.338 % │ 6.436 % │  3.246 % │    11.606 % │\n",
      "│     GE │  1.924 % │  2.356 % │  2.923 % │ 3.423 % │  1.387 % │     3.284 % │\n",
      "│     HD │  2.386 % │  2.995 % │  3.629 % │ 4.244 % │  1.763 % │     4.071 % │\n",
      "│    JNJ │ 10.746 % │  7.487 % │ 10.587 % │ 7.821 % │ 10.413 % │     6.708 % │\n",
      "│    JPM │  2.623 % │  5.682 % │  4.153 % │ 4.666 % │  3.345 % │     4.476 % │\n",
      "│     KO │  13.86 % │  7.188 % │  9.593 % │ 7.509 % │ 13.431 % │     9.748 % │\n",
      "│    LLY │  4.388 % │  7.217 % │  4.727 % │ 7.539 % │  4.253 % │     2.739 % │\n",
      "│    MRK │  8.205 % │   7.77 % │  8.283 % │ 8.117 % │  7.951 % │     5.122 % │\n",
      "│   MSFT │  1.886 % │    4.4 % │  3.008 % │ 3.356 % │   2.59 % │     3.219 % │\n",
      "│    PEP │ 14.175 % │  6.616 % │  9.727 % │ 6.911 % │ 13.736 % │     9.969 % │\n",
      "│    PFE │  4.473 % │   5.51 % │  4.639 % │ 5.756 % │  4.334 % │     2.792 % │\n",
      "│      ⋮ │        ⋮ │        ⋮ │        ⋮ │       ⋮ │        ⋮ │           ⋮ │\n",
      "└────────┴──────────┴──────────┴──────────┴─────────┴──────────┴─────────────┘\n",
      "                                                                5 rows omitted\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "clr = clusterise(ClustersEstimator(; alg = DBHT()), pr.X)\n",
    "r = [Variance(), NegativeSkewness(; settings = RiskMeasureSettings(; scale = 0.1))]\n",
    "\n",
    "results = [optimise(HierarchicalEqualRiskContribution(; ri = r[1],# inner (intra-cluster) risk measure\n",
    "                                                      ro = r[1],# outer (inter-cluster) risk measure\n",
    "                                                      opt = HierarchicalOptimiser(; pr = pr,\n",
    "                                                                                  clr = clr))),\n",
    "           optimise(HierarchicalEqualRiskContribution(; ri = r[2], ro = r[2],\n",
    "                                                      opt = HierarchicalOptimiser(; pr = pr,\n",
    "                                                                                  clr = clr))),\n",
    "           optimise(HierarchicalEqualRiskContribution(; ri = r, ro = r,#\n",
    "                                                      scai = SumScalariser(),# inner (intra-cluster)\n",
    "                                                      scao = SumScalariser(),# outer (inter-cluster)\n",
    "                                                      opt = HierarchicalOptimiser(; pr = pr,\n",
    "                                                                                  clr = clr))),\n",
    "           optimise(HierarchicalEqualRiskContribution(; ri = r, ro = r,\n",
    "                                                      scai = MaxScalariser(),\n",
    "                                                      scao = MaxScalariser(),\n",
    "                                                      opt = HierarchicalOptimiser(; pr = pr,\n",
    "                                                                                  clr = clr))),\n",
    "           optimise(HierarchicalEqualRiskContribution(; ri = r, ro = r,\n",
    "                                                      scai = MinScalariser(),\n",
    "                                                      scao = MinScalariser(),\n",
    "                                                      opt = HierarchicalOptimiser(; pr = pr,\n",
    "                                                                                  clr = clr))),\n",
    "           optimise(HierarchicalEqualRiskContribution(; ri = r, ro = r,\n",
    "                                                      scai = LogSumExpScalariser(),\n",
    "                                                      scao = LogSumExpScalariser(),\n",
    "                                                      opt = HierarchicalOptimiser(; pr = pr,\n",
    "                                                                                  clr = clr)))]\n",
    "\n",
    "pretty_table(DataFrame(:assets => rd.nx, :variance => results[1].w,\n",
    "                       :neg_skew => results[2].w, :sum_sca => results[3].w,\n",
    "                       :max_sca => results[4].w, :min_sca => results[5].w,\n",
    "                       :log_sum_exp => results[6].w); formatters = [resfmt])"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "When the weights are different enough that one risk measure domintes over the other in all contexts, then the results of the max and min scalarisers will be as expected, i.e. they will be as if only one risk measure was used."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────┬──────────┬──────────┬─────────┬─────────┬──────────┬─────────────┐\n",
      "│ assets │ variance │ neg_skew │ sum_sca │ max_sca │  min_sca │ log_sum_exp │\n",
      "│ String │  Float64 │  Float64 │ Float64 │ Float64 │  Float64 │     Float64 │\n",
      "├────────┼──────────┼──────────┼─────────┼─────────┼──────────┼─────────────┤\n",
      "│   AAPL │  1.847 % │  4.367 % │ 3.946 % │ 4.367 % │  1.847 % │     3.155 % │\n",
      "│    AMD │  0.627 % │    2.3 % │  1.73 % │   2.3 % │  0.627 % │      1.07 % │\n",
      "│    BAC │  2.221 % │  6.575 % │ 5.377 % │ 6.575 % │  2.221 % │     3.792 % │\n",
      "│    BBY │  1.138 % │  2.166 % │ 2.181 % │ 2.166 % │  1.138 % │     1.943 % │\n",
      "│    CVX │  4.525 % │   4.41 % │ 4.959 % │  4.41 % │  4.525 % │    11.589 % │\n",
      "│     GE │  1.924 % │  2.356 % │ 3.063 % │ 2.356 % │  1.924 % │     3.286 % │\n",
      "│     HD │  2.386 % │  2.995 % │ 3.833 % │ 2.995 % │  2.386 % │     4.074 % │\n",
      "│    JNJ │ 10.746 % │  7.487 % │ 8.942 % │ 7.487 % │ 10.746 % │     6.714 % │\n",
      "│    JPM │  2.623 % │  5.682 % │ 5.356 % │ 5.682 % │  2.623 % │     4.479 % │\n",
      "│     KO │  13.86 % │  7.188 % │ 7.697 % │ 7.188 % │  13.86 % │     9.745 % │\n",
      "│    LLY │  4.388 % │  7.217 % │  5.76 % │ 7.217 % │  4.388 % │     2.742 % │\n",
      "│    MRK │  8.205 % │   7.77 % │ 7.869 % │  7.77 % │  8.205 % │     5.127 % │\n",
      "│   MSFT │  1.886 % │    4.4 % │ 4.002 % │   4.4 % │  1.886 % │     3.221 % │\n",
      "│    PEP │ 14.175 % │  6.616 % │ 7.491 % │ 6.616 % │ 14.175 % │     9.967 % │\n",
      "│    PFE │  4.473 % │   5.51 % │ 4.935 % │  5.51 % │  4.473 % │     2.795 % │\n",
      "│      ⋮ │        ⋮ │        ⋮ │       ⋮ │       ⋮ │        ⋮ │           ⋮ │\n",
      "└────────┴──────────┴──────────┴─────────┴─────────┴──────────┴─────────────┘\n",
      "                                                               5 rows omitted\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "r = [Variance(), NegativeSkewness()]\n",
    "\n",
    "results = [optimise(HierarchicalEqualRiskContribution(; ri = r[1],# inner (intra-cluster) risk measure\n",
    "                                                      ro = r[1],# outer (inter-cluster) risk measure\n",
    "                                                      opt = HierarchicalOptimiser(; pr = pr,\n",
    "                                                                                  clr = clr))),\n",
    "           optimise(HierarchicalEqualRiskContribution(; ri = r[2], ro = r[2],\n",
    "                                                      opt = HierarchicalOptimiser(; pr = pr,\n",
    "                                                                                  clr = clr))),\n",
    "           optimise(HierarchicalEqualRiskContribution(; ri = r, ro = r,#\n",
    "                                                      scai = SumScalariser(),# inner (intra-cluster)\n",
    "                                                      scao = SumScalariser(),# outer (inter-cluster)\n",
    "                                                      opt = HierarchicalOptimiser(; pr = pr,\n",
    "                                                                                  clr = clr))),\n",
    "           optimise(HierarchicalEqualRiskContribution(; ri = r, ro = r,\n",
    "                                                      scai = MaxScalariser(),\n",
    "                                                      scao = MaxScalariser(),\n",
    "                                                      opt = HierarchicalOptimiser(; pr = pr,\n",
    "                                                                                  clr = clr))),\n",
    "           optimise(HierarchicalEqualRiskContribution(; ri = r, ro = r,\n",
    "                                                      scai = MinScalariser(),\n",
    "                                                      scao = MinScalariser(),\n",
    "                                                      opt = HierarchicalOptimiser(; pr = pr,\n",
    "                                                                                  clr = clr))),\n",
    "           optimise(HierarchicalEqualRiskContribution(; ri = r, ro = r,\n",
    "                                                      scai = LogSumExpScalariser(),\n",
    "                                                      scao = LogSumExpScalariser(),\n",
    "                                                      opt = HierarchicalOptimiser(; pr = pr,\n",
    "                                                                                  clr = clr)))]\n",
    "\n",
    "pretty_table(DataFrame(:assets => rd.nx, :variance => results[1].w,\n",
    "                       :neg_skew => results[2].w, :sum_sca => results[3].w,\n",
    "                       :max_sca => results[4].w, :min_sca => results[5].w,\n",
    "                       :log_sum_exp => results[6].w); formatters = [resfmt])"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note how the max scalariser produced the same weights as the negative skewness and the min scalariser produced the same weights as the variance. This is because in all cases, the same the value of the negative skewness was greater than that of the variance. A similar behaviour can be observed with other clustering optimisers. [`NearOptimalCentering`]-(@ref) can also have unintuitive behaviour when computing the risk bounds with an effective frontier `MaxScalariser` and `MinScalariser` due to the fact that each point in the efficient frontier can have a different risk measure dominating the others."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.4"
  },
  "kernelspec": {
   "name": "julia-1.12",
   "display_name": "Julia 1.12.4",
   "language": "julia"
  }
 },
 "nbformat": 4
}
