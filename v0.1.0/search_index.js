var documenterSearchIndex = {"docs":
[{"location":"007-21-Moments/#Implied-Volatility","page":"Implied Volatility","title":"Implied Volatility","text":"","category":"section"},{"location":"007-12-Moments/#PortfolioOptimisersCovariance","page":"PortfolioOptimisersCovariance","title":"PortfolioOptimisersCovariance","text":"","category":"section"},{"location":"007-12-Moments/#PortfolioOptimisers.PortfolioOptimisersCovariance","page":"PortfolioOptimisersCovariance","title":"PortfolioOptimisers.PortfolioOptimisersCovariance","text":"struct PortfolioOptimisersCovariance{T1, T2} <: AbstractCovarianceEstimator\n    ce::T1\n    mp::T2\nend\n\nComposite covariance estimator with post-processing.\n\nPortfolioOptimisersCovariance is a flexible container type that combines any covariance estimator with a matrix post-processing step. This enables users to apply additional transformations or corrections (such as shrinkage, regularisation, or projection to positive definite) to the covariance or correlation matrix after it is estimated.\n\nFields\n\nce: The underlying covariance estimator.\nmp: Matrix post-processing estimator.\n\nConstructor\n\nPortfolioOptimisersCovariance(; ce::AbstractCovarianceEstimator = Covariance(),\n                               mp::AbstractMatrixProcessingEstimator = DefaultMatrixProcessing())\n\nCreates a PortfolioOptimisersCovariance object with the specified covariance estimator and matrix processing step.\n\nRelated\n\nAbstractCovarianceEstimator\nAbstractMatrixProcessingEstimator\n\n\n\n\n\n","category":"type"},{"location":"007-12-Moments/#PortfolioOptimisers.PortfolioOptimisersCovariance-Tuple{}","page":"PortfolioOptimisersCovariance","title":"PortfolioOptimisers.PortfolioOptimisersCovariance","text":"PortfolioOptimisersCovariance(; ce::AbstractCovarianceEstimator = Covariance(),\n                               mp::AbstractMatrixProcessingEstimator = DefaultMatrixProcessing())\n\nConstruct a PortfolioOptimisersCovariance estimator that applies a matrix post-processing step to the output of any covariance estimator.\n\nThis constructor creates a PortfolioOptimisersCovariance object using the specified covariance estimator and matrix processing estimator. The resulting object can be used as a drop-in replacement for any covariance estimator, with the added benefit of post-processing (such as shrinkage, regularisation, or projection to positive definite).\n\nArguments\n\nce: Covariance estimator to use.\nmp: Matrix post-processing estimator.\n\nReturns\n\nPortfolioOptimisersCovariance: A composite covariance estimator with post-processing.\n\nExamples\n\njulia> ce = PortfolioOptimisersCovariance()\nPortfolioOptimisersCovariance\n  ce | Covariance\n     |    me | SimpleExpectedReturns\n     |       |   w | nothing\n     |    ce | GeneralWeightedCovariance\n     |       |   ce | StatsBase.SimpleCovariance: StatsBase.SimpleCovariance(true)\n     |       |    w | nothing\n     |   alg | Full()\n  mp | DefaultMatrixProcessing\n     |       pdm | Posdef\n     |           |   alg | UnionAll: NearestCorrelationMatrix.Newton\n     |   denoise | nothing\n     |    detone | nothing\n     |       alg | nothing\n\nRelated\n\nPortfolioOptimisersCovariance\nAbstractCovarianceEstimator\nCovariance\nAbstractMatrixProcessingEstimator\nDefaultMatrixProcessing\n\n\n\n\n\n","category":"method"},{"location":"007-12-Moments/#Statistics.cov-Tuple{PortfolioOptimisersCovariance, AbstractMatrix}","page":"PortfolioOptimisersCovariance","title":"Statistics.cov","text":"cov(ce::PortfolioOptimisersCovariance, X::AbstractMatrix; dims = 1, kwargs...)\n\nCompute the covariance matrix with post-processing using a PortfolioOptimisersCovariance estimator.\n\nThis method computes the covariance matrix for the input data matrix X using the underlying covariance estimator in ce, and then applies the matrix post-processing step specified by ce.mp. This enables workflows such as shrinkage, regularisation, or projection to positive definite after covariance estimation.\n\nArguments\n\nce: Composite covariance estimator with post-processing.\nX: Data matrix of asset returns (observations × assets).\ndims: Dimension along which to compute the covariance (1 = columns/assets, 2 = rows). Default is 1.\nkwargs...: Additional keyword arguments passed to the underlying covariance estimator and matrix processing step.\n\nReturns\n\nsigma::Matrix{<:Real}: The processed covariance matrix.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nRelated\n\nPortfolioOptimisersCovariance\nmatrix_processing!\nStatistics.cov\n\n\n\n\n\n","category":"method"},{"location":"007-12-Moments/#Statistics.cor-Tuple{PortfolioOptimisersCovariance, AbstractMatrix}","page":"PortfolioOptimisersCovariance","title":"Statistics.cor","text":"cor(ce::PortfolioOptimisersCovariance, X::AbstractMatrix; dims = 1, kwargs...)\n\nCompute the correlation matrix with post-processing using a PortfolioOptimisersCovariance estimator.\n\nThis method computes the correlation matrix for the input data matrix X using the underlying covariance estimator in ce, and then applies the matrix post-processing step specified by ce.mp. This enables workflows such as shrinkage, regularisation, or projection to positive definite after correlation estimation.\n\nArguments\n\nce: Composite covariance estimator with post-processing.\nX: Data matrix of asset returns (observations × assets).\ndims: Dimension along which to compute the correlation (1 = columns/assets, 2 = rows). Default is 1.\nkwargs...: Additional keyword arguments passed to the underlying covariance estimator and matrix processing step.\n\nReturns\n\nrho::Matrix{<:Real}: The processed correlation matrix.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nRelated\n\nPortfolioOptimisersCovariance\nmatrix_processing!\nStatistics.cor\n\n\n\n\n\n","category":"method"},{"location":"007-19-Moments/#Stepwise-Regression","page":"Stepwise Regression","title":"Stepwise Regression","text":"","category":"section"},{"location":"007-19-Moments/#PortfolioOptimisers.PValue","page":"Stepwise Regression","title":"PortfolioOptimisers.PValue","text":"struct PValue{T1} <: AbstractStepwiseRegressionCriterion\n    threshold::T1\nend\n\nStepwise regression criterion based on p-value thresholding.\n\nPValue is used as a criterion for stepwise regression algorithms, where variables are included or excluded from the model based on their statistical significance (p-value). The threshold field specifies the maximum p-value for a variable to be considered significant and included in the model.\n\nFields\n\nthreshold: The p-value threshold for variable inclusion.\n\nRelated\n\nAbstractStepwiseRegressionCriterion\nStepwiseRegression\n\n\n\n\n\n","category":"type"},{"location":"007-19-Moments/#PortfolioOptimisers.PValue-Tuple{}","page":"Stepwise Regression","title":"PortfolioOptimisers.PValue","text":"PValue(; threshold::Real = 0.05)\n\nConstruct a PValue stepwise regression criterion.\n\nThis constructor creates a PValue object with the specified p-value threshold.\n\nArguments\n\nthreshold: The p-value threshold for variable inclusion.\n\nReturns\n\nPValue: A p-value-based stepwise regression criterion.\n\nValidation\n\nAsserts that 0 < threshold < 1.\n\nExamples\n\njulia> PValue()\nPValue\n  threshold | Float64: 0.05\n\nRelated\n\nPValue\nStepwiseRegression\n\n\n\n\n\n","category":"method"},{"location":"007-19-Moments/#PortfolioOptimisers.Forward","page":"Stepwise Regression","title":"PortfolioOptimisers.Forward","text":"struct Forward <: AbstractStepwiseRegressionAlgorithm end\n\nStepwise regression algorithm: forward selection.\n\nForward specifies the forward selection strategy for stepwise regression. In forward selection, variables are added to the model one at a time based on a criterion (such as p-value or information criterion), starting from an empty model and including the variable that most improves the model at each step. The process continues until no further improvement is possible or a stopping criterion is met.\n\nRelated\n\nAbstractStepwiseRegressionAlgorithm\nBackward\nStepwiseRegression\n\n\n\n\n\n","category":"type"},{"location":"007-19-Moments/#PortfolioOptimisers.Backward","page":"Stepwise Regression","title":"PortfolioOptimisers.Backward","text":"struct Backward <: AbstractStepwiseRegressionAlgorithm end\n\nStepwise regression algorithm: backward elimination.\n\nBackward specifies the backward elimination strategy for stepwise regression. In backward elimination, all candidate variables are initially included in the model, and variables are removed one at a time based on a criterion (such as p-value or information criterion). At each step, the variable whose removal most improves the model (or least degrades it) is excluded, until no further improvement is possible or a stopping criterion is met.\n\nRelated\n\nAbstractStepwiseRegressionAlgorithm\nForward\nStepwiseRegression\n\n\n\n\n\n","category":"type"},{"location":"007-19-Moments/#PortfolioOptimisers.StepwiseRegression","page":"Stepwise Regression","title":"PortfolioOptimisers.StepwiseRegression","text":"struct StepwiseRegression{T1, T2, T3} <: AbstractRegressionEstimator\n    crit::T1\n    alg::T2\n    target::T3\nend\n\nEstimator for stepwise regression-based moment estimation.\n\nStepwiseRegression is a flexible estimator type for performing stepwise regression, supporting both forward selection and backward elimination strategies. It allows users to specify the criterion for variable selection (such as p-value, AIC, BIC, or R²), the stepwise algorithm, and the regression target (e.g., linear or generalised linear models).\n\nFields\n\ncrit: Criterion for variable selection.\nalg: Stepwise algorithm.\ntarget: Regression target type.\n\nConstructor\n\nStepwiseRegression(; crit::AbstractStepwiseRegressionCriterion = PValue(),\n                    alg::AbstractStepwiseRegressionAlgorithm = Forward(),\n                    target::AbstractRegressionTarget = LinearModel())\n\nRelated\n\nAbstractStepwiseRegressionCriterion\nAbstractStepwiseRegressionAlgorithm\nAbstractRegressionTarget\n\n\n\n\n\n","category":"type"},{"location":"007-19-Moments/#PortfolioOptimisers.StepwiseRegression-Tuple{}","page":"Stepwise Regression","title":"PortfolioOptimisers.StepwiseRegression","text":"StepwiseRegression(; crit::AbstractStepwiseRegressionCriterion = PValue(),\n                    alg::AbstractStepwiseRegressionAlgorithm = Forward(),\n                    target::AbstractRegressionTarget = LinearModel())\n\nConstruct a StepwiseRegression estimator for stepwise regression-based moment estimation.\n\nThis constructor creates a StepwiseRegression object with the specified criterion, algorithm, and regression target.\n\nArguments\n\ncrit: Criterion for variable selection.\nalg: Stepwise algorithm.\ntarget: Regression target type.\n\nReturns\n\nStepwiseRegression: A configured stepwise regression estimator.\n\nExamples\n\njulia> StepwiseRegression()\nStepwiseRegression\n    crit | PValue\n         |   threshold | Float64: 0.05\n     alg | Forward()\n  target | LinearModel\n         |   kwargs | @NamedTuple{}: NamedTuple()\n\nRelated\n\nAbstractStepwiseRegressionCriterion\nAbstractStepwiseRegressionAlgorithm\nAbstractRegressionTarget\n\n\n\n\n\n","category":"method"},{"location":"007-19-Moments/#PortfolioOptimisers.add_best_asset_after_failure_pval!","page":"Stepwise Regression","title":"PortfolioOptimisers.add_best_asset_after_failure_pval!","text":"add_best_asset_after_failure_pval!(target::AbstractRegressionTarget,\n                                  included::AbstractVector,\n                                  F::AbstractMatrix,\n                                  x::AbstractVector)\n\nHelper for stepwise regression: add the \"best\" asset by p-value if no variables are included.\n\nThis function is used in stepwise regression routines when no variables meet the p-value threshold for inclusion. It scans all excluded variables, fits a regression for each, and selects the variable with the lowest p-value (even if above the threshold). The index of this variable is pushed to included, ensuring the model always includes at least one variable.\n\nArguments\n\ntarget: Regression target type (e.g., LinearModel()).\nincluded: Indices of currently included variables (modified in-place).\nF: Factor matrix (features × observations).\nx: Response vector.\n\nReturns\n\nnothing: Modifies included in-place.\n\nDetails\n\nIf included is not empty, the function does nothing. Otherwise, it evaluates each excluded variable by fitting a regression and extracting its p-value, then adds the variable with the lowest p-value to included. A warning is issued if no variable meets the threshold.\n\nRelated\n\nStepwiseRegression\nregression\n\n\n\n\n\n","category":"function"},{"location":"007-19-Moments/#PortfolioOptimisers.regression-Tuple{StepwiseRegression{<:PValue, <:Forward}, AbstractVector, AbstractMatrix}","page":"Stepwise Regression","title":"PortfolioOptimisers.regression","text":"regression(re::StepwiseRegression{<:PValue, <:Forward}, x::AbstractVector, F::AbstractMatrix)\n\nPerform forward stepwise regression using a p-value criterion.\n\nThis method implements forward selection for stepwise regression, where variables (columns of F) are added to the model one at a time based on their statistical significance (p-value), starting from an empty model. At each step, the variable with the lowest p-value (and all p-values below the specified threshold) is added. The process continues until no remaining variable meets the p-value threshold. If no variable meets the threshold at any step, the variable with the lowest p-value is included to ensure at least one variable is selected.\n\nArguments\n\nre: Stepwise regression estimator with a PValue criterion and Forward algorithm.\nx: Response vector.\nF: Feature matrix (observations × variables).\n\nReturns\n\nincluded::Vector{Int}: Indices of variables selected by the forward stepwise regression.\n\nDetails\n\nAt each iteration, the method fits a regression model for each excluded variable, computes p-values, and adds the variable with the lowest p-value if it is below the threshold.\nIf no variable meets the threshold, the variable with the lowest p-value is included (see add_best_asset_after_failure_pval!).\nThe process stops when no further variables can be added under the criterion.\n\nRelated\n\nStepwiseRegression\nPValue\nForward\nadd_best_asset_after_failure_pval!\n\n\n\n\n\n","category":"method"},{"location":"007-19-Moments/#PortfolioOptimisers.get_forward_reg_incl_excl!-Tuple{PortfolioOptimisers.AbstractMinValStepwiseRegressionCriterion, AbstractVector, AbstractVector, AbstractVector, Real}","page":"Stepwise Regression","title":"PortfolioOptimisers.get_forward_reg_incl_excl!","text":"get_forward_reg_incl_excl!(::AbstractMinValStepwiseRegressionCriterion,\n                           value::AbstractVector,\n                           excluded::AbstractVector,\n                           included::AbstractVector,\n                           threshold::Real)\n\nHelper for forward stepwise regression with minimum-value criteria (e.g., p-value, AIC).\n\nThis function updates the included and excluded variable sets in forward stepwise regression when the selection criterion is minimized (such as p-value or AIC). It finds the variable among excluded with the lowest value, and if this value is less than the current threshold, moves it from excluded to included and updates the threshold.\n\nArguments\n\n::AbstractMinValStepwiseRegressionCriterion: Stepwise regression criterion type where lower values are better.\nvalue: Vector of criterion values for each variable.\nexcluded: Indices of currently excluded variables (modified in-place).\nincluded: Indices of currently included variables (modified in-place).\nthreshold: Current threshold value for inclusion.\n\nReturns\n\nthreshold::Real: Updated threshold value after inclusion (if any).\n\nDetails\n\nFinds the variable in excluded with the minimum value in value.\nIf this value is less than threshold, moves the variable from excluded to included and updates threshold.\nIf no variable meets the criterion, the sets remain unchanged and the threshold is not updated.\n\nRelated\n\nStepwiseRegression\nAbstractMinValStepwiseRegressionCriterion\nregression\n\n\n\n\n\n","category":"method"},{"location":"007-19-Moments/#PortfolioOptimisers.get_forward_reg_incl_excl!-Tuple{PortfolioOptimisers.AbstractMaxValStepwiseRegressionCriteria, AbstractVector, AbstractVector, AbstractVector, Real}","page":"Stepwise Regression","title":"PortfolioOptimisers.get_forward_reg_incl_excl!","text":"get_forward_reg_incl_excl!(::AbstractMaxValStepwiseRegressionCriteria,\n                           value::AbstractVector,\n                           excluded::AbstractVector,\n                           included::AbstractVector,\n                           threshold::Real)\n\nHelper for forward stepwise regression with maximum-value criteria (e.g., R²).\n\nThis function updates the included and excluded variable sets in forward stepwise regression when the selection criterion is maximized (such as R²). It finds the variable among excluded with the highest value, and if this value is greater than the current threshold, moves it from excluded to included and updates the threshold.\n\nArguments\n\n::AbstractMaxValStepwiseRegressionCriteria: Stepwise regression criterion type where higher values are better.\nvalue: Vector of criterion values for each variable.\nexcluded: Indices of currently excluded variables (modified in-place).\nincluded: Indices of currently included variables (modified in-place).\nthreshold: Current threshold value for inclusion.\n\nReturns\n\nthreshold::Real: Updated threshold value after inclusion (if any).\n\nDetails\n\nFinds the variable in excluded with the maximum value in value.\nIf this value is greater than threshold, moves the variable from excluded to included and updates threshold.\nIf no variable meets the criterion, the sets remain unchanged and the threshold is not updated.\n\nRelated\n\nStepwiseRegression\nAbstractMaxValStepwiseRegressionCriteria\nregression\n\n\n\n\n\n","category":"method"},{"location":"007-19-Moments/#PortfolioOptimisers.regression-Tuple{StepwiseRegression{<:Union{var\"#s15\", var\"#s14\"} where {var\"#s15\"<:PortfolioOptimisers.AbstractMinValStepwiseRegressionCriterion, var\"#s14\"<:PortfolioOptimisers.AbstractMaxValStepwiseRegressionCriteria}, <:Forward}, AbstractVector, AbstractMatrix}","page":"Stepwise Regression","title":"PortfolioOptimisers.regression","text":"regression(re::StepwiseRegression{<:Union{<:AbstractMinValStepwiseRegressionCriterion,\n                                          <:AbstractMaxValStepwiseRegressionCriteria},\n                                  <:Forward},\n           x::AbstractVector, F::AbstractMatrix)\n\nPerform forward stepwise regression using a general criterion (minimization or maximization).\n\nThis method implements forward selection for stepwise regression, where variables (columns of F) are added to the model one at a time based on a user-specified criterion. The criterion can be either minimized (e.g., p-value, AIC) or maximized (e.g., R²). At each step, the variable with the best criterion value (lowest for minimization, highest for maximization) is considered for inclusion if it improves upon the current threshold. The process continues until no remaining variable meets the criterion for inclusion.\n\nArguments\n\nre: Stepwise regression estimator with a minimization or maximization criterion and Forward algorithm.\nx: Response vector.\nF: Feature matrix (observations × variables).\n\nReturns\n\nincluded::Vector{Int}: Indices of variables selected by the forward stepwise regression.\n\nDetails\n\nAt each iteration, the method fits a regression model for each excluded variable, computes the criterion value, and adds the variable with the best value if it improves upon the current threshold.\nThe process stops when no further variables can be added under the criterion.\nThe criterion function and threshold are determined by the estimator's crit field.\nSupports both minimization and maximization criteria via dispatch.\n\nRelated\n\nStepwiseRegression\nAbstractMinValStepwiseRegressionCriterion\nAbstractMaxValStepwiseRegressionCriteria\nForward\nget_forward_reg_incl_excl!\n\n\n\n\n\n","category":"method"},{"location":"007-19-Moments/#PortfolioOptimisers.regression-Tuple{StepwiseRegression{<:PValue, <:Backward}, AbstractVector, AbstractMatrix}","page":"Stepwise Regression","title":"PortfolioOptimisers.regression","text":"regression(re::StepwiseRegression{<:PValue, <:Backward}, x::AbstractVector, F::AbstractMatrix)\n\nPerform backward stepwise regression using a p-value criterion.\n\nThis method implements backward elimination for stepwise regression, where all variables (columns of F) are initially included in the model. At each step, the variable with the highest p-value is considered for removal if its p-value exceeds the specified threshold. The process continues until all remaining variables have p-values below the threshold. If all variables are excluded, the variable with the lowest p-value is included to ensure at least one variable is selected.\n\nArguments\n\nre: Stepwise regression estimator with a PValue criterion and Backward algorithm.\nx: Response vector.\nF: Feature matrix (observations × variables).\n\nReturns\n\nincluded::Vector{Int}: Indices of variables selected by the backward stepwise regression.\n\nDetails\n\nStarts with all variables included.\nAt each iteration, fits a regression model and computes p-values for all included variables.\nRemoves the variable with the highest p-value if it exceeds the threshold.\nStops when all included variables have p-values below the threshold or no variables remain.\nIf all variables are excluded, the variable with the lowest p-value is included (see add_best_asset_after_failure_pval!).\n\nRelated\n\nStepwiseRegression\nPValue\nBackward\nadd_best_asset_after_failure_pval!\n\n\n\n\n\n","category":"method"},{"location":"007-19-Moments/#PortfolioOptimisers.get_backward_reg_incl!-Tuple{PortfolioOptimisers.AbstractMinValStepwiseRegressionCriterion, AbstractVector, AbstractVector, Real}","page":"Stepwise Regression","title":"PortfolioOptimisers.get_backward_reg_incl!","text":"get_backward_reg_incl!(::AbstractMinValStepwiseRegressionCriterion,\n                       value::AbstractVector,\n                       included::AbstractVector,\n                       threshold::Real)\n\nHelper for backward stepwise regression with minimum-value criteria (e.g., p-value, AIC).\n\nThis function updates the included variable set in backward stepwise regression when the selection criterion is minimized (such as p-value or AIC). It finds the variable among included with the lowest value, and if this value is less than the current threshold, removes it from included and updates the threshold.\n\nArguments\n\n::AbstractMinValStepwiseRegressionCriterion: Stepwise regression criterion type where lower values are better.\nvalue: Vector of criterion values for each variable.\nincluded: Indices of currently included variables (modified in-place).\nthreshold: Current threshold value for exclusion.\n\nReturns\n\nthreshold::Real: Updated threshold value after exclusion (if any).\n\nDetails\n\nFinds the variable in included with the minimum value in value.\nIf this value is less than threshold, removes the variable from included and updates threshold.\nIf no variable meets the criterion, the set remains unchanged and the threshold is not updated.\n\nRelated\n\nStepwiseRegression\nregression\n\n\n\n\n\n","category":"method"},{"location":"007-19-Moments/#PortfolioOptimisers.get_backward_reg_incl!-Tuple{PortfolioOptimisers.AbstractMaxValStepwiseRegressionCriteria, AbstractVector, AbstractVector, Real}","page":"Stepwise Regression","title":"PortfolioOptimisers.get_backward_reg_incl!","text":"get_backward_reg_incl!(::AbstractMaxValStepwiseRegressionCriteria,\n                       value::AbstractVector,\n                       included::AbstractVector,\n                       threshold::Real)\n\nHelper for backward stepwise regression with maximum-value criteria (e.g., R²).\n\nThis function updates the included variable set in backward stepwise regression when the selection criterion is maximized (such as R²). It finds the variable among included with the highest value, and if this value is greater than the current threshold, removes it from included and updates the threshold.\n\nArguments\n\n::AbstractMaxValStepwiseRegressionCriteria: Stepwise regression criterion type where higher values are better.\nvalue: Vector of criterion values for each variable.\nincluded: Indices of currently included variables (modified in-place).\nthreshold: Current threshold value for exclusion.\n\nReturns\n\nthreshold::Real: Updated threshold value after exclusion (if any).\n\nDetails\n\nFinds the variable in included with the maximum value in value.\nIf this value is greater than threshold, removes the variable from included and updates threshold.\nIf no variable meets the criterion, the set remains unchanged and the threshold is not updated.\n\nRelated\n\nStepwiseRegression\nregression\n\n\n\n\n\n","category":"method"},{"location":"007-19-Moments/#PortfolioOptimisers.regression-Tuple{StepwiseRegression{<:Union{var\"#s15\", var\"#s14\"} where {var\"#s15\"<:PortfolioOptimisers.AbstractMinValStepwiseRegressionCriterion, var\"#s14\"<:PortfolioOptimisers.AbstractMaxValStepwiseRegressionCriteria}, <:Backward}, AbstractVector, AbstractMatrix}","page":"Stepwise Regression","title":"PortfolioOptimisers.regression","text":"regression(re::StepwiseRegression{<:Union{<:AbstractMinValStepwiseRegressionCriterion,\n                                          <:AbstractMaxValStepwiseRegressionCriteria},\n                                  <:Backward},\n           x::AbstractVector, F::AbstractMatrix)\n\nPerform backward stepwise regression using a general criterion (minimization or maximization).\n\nThis method implements backward elimination for stepwise regression, where all variables (columns of F) are initially included in the model. At each step, the variable with the worst criterion value (highest for minimization, lowest for maximization) is considered for removal if it does not meet the specified threshold. The process continues until all remaining variables satisfy the criterion for inclusion.\n\nArguments\n\nre: Stepwise regression estimator with a minimization or maximization criterion and Backward algorithm.\nx: Response vector.\nF: Feature matrix (observations × variables).\n\nReturns\n\nincluded::Vector{Int}: Indices of variables selected by the backward stepwise regression.\n\nDetails\n\nStarts with all variables included.\nAt each iteration, fits a regression model for all included variables, computes the criterion value for each, and removes the variable with the worst value if it does not meet the threshold.\nThe criterion function and threshold are determined by the estimator's crit field.\nThe process stops when all included variables satisfy the criterion or no variables remain.\nSupports both minimization and maximization criteria via dispatch.\n\nRelated\n\nStepwiseRegression\nAbstractMinValStepwiseRegressionCriterion\nAbstractMaxValStepwiseRegressionCriteria\nBackward\nget_backward_reg_incl!\n\n\n\n\n\n","category":"method"},{"location":"007-19-Moments/#PortfolioOptimisers.regression-Tuple{StepwiseRegression, AbstractMatrix, AbstractMatrix}","page":"Stepwise Regression","title":"PortfolioOptimisers.regression","text":"regression(re::StepwiseRegression, X::AbstractMatrix, F::AbstractMatrix)\n\nApply stepwise regression to each column of a response matrix.\n\nThis method fits a stepwise regression model (as specified by re) to each column of the response matrix X, using the feature matrix F as predictors. For each response vector (column of X), the function selects variables via stepwise regression, fits the final model, and stores the estimated intercept and coefficients in the result.\n\nArguments\n\nre: Stepwise regression estimator specifying the criterion, algorithm, and regression target.\nX: Asset returns matrix (observations × assets).\nF: Factor returns matrix (observations × factors or features).\n\nReturns\n\nRegression: A regression result object containing:\nb: Vector of intercepts for each asset.\nM: Matrix of coefficients for each asset and feature (zeros for excluded features).\n\nDetails\n\nFor each column in X, stepwise regression is performed using the specified criterion and algorithm.\nOnly the features selected by the stepwise procedure are included in the final model for each response.\nThe output Regression object contains the intercepts and a coefficient matrix with zeros for features not selected for each response.\n\nRelated\n\nStepwiseRegression\nregression\nRegression\n\n\n\n\n\n","category":"method"},{"location":"007-11-Moments/#Mutual-Information-Covariance","page":"Mutual Information Covariance","title":"Mutual Information Covariance","text":"","category":"section"},{"location":"007-11-Moments/#PortfolioOptimisers.MutualInfoCovariance","page":"Mutual Information Covariance","title":"PortfolioOptimisers.MutualInfoCovariance","text":"struct MutualInfoCovariance{T1, T2, T3} <: AbstractCovarianceEstimator\n    ve::T1\n    bins::T2\n    normalise::T3\nend\n\nCovariance estimator based on mutual information.\n\nMutualInfoCovariance implements a robust covariance estimator that uses mutual information (MI) to capture both linear and nonlinear dependencies between asset returns. This estimator is particularly useful for identifying complex relationships that are not detected by traditional correlation-based methods. The MI matrix is optionally normalised and then rescaled by marginal standard deviations to produce a covariance matrix.\n\nFields\n\nve: Variance estimator used to compute marginal standard deviations.\nbins: Binning algorithm or fixed number of bins for histogram-based MI estimation.\nnormalise: Whether to normalise the MI matrix.\n\nConstructor\n\nMutualInfoCovariance(; ve::AbstractVarianceEstimator = SimpleVariance(),\n                      bins::Union{<:AbstractBins, <:Integer} = HacineGharbiRavier(),\n                      normalise::Bool = true)\n\nCreates a MutualInfoCovariance object with the specified variance estimator, binning strategy, and normalisation option.\n\nRelated\n\nAbstractVarianceEstimator\nAbstractBins\n\n\n\n\n\n","category":"type"},{"location":"007-11-Moments/#PortfolioOptimisers.MutualInfoCovariance-Tuple{}","page":"Mutual Information Covariance","title":"PortfolioOptimisers.MutualInfoCovariance","text":"MutualInfoCovariance(; ve::AbstractVarianceEstimator = SimpleVariance(),\n                      bins::Union{<:AbstractBins, <:Integer} = HacineGharbiRavier(),\n                      normalise::Bool = true)\n\nConstruct a MutualInfoCovariance estimator for robust covariance or correlation estimation using mutual information.\n\nThis constructor creates a MutualInfoCovariance object using the specified variance estimator, binning algorithm (or fixed bin count), and normalisation flag. The estimator computes the covariance matrix by combining the mutual information matrix (optionally normalised) with the marginal standard deviations.\n\nArguments\n\nve: Variance estimator.\nbins: Binning algorithm or fixed number of bins for MI estimation.\nnormalise: Whether to normalise the MI matrix.\n\nReturns\n\nMutualInfoCovariance: A configured mutual information-based covariance estimator.\n\nValidation\n\nIf bins is an integer, asserts that bins > 0.\n\nExamples\n\njulia> ce = MutualInfoCovariance()\nMutualInfoCovariance\n         ve | SimpleVariance\n            |          me | SimpleExpectedReturns\n            |             |   w | nothing\n            |           w | nothing\n            |   corrected | Bool: true\n       bins | HacineGharbiRavier()\n  normalise | Bool: true\n\nRelated\n\nMutualInfoCovariance\nAbstractVarianceEstimator\nAbstractBins\n\n\n\n\n\n","category":"method"},{"location":"007-11-Moments/#Statistics.cor-Tuple{MutualInfoCovariance, AbstractMatrix}","page":"Mutual Information Covariance","title":"Statistics.cor","text":"cor(ce::MutualInfoCovariance, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the mutual information (MI) correlation matrix using a MutualInfoCovariance estimator.\n\nThis method computes the pairwise mutual information correlation matrix for the input data matrix X, using the binning strategy and normalisation specified in ce. The MI correlation captures both linear and nonlinear dependencies between asset returns, making it robust to complex relationships that may not be detected by traditional correlation measures.\n\nArguments\n\nce: Mutual information-based covariance estimator.\nX: Data matrix of asset returns (observations × assets).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments (currently unused).\n\nReturns\n\nrho::Matrix{<:Real}: Symmetric matrix of mutual information-based correlation coefficients.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nRelated\n\nMutualInfoCovariance\nmutual_info\ncov(ce::MutualInfoCovariance, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"007-11-Moments/#Statistics.cov-Tuple{MutualInfoCovariance, AbstractMatrix}","page":"Mutual Information Covariance","title":"Statistics.cov","text":"cov(ce::MutualInfoCovariance, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the mutual information (MI) covariance matrix using a MutualInfoCovariance estimator.\n\nThis method computes the pairwise mutual information covariance matrix for the input data matrix X, using the binning strategy and normalisation specified in ce. The MI covariance matrix is obtained by rescaling the MI correlation matrix by the marginal standard deviations, as estimated by the variance estimator in ce.\n\nArguments\n\nce: Mutual information-based covariance estimator.\nX: Data matrix of asset returns (observations × assets).\ndims: Dimension along which to compute the covariance.\nkwargs...: Additional keyword arguments passed to the variance estimator.\n\nReturns\n\nsigma::Matrix{<:Real}: Symmetric matrix of mutual information-based covariances.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nExamples\n\nRelated\n\nMutualInfoCovariance\nmutual_info\ncor(ce::MutualInfoCovariance, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"009-JuMPModelOptimisation/#JuMP-Model-Optimisation","page":"JuMP Model Optimisation","title":"JuMP Model Optimisation","text":"","category":"section"},{"location":"009-JuMPModelOptimisation/#PortfolioOptimisers.AbstractJuMPResult","page":"JuMP Model Optimisation","title":"PortfolioOptimisers.AbstractJuMPResult","text":"abstract type AbstractJuMPResult <: AbstractResult end\n\nAbstract supertype for all JuMP-based optimisation result types in PortfolioOptimisers.jl.\n\nAll concrete types representing the result of a JuMP model optimisation should subtype AbstractJuMPResult. This enables a consistent interface for handling solver results throughout the package.\n\nRelated\n\nJuMPResult\n\n\n\n\n\n","category":"type"},{"location":"009-JuMPModelOptimisation/#PortfolioOptimisers.Solver","page":"JuMP Model Optimisation","title":"PortfolioOptimisers.Solver","text":"struct Solver{T1, T2, T3, T4, T5} <: AbstractEstimator\n    name::T1\n    solver::T2\n    settings::T3\n    check_sol::T4\n    add_bridges::T5\nend\n\nContainer for configuring a JuMP solver and its settings.\n\nThe Solver struct encapsulates all information needed to set up and run a JuMP optimisation, including the solver backend, solver-specific settings, solution checks, and bridge options.\n\nFields\n\nname: Symbol or string identifier for the solver.\nsolver: The optimizer_factory in set_optimizer.\nsettings: Solver-specific settings used in set_attribute.\ncheck_sol: Named tuple of solution for keyword arguments in assert_is_solved_and_feasible.\nadd_bridges: The add_bridges keyword argument in set_optimizer.\n\nConstructor\n\nSolver(; name::Union{Symbol, <:AbstractString} = \"\", solver = nothing,\n         settings::Union{Nothing, <:AbstractDict, <:Pair, <:AbstractVector{<:Pair}} = nothing,\n         check_sol::NamedTuple = (;), add_bridges::Bool = true)\n\nRelated\n\noptimise_JuMP_model!\n\n\n\n\n\n","category":"type"},{"location":"009-JuMPModelOptimisation/#PortfolioOptimisers.Solver-Tuple{}","page":"JuMP Model Optimisation","title":"PortfolioOptimisers.Solver","text":"Solver(; name::Union{Symbol, <:AbstractString} = \"\", solver::Any = nothing,\n        settings::Union{Nothing, <:AbstractDict, <:Pair, <:AbstractVector{<:Pair}} = nothing,\n        check_sol::NamedTuple = (;), add_bridges::Bool = true)\n\nConstruct a Solver object for configuring a JuMP solver.\n\nThis constructor validates and packages the solver backend, settings, and options for use in model optimisation.\n\nArguments\n\nname: Symbol or string identifier for the solver.\nsolver: The optimizer_factory in set_optimizer.\nsettings: Solver-specific settings used in set_attribute.\ncheck_sol: Named tuple of solution for keyword arguments in assert_is_solved_and_feasible.\nadd_bridges: The add_bridges keyword argument in set_optimizer.\n\nReturns\n\nSolver: Configured solver object.\n\nValidation\n\nAsserts that settings is non-empty if provided as a dictionary or vector.\n\nExamples\n\njulia> Solver()\nSolver\n         name | String: \"\"\n       solver | nothing\n     settings | nothing\n    check_sol | @NamedTuple{}: NamedTuple()\n  add_bridges | Bool: true\n\n\n\n\n\n","category":"method"},{"location":"009-JuMPModelOptimisation/#PortfolioOptimisers.JuMPResult","page":"JuMP Model Optimisation","title":"PortfolioOptimisers.JuMPResult","text":"struct JuMPResult{T1, T2} <: AbstractJuMPResult\n    trials::T1\n    success::T2\nend\n\nResult type for JuMP model optimisation.\n\nThe JuMPResult struct records the outcome of a JuMP optimisation, including trial errors and success status.\n\nFields\n\ntrials: Dictionary of solver attempts and errors.\nsuccess: Boolean indicating whether optimisation succeeded.\n\nConstructor\n\nJuMPResult(; trials::AbstractDict, success::Bool)\n\nRelated\n\noptimise_JuMP_model!\n\n\n\n\n\n","category":"type"},{"location":"009-JuMPModelOptimisation/#PortfolioOptimisers.JuMPResult-Tuple{}","page":"JuMP Model Optimisation","title":"PortfolioOptimisers.JuMPResult","text":"JuMPResult(; trials::AbstractDict, success::Bool)\n\nConstruct a JuMPResult object from solver trials and success status.\n\nIf success is false, a warning is emitted with the trial errors.\n\nArguments\n\ntrials: Dictionary of solver attempts and errors.\nsuccess: Boolean indicating whether optimisation succeeded.\n\nReturns\n\nJuMPResult: Result object.\n\nExamples\n\njulia> JuMPResult(; trials = Dict(:HiGHS => Dict(:optimize! => \"error\")), success = true)\nJuMPResult\n   trials | Dict{Symbol, Dict{Symbol, String}}: Dict(:HiGHS => Dict(:optimize! => \"error\"))\n  success | Bool: true\n\n\n\n\n\n","category":"method"},{"location":"009-JuMPModelOptimisation/#PortfolioOptimisers.set_solver_attributes","page":"JuMP Model Optimisation","title":"PortfolioOptimisers.set_solver_attributes","text":"set_solver_attributes(args...)\n\nSet solver attributes for a JuMP model.\n\nThis is a generic fallback that does nothing if no model or settings are provided.\n\nArguments\n\nargs...: Arguments (ignored).\n\nReturns\n\nnothing\n\n\n\n\n\nset_solver_attributes(model::JuMP.Model,\n                      settings::Union{<:AbstractDict, <:AbstractVector{<:Pair}})\n\nSet multiple solver attributes on a JuMP model.\n\nIterates over the provided settings and applies each as a solver attribute.\n\nArguments\n\nmodel: JuMP model.\nsettings: Dictionary or vector of pairs of solver settings.\n\nReturns\n\nnothing\n\n\n\n\n\nset_solver_attributes(model::JuMP.Model, settings::Pair)\n\nSet a single solver attribute on a JuMP model.\n\nArguments\n\nmodel: JuMP model.\nsettings: Pair of attribute name and value.\n\nReturns\n\nnothing\n\n\n\n\n\n","category":"function"},{"location":"009-JuMPModelOptimisation/#PortfolioOptimisers.optimise_JuMP_model!","page":"JuMP Model Optimisation","title":"PortfolioOptimisers.optimise_JuMP_model!","text":"optimise_JuMP_model!(model::JuMP.Model,\n                     slv::Union{<:Solver, <:AbstractVector{<:Solver}})\n\nAttempt to optimise a JuMP model using one or more configured solvers.\n\nTries each solver in order, applying settings and checking for solution feasibility. Returns a JuMPResult with trial errors and success status.\n\nArguments\n\nmodel: JuMP model to optimise.\nslv: Single Solver or vector of Solver objects.\n\nReturns\n\nJuMPResult: Result object containing trial errors and success flag.\n\nDetails\n\nFor each solver, sets the optimizer and attributes, runs JuMP.optimize!, and checks solution feasibility.\nIf a solver fails, records the error and tries the next.\nStops at the first successful solution.\n\n\n\n\n\n","category":"function"},{"location":"007-18-Moments/#Regression","page":"Regression","title":"Regression","text":"","category":"section"},{"location":"007-18-Moments/#PortfolioOptimisers.AbstractRegressionEstimator","page":"Regression","title":"PortfolioOptimisers.AbstractRegressionEstimator","text":"abstract type AbstractRegressionEstimator <: AbstractEstimator end\n\nAbstract supertype for all regression estimator types in PortfolioOptimisers.jl.\n\nAll concrete types implementing regression estimation algorithms should subtype AbstractRegressionEstimator. This enables a consistent interface for regression-based moment estimation throughout the package.\n\nRelated\n\nAbstractEstimator\nAbstractRegressionAlgorithm\nAbstractRegressionResult\n\n\n\n\n\n","category":"type"},{"location":"007-18-Moments/#PortfolioOptimisers.AbstractRegressionResult","page":"Regression","title":"PortfolioOptimisers.AbstractRegressionResult","text":"abstract type AbstractRegressionResult <: AbstractResult end\n\nAbstract supertype for all regression result types in PortfolioOptimisers.jl.\n\nAll concrete types representing the output of regression-based moment estimation should subtype AbstractRegressionResult. This enables a consistent interface for handling regression results, such as fitted parameters, rr, and intercepts, throughout the package.\n\nRelated\n\nAbstractResult\nRegression\nAbstractRegressionEstimator\n\n\n\n\n\n","category":"type"},{"location":"007-18-Moments/#PortfolioOptimisers.AbstractRegressionAlgorithm","page":"Regression","title":"PortfolioOptimisers.AbstractRegressionAlgorithm","text":"abstract type AbstractRegressionAlgorithm <: AbstractAlgorithm end\n\nAbstract supertype for all regression algorithm types in PortfolioOptimisers.jl.\n\nAll concrete types implementing specific regression algorithms should subtype AbstractRegressionAlgorithm. This enables flexible extension and dispatch of regression routines for moment estimation.\n\nThese types are used to specify the algorithm when constructing a regression estimator.\n\nRelated\n\nAbstractEstimator\nAbstractRegressionAlgorithm\nAbstractStepwiseRegressionAlgorithm\nAbstractStepwiseRegressionCriterion\nAbstractRegressionTarget\n\n\n\n\n\n","category":"type"},{"location":"007-18-Moments/#PortfolioOptimisers.AbstractStepwiseRegressionAlgorithm","page":"Regression","title":"PortfolioOptimisers.AbstractStepwiseRegressionAlgorithm","text":"abstract type AbstractStepwiseRegressionAlgorithm <: AbstractRegressionAlgorithm end\n\nAbstract supertype for all stepwise regression algorithm types in PortfolioOptimisers.jl.\n\nAll concrete types implementing stepwise regression algorithms should subtype AbstractStepwiseRegressionAlgorithm. This enables modular extension and dispatch for stepwise regression routines, commonly used for variable selection and model refinement in regression-based moment estimation.\n\nRelated\n\nAbstractRegressionAlgorithm\nAbstractStepwiseRegressionCriterion\nAbstractRegressionTarget\n\n\n\n\n\n","category":"type"},{"location":"007-18-Moments/#PortfolioOptimisers.AbstractStepwiseRegressionCriterion","page":"Regression","title":"PortfolioOptimisers.AbstractStepwiseRegressionCriterion","text":"abstract type AbstractStepwiseRegressionCriterion <: AbstractRegressionAlgorithm end\n\nAbstract supertype for all stepwise regression criterion types in PortfolioOptimisers.jl.\n\nAll concrete types representing criteria for stepwise regression algorithms should subtype AbstractStepwiseRegressionCriterion. These criteria are used to evaluate model quality and guide variable selection during stepwise regression, such as AIC, BIC, or R².\n\nRelated\n\nAbstractStepwiseRegressionAlgorithm\nAbstractRegressionTarget\n\n\n\n\n\n","category":"type"},{"location":"007-18-Moments/#PortfolioOptimisers.AbstractRegressionTarget","page":"Regression","title":"PortfolioOptimisers.AbstractRegressionTarget","text":"abstract type AbstractRegressionTarget <: AbstractRegressionAlgorithm end\n\nAbstract supertype for all regression target types in PortfolioOptimisers.jl.\n\nAll concrete types representing regression targets (such as linear or generalised linear models) should subtype AbstractRegressionTarget. This enables flexible specification and dispatch of regression targets when constructing regression estimators.\n\nRelated\n\nAbstractRegressionAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"007-18-Moments/#PortfolioOptimisers.LinearModel","page":"Regression","title":"PortfolioOptimisers.LinearModel","text":"struct LinearModel{T1} <: AbstractRegressionTarget\n    kwargs::T1\nend\n\nRegression target type for standard linear models in PortfolioOptimisers.jl.\n\nLinearModel is used to specify a standard linear regression target (i.e., ordinary least squares) when constructing regression estimators. It encapsulates keyword arguments for configuring the underlying linear model fitting routine, enabling flexible extension and dispatch within the regression estimation framework.\n\nFields\n\nkwargs: Keyword arguments to be passed to the linear model fitting routine (e.g., options for the solver or regularisation).\n\nConstructor\n\nLinearModel(; kwargs::NamedTuple = (;))\n\nConstruct a LinearModel regression target with optional keyword arguments for model fitting.\n\nRelated\n\nAbstractRegressionTarget\nGeneralisedLinearModel\nStatsAPI.fit(::LinearModel, ::AbstractMatrix, ::AbstractVector)\n\n\n\n\n\n","category":"type"},{"location":"007-18-Moments/#PortfolioOptimisers.LinearModel-Tuple{}","page":"Regression","title":"PortfolioOptimisers.LinearModel","text":"LinearModel(; kwargs::NamedTuple = (;))\n\nConstruct a LinearModel regression target for standard linear regression.\n\nThis constructor creates a LinearModel object, optionally accepting keyword arguments as a NamedTuple to configure the underlying linear model fitting routine.\n\nArguments\n\nkwargs: Keyword arguments for the linear model fitting routine.\n\nReturns\n\nLinearModel: A configured linear regression target.\n\nExamples\n\njulia> LinearModel()\nLinearModel\n  kwargs | @NamedTuple{}: NamedTuple()\n\nRelated\n\nLinearModel\n\n\n\n\n\n","category":"method"},{"location":"007-18-Moments/#StatsAPI.fit-Tuple{LinearModel, AbstractMatrix, AbstractVector}","page":"Regression","title":"StatsAPI.fit","text":"StatsAPI.fit(target::LinearModel, X::AbstractMatrix, y::AbstractVector)\n\nFit a standard linear regression model using a LinearModel regression target.\n\nThis method dispatches to StatsAPI.fit with the GLM.LinearModel type, passing the design matrix X, response vector y, and any keyword arguments stored in target.kwargs. It enables flexible configuration of the underlying linear model fitting routine within the PortfolioOptimisers.jl regression estimation framework.\n\nArguments\n\ntarget: A LinearModel regression target specifying model options.\nX: The design matrix (observations × features).\ny: The response vector.\n\nReturns\n\nGLM.LinearModel: A fitted linear model object from the GLM.jl package.\n\nRelated\n\nLinearModel\nGLM.LinearModel\n\n\n\n\n\n","category":"method"},{"location":"007-18-Moments/#PortfolioOptimisers.GeneralisedLinearModel","page":"Regression","title":"PortfolioOptimisers.GeneralisedLinearModel","text":"struct GeneralisedLinearModel{T1, T2} <: AbstractRegressionTarget\n    args::T1\n    kwargs::T2\nend\n\nRegression target type for generalised linear models (GLMs) in PortfolioOptimisers.jl.\n\nGeneralisedLinearModel is used to specify a generalised linear regression target (e.g., logistic, Poisson, etc.) when constructing regression estimators. It encapsulates positional and keyword arguments for configuring the underlying GLM fitting routine, enabling flexible extension and dispatch within the regression estimation framework.\n\nFields\n\nargs: Positional arguments to be passed to the GLM fitting routine (e.g., distribution and link).\nkwargs: Keyword arguments for the GLM fitting routine (e.g., solver options, regularisation).\n\nConstructor\n\nGeneralisedLinearModel(; args::Tuple = (Normal(),), kwargs::NamedTuple = (;))\n\nConstruct a GeneralisedLinearModel regression target with optional arguments for model fitting.\n\nRelated\n\nAbstractRegressionTarget\nLinearModel\nStatsAPI.fit(::GeneralisedLinearModel, ::AbstractMatrix, ::AbstractVector)\n\n\n\n\n\n","category":"type"},{"location":"007-18-Moments/#PortfolioOptimisers.GeneralisedLinearModel-Tuple{}","page":"Regression","title":"PortfolioOptimisers.GeneralisedLinearModel","text":"GeneralisedLinearModel(; args::Tuple = (Normal(),), kwargs::NamedTuple = (;))\n\nConstruct a GeneralisedLinearModel regression target for generalised linear regression.\n\nThis constructor creates a GeneralisedLinearModel object, optionally accepting positional arguments (as a Tuple) and keyword arguments (as a NamedTuple) to configure the underlying GLM fitting routine.\n\nArguments\n\nargs: Positional arguments for the GLM fitting routine.\nkwargs: Keyword arguments for the GLM fitting routine.\n\nReturns\n\nGeneralisedLinearModel: A configured generalised linear regression target.\n\nExamples\n\njulia> GeneralisedLinearModel()\nGeneralisedLinearModel\n    args | Tuple{Distributions.Normal{Float64}}: (Distributions.Normal{Float64}(μ=0.0, σ=1.0),)\n  kwargs | @NamedTuple{}: NamedTuple()\n\nRelated\n\nGeneralisedLinearModel\n\n\n\n\n\n","category":"method"},{"location":"007-18-Moments/#StatsAPI.fit-Tuple{GeneralisedLinearModel, AbstractMatrix, AbstractVector}","page":"Regression","title":"StatsAPI.fit","text":"StatsAPI.fit(target::GeneralisedLinearModel, X::AbstractMatrix, y::AbstractVector)\n\nFit a generalised linear regression model using a GeneralisedLinearModel regression target.\n\nThis method dispatches to StatsAPI.fit with the GLM.GeneralizedLinearModel type, passing the design matrix X, response vector y, any positional arguments in target.args, and any keyword arguments in target.kwargs. This enables flexible configuration of the underlying GLM fitting routine within the PortfolioOptimisers.jl regression estimation framework.\n\nArguments\n\ntarget: A GeneralisedLinearModel regression target specifying model options.\nX: The design matrix (observations × features).\ny: The response vector.\n\nReturns\n\nGLM.GeneralizedLinearModel: A fitted generalised linear model object from the GLM.jl package.\n\nRelated\n\nGeneralisedLinearModel\nGLM.GeneralizedLinearModel\n\n\n\n\n\n","category":"method"},{"location":"007-18-Moments/#PortfolioOptimisers.AbstractMinValStepwiseRegressionCriterion","page":"Regression","title":"PortfolioOptimisers.AbstractMinValStepwiseRegressionCriterion","text":"abstract type AbstractMinValStepwiseRegressionCriterion <: AbstractStepwiseRegressionCriterion end\n\nAbstract supertype for all stepwise regression criteria where lower values indicate better model fit in PortfolioOptimisers.jl.\n\nAll concrete types implementing minimisation-based stepwise regression criteria (such as AIC, AICC, or BIC) should subtype AbstractMinValStepwiseRegressionCriterion. These criteria are used to guide variable selection in stepwise regression algorithms by minimising the criterion value.\n\nRelated\n\nAbstractStepwiseRegressionCriterion\nAIC\nAICC\nBIC\n\n\n\n\n\n","category":"type"},{"location":"007-18-Moments/#PortfolioOptimisers.AbstractMaxValStepwiseRegressionCriteria","page":"Regression","title":"PortfolioOptimisers.AbstractMaxValStepwiseRegressionCriteria","text":"abstract type AbstractMaxValStepwiseRegressionCriteria <: AbstractStepwiseRegressionCriterion end\n\nAbstract supertype for all stepwise regression criteria where higher values indicate better model fit in PortfolioOptimisers.jl.\n\nAll concrete types implementing maximisation-based stepwise regression criteria (such as R² or Adjusted R²) should subtype AbstractMaxValStepwiseRegressionCriteria. These criteria are used to guide variable selection in stepwise regression algorithms by maximising the criterion value.\n\nRelated\n\nAbstractStepwiseRegressionCriterion\nRSquared\nAdjustedRSquared\n\n\n\n\n\n","category":"type"},{"location":"007-18-Moments/#PortfolioOptimisers.AIC","page":"Regression","title":"PortfolioOptimisers.AIC","text":"struct AIC <: AbstractMinValStepwiseRegressionCriterion end\n\nAkaike Information Criterion (AIC) for stepwise regression in PortfolioOptimisers.jl.\n\nAIC is a minimisation-based criterion used to evaluate model quality in stepwise regression algorithms. Lower values indicate better model fit, penalising model complexity to avoid overfitting.\n\nRelated\n\nAbstractMinValStepwiseRegressionCriterion\nAICC\nBIC\nregression_criterion_func(::AIC)\n\n\n\n\n\n","category":"type"},{"location":"007-18-Moments/#PortfolioOptimisers.AICC","page":"Regression","title":"PortfolioOptimisers.AICC","text":"struct AICC <: AbstractMinValStepwiseRegressionCriterion end\n\nCorrected Akaike Information Criterion (AICC) for stepwise regression in PortfolioOptimisers.jl.\n\nAICC is a minimisation-based criterion similar to AIC, but includes a correction for small sample sizes. Lower values indicate better model fit, balancing fit and complexity.\n\nRelated\n\nAbstractMinValStepwiseRegressionCriterion\nAIC\nBIC\nregression_criterion_func(::AICC)\n\n\n\n\n\n","category":"type"},{"location":"007-18-Moments/#PortfolioOptimisers.BIC","page":"Regression","title":"PortfolioOptimisers.BIC","text":"struct BIC <: AbstractMinValStepwiseRegressionCriterion end\n\nBayesian Information Criterion (BIC) for stepwise regression in PortfolioOptimisers.jl.\n\nBIC is a minimisation-based criterion used to evaluate model quality in stepwise regression algorithms. It penalises model complexity more strongly than AIC. Lower values indicate better model fit.\n\nRelated\n\nAbstractMinValStepwiseRegressionCriterion\nAIC\nAICC\nregression_criterion_func(::BIC)\n\n\n\n\n\n","category":"type"},{"location":"007-18-Moments/#PortfolioOptimisers.RSquared","page":"Regression","title":"PortfolioOptimisers.RSquared","text":"struct RSquared <: AbstractMaxValStepwiseRegressionCriteria end\n\nCoefficient of determination (R²) for stepwise regression in PortfolioOptimisers.jl.\n\nRSquared is a maximisation-based criterion used to evaluate model quality in stepwise regression algorithms. Higher values indicate better model fit, representing the proportion of variance explained by the model.\n\nRelated\n\nAbstractMaxValStepwiseRegressionCriteria\nAdjustedRSquared\nregression_criterion_func(::RSquared)\n\n\n\n\n\n","category":"type"},{"location":"007-18-Moments/#PortfolioOptimisers.AdjustedRSquared","page":"Regression","title":"PortfolioOptimisers.AdjustedRSquared","text":"struct AdjustedRSquared <: AbstractMaxValStepwiseRegressionCriteria end\n\nAdjusted coefficient of determination (Adjusted R²) for stepwise regression in PortfolioOptimisers.jl.\n\nAdjustedRSquared is a maximisation-based criterion that adjusts R² for the number of predictors in the model, providing a more accurate measure of model quality when comparing models with different numbers of predictors.\n\nRelated\n\nAbstractMaxValStepwiseRegressionCriteria\nRSquared\nregression_criterion_func(::AdjustedRSquared)\n\n\n\n\n\n","category":"type"},{"location":"007-18-Moments/#PortfolioOptimisers.regression_criterion_func","page":"Regression","title":"PortfolioOptimisers.regression_criterion_func","text":"regression_criterion_func(::AbstractStepwiseRegressionCriterion)\n\nReturn the function used to compute the value of a stepwise regression criterion.\n\nThis utility dispatches on the concrete criterion subtype of AbstractStepwiseRegressionCriterion, returning the corresponding function from GLM.jl. Used internally by stepwise regression algorithms to evaluate model quality.\n\nArguments\n\ncriterion: A stepwise regression criterion type (e.g., AIC(), BIC(), RSquared()).\n\nReturns\n\nf::Function: The function that computes the criterion value for a fitted model.\n\nRelated\n\nAIC\nAICC\nBIC\nRSquared\nAdjustedRSquared\n\n\n\n\n\n","category":"function"},{"location":"007-18-Moments/#PortfolioOptimisers.Regression","page":"Regression","title":"PortfolioOptimisers.Regression","text":"struct Regression{T1, T2, T3} <: AbstractRegressionResult\n    M::T1\n    L::T2\n    b::T3\nend\n\nContainer type for regression results in PortfolioOptimisers.jl.\n\nRegression stores the results of a regression-based moment estimation, including the main coefficient matrix, an optional auxiliary matrix, and the intercept vector. This type is used as the standard output for regression estimators, enabling consistent downstream processing and analysis.\n\nFields\n\nM: Main coefficient matrix (e.g., regression weights or loadings).\nL: Optional auxiliary matrix for recovering lost dimensions in dimensionality reduction regressions.\nb: Optional intercept vector.\n\nConstructor\n\nRegression(; M::AbstractMatrix, L::Union{Nothing, <:AbstractMatrix} = nothing,\n             b::Union{Nothing, <:AbstractVector} = nothing)\n\nConstruct a Regression result object with the specified coefficient matrix, optional auxiliary matrix, and intercept vector.\n\nRelated\n\nAbstractRegressionResult\n\n\n\n\n\n","category":"type"},{"location":"007-18-Moments/#PortfolioOptimisers.Regression-Tuple{}","page":"Regression","title":"PortfolioOptimisers.Regression","text":"Regression(; M::AbstractMatrix, L::Union{Nothing, <:AbstractMatrix} = nothing,\n             b::Union{Nothing, <:AbstractVector} = nothing)\n\nConstruct a Regression result object for regression-based moment estimation.\n\nThis constructor creates a Regression object from the given coefficient matrix, optional auxiliary matrix, and intercept vector. It performs validation to ensure consistency of dimensions.\n\nArguments\n\nM: Main coefficient matrix.\nL: Optional auxiliary matrix for recovering lost dimensions in dimensionality reduction regressions.\nb: Optional intercept vector.\n\nReturns\n\nRegression: A regression result object.\n\nValidation\n\nAsserts that M is non-empty.\nIf b is provided, asserts that it is non-empty and matches the row dimension of M.\nIf L is provided, asserts that it matches the row dimension of M.\n\nExamples\n\njulia> Regression(; M = [1 2 3; 4 5 6], L = [1 2 3 4; 5 6 7 8], b = [1, 2])\nRegression\n  M | 2×3 Matrix{Int64}\n  L | 2×4 Matrix{Int64}\n  b | Vector{Int64}: [1, 2]\n\nRelated\n\nRegression\n\n\n\n\n\n","category":"method"},{"location":"007-18-Moments/#PortfolioOptimisers.regression_view","page":"Regression","title":"PortfolioOptimisers.regression_view","text":"regression_view(re::Regression, i::AbstractVector)\n\nReturn a view of a Regression result object, selecting only the rows indexed by i.\n\nThis function constructs a new Regression result, where the coefficient matrix M, optional auxiliary matrix L, and intercept vector b are restricted to the rows specified by the index vector i. This is useful for extracting or operating on a subset of regression results, such as for a subset of assets or features.\n\nArguments\n\nre: A regression result object.\ni: Indices of the rows to select.\n\nReturns\n\nRegression: A new regression result object with fields restricted to the selected rows.\n\nExamples\n\njulia> re = Regression(; M = [1 2; 3 4; 5 6], L = [10 20; 30 40; 50 60], b = [7, 8, 9])\nRegression\n  M | 3×2 Matrix{Int64}\n  L | 3×2 Matrix{Int64}\n  b | Vector{Int64}: [7, 8, 9]\n\njulia> PortfolioOptimisers.regression_view(re, [1, 3])\nRegression\n  M | 2×2 SubArray{Int64, 2, Matrix{Int64}, Tuple{Vector{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}\n  L | 2×2 SubArray{Int64, 2, Matrix{Int64}, Tuple{Vector{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}\n  b | SubArray{Int64, 1, Vector{Int64}, Tuple{Vector{Int64}}, false}: [7, 9]\n\nRelated\n\nRegression\n\n\n\n\n\nregression_view(re::Union{Nothing, <:AbstractRegressionEstimator}, args...)\n\nNo-op fallback for regression_view when the input is nothing or an AbstractRegressionEstimator.\n\nThis method returns the input re unchanged. It is used internally to allow generic code to call regression_view without needing to check for nothing or estimator types, ensuring graceful handling of missing or non-result regression objects.\n\nArguments\n\nre: Either nothing or a regression estimator type.\nargs...: Additional arguments (ignored).\n\nReturns\n\nThe input re, unchanged.\n\nRelated\n\nregression_view(::Regression, ::AbstractVector)\n\n\n\n\n\n","category":"function"},{"location":"007-18-Moments/#PortfolioOptimisers.regression-Tuple{Regression, Vararg{Any}}","page":"Regression","title":"PortfolioOptimisers.regression","text":"regression(re::Regression, args...)\n\nReturn the regression result object unchanged.\n\nThis method is a pass-through for Regression result objects, allowing generic code to call regression on a result and receive the same object. It enables a unified interface for both estimator and result types.\n\nArguments\n\nre: A regression result object.\nargs...: Additional arguments (ignored).\n\nReturns\n\nThe input re, unchanged.\n\nRelated\n\nRegression\n\n\n\n\n\n","category":"method"},{"location":"007-18-Moments/#PortfolioOptimisers.regression-Tuple{PortfolioOptimisers.AbstractRegressionEstimator, ReturnsResult}","page":"Regression","title":"PortfolioOptimisers.regression","text":"regression(re::AbstractRegressionEstimator, rd::ReturnsResult)\n\nCompute or extract a regression result from an estimator or result and a ReturnsResult.\n\nThis method dispatches to regression(re, rd.X, rd.F), allowing both regression estimators and regression result objects to be used interchangeably in generic workflows. If re is an estimator, it computes the regression result using the data in rd. If re is already a result, it is returned unchanged.\n\nArguments\n\nre: A regression estimator or result object.\nrd: A returns result object containing data matrices X and F.\n\nReturns\n\nRegression: The computed or extracted regression result.\n\nRelated\n\nRegression\nReturnsResult\n\n\n\n\n\n","category":"method"},{"location":"007-02-Moments/#Mean","page":"Mean","title":"Mean","text":"","category":"section"},{"location":"007-02-Moments/#PortfolioOptimisers.SimpleExpectedReturns","page":"Mean","title":"PortfolioOptimisers.SimpleExpectedReturns","text":"struct SimpleExpectedReturns{T1} <: AbstractExpectedReturnsEstimator\n    w::T1\nend\n\nA simple expected returns estimator for PortfolioOptimisers.jl, representing the sample mean with optional observation weights.\n\nSimpleExpectedReturns is the standard estimator for computing expected returns as the (possibly weighted) mean of asset returns. It supports both unweighted and weighted mean estimation by storing an optional weights vector.\n\nFields\n\nw: Optional weights for each observation. If nothing, the unweighted mean is computed.\n\nConstructor\n\nSimpleExpectedReturns(; w::Union{Nothing, <:AbstractWeights} = nothing)\n\nConstruct a SimpleExpectedReturns estimator with optional observation weights.\n\nFields\n\nw: Optional weights for each observation.\n\nRelated\n\nAbstractExpectedReturnsEstimator\nStatsBase.AbstractWeights\nmean(me::SimpleExpectedReturns, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\n\n\n\n\n","category":"type"},{"location":"007-02-Moments/#PortfolioOptimisers.SimpleExpectedReturns-Tuple{}","page":"Mean","title":"PortfolioOptimisers.SimpleExpectedReturns","text":"SimpleExpectedReturns(; w::Union{Nothing, <:AbstractWeights} = nothing)\n\nConstruct a SimpleExpectedReturns estimator for computing expected returns as the (optionally weighted) sample mean.\n\nArguments\n\nw: Optional observation weights. If nothing, the unweighted mean is computed.\n\nValidation\n\n- If `w` is provided, it must not be empty.\n\nReturns\n\nSimpleExpectedReturns: A simple expected returns estimator configured with optional weights.\n\nExamples\n\njulia> using StatsBase\n\njulia> ser = SimpleExpectedReturns()\nSimpleExpectedReturns\n  w | nothing\n\njulia> w = Weights([0.2, 0.3, 0.5]);\n\njulia> ser = SimpleExpectedReturns(; w = w)\nSimpleExpectedReturns\n  w | StatsBase.Weights{Float64, Float64, Vector{Float64}}: [0.2, 0.3, 0.5]\n\nRelated\n\nAbstractExpectedReturnsEstimator\nStatsBase.AbstractWeights\nSimpleExpectedReturns\nmean(me::SimpleExpectedReturns, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"007-02-Moments/#Statistics.mean-Tuple{SimpleExpectedReturns, AbstractMatrix}","page":"Mean","title":"Statistics.mean","text":"mean(me::SimpleExpectedReturns, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the mean of asset returns using a SimpleExpectedReturns estimator.\n\nThis method computes the expected returns as the sample mean of the input data X, optionally using observation weights stored in the estimator. If no weights are provided, the unweighted mean is computed.\n\nArguments\n\nme: The expected returns estimator.\nX: Data array of asset returns (observations × assets).\ndims: Dimension along which to compute the mean.\nkwargs...: Additional keyword arguments passed to Statistics.mean.\n\nReturns\n\nThe mean of X along the specified dimension using the SimpleExpectedReturns estimator.\n\nExamples\n\njulia> using StatsBase\n\njulia> X = [0.01 0.02; 0.03 0.04];\n\njulia> ser = SimpleExpectedReturns()\nSimpleExpectedReturns\n  w | nothing\n\njulia> mean(ser, X)\n1×2 Matrix{Float64}:\n 0.02  0.03\n\njulia> w = Weights([0.2, 0.8]);\n\njulia> serw = SimpleExpectedReturns(; w = w)\nSimpleExpectedReturns\n  w | StatsBase.Weights{Float64, Float64, Vector{Float64}}: [0.2, 0.8]\n\njulia> mean(serw, X)\n1×2 Matrix{Float64}:\n 0.026  0.036\n\nRelated\n\nSimpleExpectedReturns\nStatistics.mean\n\n\n\n\n\n","category":"method"},{"location":"008-5-Distance/#General-Distance-of-Distances","page":"General Distance of Distances","title":"General Distance of Distances","text":"","category":"section"},{"location":"008-5-Distance/#PortfolioOptimisers.GeneralDistanceDistance","page":"General Distance of Distances","title":"PortfolioOptimisers.GeneralDistanceDistance","text":"struct GeneralDistanceDistance{T1, T2, T3, T4, T5} <: AbstractDistanceEstimator\n    dist::T1\n    args::T2\n    kwargs::T3\n    power::T4\n    alg::T5\nend\n\nA general distance-of-distances estimator for portfolio optimization.\n\nGeneralDistanceDistance allows you to compute a \"distance of distances\" matrix using a customizable base distance powered by a power parameter and algorithm, and a second-level metric from Distances.jl. This is useful for meta-clustering or higher-order distance-based analyses.\n\nFields\n\ndist: The metric to use for the second-level distance.\nargs: Positional arguments to pass to the metric.\nkwargs: Keyword arguments to pass to the metric.\npower: Power parameter for the base distance.\nalg: The base distance algorithm to use.\n\nConstructor\n\nGeneralDistanceDistance(; dist::Distances.Metric = Distances.Euclidean(),\n                         args::Tuple = (), kwargs::NamedTuple = (;),\n                         power::Integer = 1,\n                         alg::AbstractDistanceAlgorithm = SimpleDistance())\n\nRelated\n\nGeneralDistance\ndistance\nDistances.jl\n\n\n\n\n\n","category":"type"},{"location":"008-5-Distance/#PortfolioOptimisers.GeneralDistanceDistance-Tuple{}","page":"General Distance of Distances","title":"PortfolioOptimisers.GeneralDistanceDistance","text":"GeneralDistanceDistance(; dist::Distances.Metric = Distances.Euclidean(),\n                         args::Tuple = (), kwargs::NamedTuple = (;),\n                         power::Integer = 1,\n                         alg::AbstractDistanceAlgorithm = SimpleDistance())\n\nConstruct a GeneralDistanceDistance estimator with the specified metric, power, and base distance algorithm.\n\nArguments\n\ndist: The metric to use for the second-level distance from Distances.jl.\nargs: Positional arguments to pass to the metric.\nkwargs: Keyword arguments to pass to the metric.\npower: Power parameter for the base distance.\nalg: The base distance algorithm to use.\n\nReturns\n\nGeneralDistanceDistance: A configured general distance-of-distances estimator.\n\nRelated\n\nGeneralDistanceDistance\nGeneralDistance\ndistance\nDistances.jl]\n\n\n\n\n\n","category":"method"},{"location":"008-5-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistanceDistance, CovarianceEstimator, AbstractMatrix}","page":"General Distance of Distances","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistanceDistance, ce::StatsBase.CovarianceEstimator,\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the general distance-of-distances matrix from a covariance estimator and data matrix.\n\nThis method first computes a base distance matrix using GeneralDistance with the specified power and algorithm, then applies the provided metric to compute a second-level distance matrix.\n\nArguments\n\nde: General distance-of-distances estimator.\nce: Covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the base distance.\nkwargs...: Additional keyword arguments passed to the base distance computation.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise distances of distances.\n\nRelated\n\nGeneralDistanceDistance\nGeneralDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-5-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistanceDistance, AbstractMatrix, Vararg{Any}}","page":"General Distance of Distances","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistanceDistance, rho::AbstractMatrix, args...; kwargs...)\n\nCompute the general distance-of-distances matrix from a correlation or covariance matrix.\n\nThis method first computes a base distance matrix using GeneralDistance with the specified power and algorithm, then applies the provided metric to compute a second-level distance matrix.\n\nArguments\n\nde: General distance-of-distances estimator.\nrho: Correlation or covariance matrix.\nargs...: Additional arguments (ignored).\nkwargs...: Additional keyword arguments passed to the base distance computation.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise distances of distances.\n\nRelated\n\nGeneralDistanceDistance\nGeneralDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-5-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{GeneralDistanceDistance, CovarianceEstimator, AbstractMatrix}","page":"General Distance of Distances","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(de::GeneralDistanceDistance, ce::StatsBase.CovarianceEstimator,\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the correlation matrix and the general distance-of-distances matrix from a covariance estimator and data matrix.\n\nThis method first computes the correlation and base distance matrices using GeneralDistance, then applies the provided metric to the base distance matrix.\n\nArguments\n\nde: General distance-of-distances estimator.\nce: Covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the base distance.\nkwargs...: Additional keyword arguments passed to the base distance computation.\n\nReturns\n\n(rho::Matrix{<:Real}, D::Matrix{<:Real}): Tuple of correlation matrix and distance-of-distances matrix.\n\nRelated\n\nGeneralDistanceDistance\nGeneralDistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"007-14-Moments/#Equilibrium-expected-returns","page":"Equilibrium expected returns","title":"Equilibrium expected returns","text":"","category":"section"},{"location":"007-14-Moments/#PortfolioOptimisers.EquilibriumExpectedReturns","page":"Equilibrium expected returns","title":"PortfolioOptimisers.EquilibriumExpectedReturns","text":"struct EquilibriumExpectedReturns{T1, T2, T3} <: AbstractShrunkExpectedReturnsEstimator\n    ce::T1\n    w::T2\n    l::T3\nend\n\nContainer type for equilibrium expected returns estimators.\n\nEquilibriumExpectedReturns encapsulates the covariance estimator, equilibrium weights, and risk aversion parameter for computing equilibrium expected returns (e.g., as in Black-Litterman). This enables modular workflows for reverse optimization and equilibrium-based return estimation.\n\nFields\n\nce: Covariance estimator.\nw: Equilibrium portfolio weights. If nothing, uses equal weights.\nl: Risk aversion parameter.\n\nConstructor\n\nEquilibriumExpectedReturns(; ce::StatsBase.CovarianceEstimator = PortfolioOptimisersCovariance(),\n                           w::Union{Nothing, <:AbstractWeights} = nothing,\n                           l::Real = 1.0)\n\nConstruct an EquilibriumExpectedReturns estimator with the specified covariance estimator, weights, and risk aversion.\n\nRelated\n\nAbstractShrunkExpectedReturnsEstimator\nStatsBase.CovarianceEstimator\nStatsBase.AbstractWeights\n\n\n\n\n\n","category":"type"},{"location":"007-14-Moments/#PortfolioOptimisers.EquilibriumExpectedReturns-Tuple{}","page":"Equilibrium expected returns","title":"PortfolioOptimisers.EquilibriumExpectedReturns","text":"EquilibriumExpectedReturns(; ce::StatsBase.CovarianceEstimator = PortfolioOptimisersCovariance(),\n                           w::Union{Nothing, <:AbstractWeights} = nothing,\n                           l::Real = 1.0)\n\nConstruct an EquilibriumExpectedReturns estimator for equilibrium-based expected returns.\n\nArguments\n\nce: Covariance estimator.\nw: Equilibrium portfolio weights. If nothing, uses equal weights.\nl: Risk aversion parameter.\n\nReturns\n\nEquilibriumExpectedReturns: Configured equilibrium expected returns estimator.\n\nExamples\n\njulia> EquilibriumExpectedReturns()\nEquilibriumExpectedReturns\n  ce | PortfolioOptimisersCovariance\n     |   ce | Covariance\n     |      |    me | SimpleExpectedReturns\n     |      |       |   w | nothing\n     |      |    ce | GeneralWeightedCovariance\n     |      |       |   ce | StatsBase.SimpleCovariance: StatsBase.SimpleCovariance(true)\n     |      |       |    w | nothing\n     |      |   alg | Full()\n     |   mp | DefaultMatrixProcessing\n     |      |       pdm | Posdef\n     |      |           |   alg | UnionAll: NearestCorrelationMatrix.Newton\n     |      |   denoise | nothing\n     |      |    detone | nothing\n     |      |       alg | nothing\n   w | nothing\n   l | Float64: 1.0\n\nRelated\n\nEquilibriumExpectedReturns\nStatsBase.CovarianceEstimator\nStatsBase.AbstractWeights\n\n\n\n\n\n","category":"method"},{"location":"007-14-Moments/#Statistics.mean-Tuple{EquilibriumExpectedReturns, AbstractMatrix}","page":"Equilibrium expected returns","title":"Statistics.mean","text":"mean(me::EquilibriumExpectedReturns, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute equilibrium expected returns from a covariance estimator, weights, and risk aversion.\n\nThis method computes equilibrium expected returns as λ * Σ * w, where λ is the risk aversion parameter, Σ is the covariance matrix, and w are the equilibrium weights. If w is not provided, equal weights are used.\n\nArguments\n\nme: Equilibrium expected returns estimator.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the covariance.\nkwargs...: Additional keyword arguments passed to the covariance estimator.\n\nReturns\n\nmu::AbstractArray: Equilibrium expected returns vector.\n\nRelated\n\nEquilibriumExpectedReturns\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#Distance","page":"Distance","title":"Distance","text":"","category":"section"},{"location":"008-2-Distance/#PortfolioOptimisers.Distance","page":"Distance","title":"PortfolioOptimisers.Distance","text":"struct Distance{T1} <: AbstractDistanceEstimator\n    alg::T1\nend\n\nDistance estimator for portfolio optimization.\n\nDistance is a flexible container type for configuring and applying distance-based estimators in PortfolioOptimisers.jl. It encapsulates a distance algorithm (such as SimpleDistance, SimpleAbsoluteDistance, LogDistance, CorrelationDistance, CanonicalDistance, or VariationInfoDistance) and provides a unified interface for computing distance matrices and related quantities.\n\nFields\n\nalg: The distance algorithm to use (e.g., SimpleDistance()).\n\nConstructor\n\nDistance(; alg::AbstractDistanceAlgorithm = SimpleDistance())\n\nRelated\n\nAbstractDistanceEstimator\nAbstractDistanceAlgorithm\ndistance\n\n\n\n\n\n","category":"type"},{"location":"008-2-Distance/#PortfolioOptimisers.Distance-Tuple{}","page":"Distance","title":"PortfolioOptimisers.Distance","text":"Distance(; alg::AbstractDistanceAlgorithm = SimpleDistance())\n\nConstruct a Distance estimator with the specified distance algorithm.\n\nThis constructor creates a Distance object using the provided distance algorithm.\n\nArguments\n\nalg: The distance algorithm to use.\n\nReturns\n\nDistance: A configured distance estimator.\n\nExamples\n\njulia> Distance()\nDistance\n  alg | SimpleDistance()\n\nRelated\n\nDistance\nAbstractDistanceAlgorithm\nSimpleDistance\nSimpleAbsoluteDistance\nLogDistance\nCorrelationDistance\nCanonicalDistance\nVariationInfoDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.distance-Tuple{Distance{<:SimpleDistance}, CovarianceEstimator, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.distance","text":"distance(::Distance{<:SimpleDistance}, ce::StatsBase.CovarianceEstimator,\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the simple distance matrix from a covariance estimator and data matrix.\n\nThis method computes the correlation matrix using the provided covariance estimator ce and data matrix X, then transforms it into a distance matrix using the formula distance = sqrt(clamp((1 - ρ) / 2, 0, 1)), where ρ is the correlation coefficient.\n\nArguments\n\n::Distance{<:SimpleDistance}: Distance estimator with SimpleDistance algorithm.\nce: Covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation computation.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise Euclidean distances.\n\nRelated\n\nDistance\nSimpleDistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.distance-Tuple{Distance{<:SimpleDistance}, AbstractMatrix, Vararg{Any}}","page":"Distance","title":"PortfolioOptimisers.distance","text":"distance(::Distance{<:SimpleDistance}, rho::AbstractMatrix, args...; kwargs...)\n\nCompute the simple distance matrix from a correlation or covariance matrix.\n\nIf the input rho is a covariance matrix, it is first converted to a correlation matrix. The distance matrix is then computed using the formula distance = sqrt(clamp((1 - ρ) / 2, 0, 1)), where ρ is the correlation coefficient.\n\nArguments\n\n::Distance{<:SimpleDistance}: Distance estimator with SimpleDistance algorithm.\nrho: Correlation or covariance matrix.\nargs...: Additional arguments (ignored).\nkwargs...: Additional keyword arguments.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise Euclidean distances.\n\nDetails\n\nIf rho is a covariance matrix, it is converted to a correlation matrix using StatsBase.cov2cor.\n\nRelated\n\nDistance\nSimpleDistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{Distance{<:SimpleDistance}, CovarianceEstimator, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(::Distance{<:SimpleDistance}, ce::StatsBase.CovarianceEstimator,\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the correlation matrix and the simple distance matrix from a covariance estimator and data matrix.\n\nThis method returns a tuple containing the correlation matrix and the corresponding distance matrix, where the distance is computed as sqrt(clamp((1 - ρ) / 2, 0, 1)), where ρ is the correlation coefficient.\n\nArguments\n\n::Distance{<:SimpleDistance}: Distance estimator with SimpleDistance algorithm.\nce: Covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation computation.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of correlation matrix and distance matrix.\n\nRelated\n\nDistance\nSimpleDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.distance-Tuple{Distance{<:SimpleAbsoluteDistance}, CovarianceEstimator, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.distance","text":"distance(::Distance{<:SimpleAbsoluteDistance}, ce::StatsBase.CovarianceEstimator,\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the simple absolute distance matrix from a covariance estimator and data matrix.\n\nThis method computes the correlation matrix using the provided covariance estimator ce and data matrix X, takes the absolute value of the correlation coefficients, and transforms them into a distance matrix using the formula distance = sqrt(clamp(1 - |ρ|, 0, 1)), where ρ is the correlation coefficient.\n\nArguments\n\n::Distance{<:SimpleAbsoluteDistance}: Distance estimator with SimpleAbsoluteDistance algorithm.\nce: Covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation computation.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise absolute distances.\n\nRelated\n\nDistance\nSimpleAbsoluteDistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.distance-Tuple{Distance{<:SimpleAbsoluteDistance}, AbstractMatrix, Vararg{Any}}","page":"Distance","title":"PortfolioOptimisers.distance","text":"distance(::Distance{<:SimpleAbsoluteDistance}, rho::AbstractMatrix, args...; kwargs...)\n\nCompute the simple absolute distance matrix from a correlation or covariance matrix.\n\nIf the input rho is a covariance matrix, it is first converted to a correlation matrix. The distance matrix is then computed using the formula distance = sqrt(clamp(1 - |ρ|, 0, 1)), where ρ is the correlation coefficient.\n\nArguments\n\n::Distance{<:SimpleAbsoluteDistance}: Distance estimator with SimpleAbsoluteDistance algorithm.\nrho: Correlation or covariance matrix.\nargs...: Additional arguments (ignored).\nkwargs...: Additional keyword arguments.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise absolute distances.\n\nDetails\n\nIf rho is a covariance matrix, it is converted to a correlation matrix using StatsBase.cov2cor.\n\nRelated\n\nDistance\nSimpleAbsoluteDistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{Distance{<:SimpleAbsoluteDistance}, CovarianceEstimator, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(::Distance{<:SimpleAbsoluteDistance},\n             ce::StatsBase.CovarianceEstimator, X::AbstractMatrix; dims::Int = 1,\n             kwargs...)\n\nCompute both the absolute correlation matrix and the simple absolute distance matrix from a covariance estimator and data matrix.\n\nThis method returns a tuple containing the absolute correlation matrix and the corresponding distance matrix, where the distance is computed as sqrt(clamp(1 - |ρ|, 0, 1)), with ρ the correlation coefficient.\n\nArguments\n\n::Distance{<:SimpleAbsoluteDistance}: Distance estimator with SimpleAbsoluteDistance algorithm.\nce: Covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation computation.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of absolute correlation matrix and distance matrix.\n\nRelated\n\nDistance\nSimpleAbsoluteDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.distance-Tuple{Distance{<:LogDistance}, CovarianceEstimator, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.distance","text":"distance(::Distance{<:LogDistance}, ce::StatsBase.CovarianceEstimator,\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the log-distance matrix from a covariance estimator and data matrix.\n\nThis method computes the correlation matrix using the provided covariance estimator ce and data matrix X, takes the absolute value of the correlation coefficients, and transforms them into a distance matrix using the formula distance = -log(|ρ|), where ρ is the correlation coefficient.\n\nArguments\n\n::Distance{<:LogDistance}: Distance estimator with LogDistance algorithm.\nce: Covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation computation.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise log-distances.\n\nRelated\n\nDistance\nLogDistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.distance-Tuple{Distance{<:LogDistance}, Union{LTDCovariance, PortfolioOptimisersCovariance{<:LTDCovariance}}, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.distance","text":"distance(::Distance{<:LogDistance},\n         ce::Union{<:LTDCovariance,\n                   <:PortfolioOptimisersCovariance{<:LTDCovariance, <:Any}},\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the log-distance matrix from a Lower Tail Dependence (LTD) covariance estimator and data matrix.\n\nThis method computes the correlation matrix using the provided LTD covariance estimator ce and data matrix X, then transforms it into a distance matrix using the formula distance = -log(ρ), where ρ is the correlation coefficient.\n\nArguments\n\n::Distance{<:LogDistance}: Distance estimator with LogDistance algorithm.\nce: LTD covariance estimator or a PortfolioOptimisersCovariance wrapping an LTD estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation computation.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise log-distances.\n\nRelated\n\nDistance\nLogDistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.distance-Tuple{Distance{<:LogDistance}, AbstractMatrix, Vararg{Any}}","page":"Distance","title":"PortfolioOptimisers.distance","text":"distance(::Distance{<:LogDistance}, rho::AbstractMatrix, args...; kwargs...)\n\nCompute the log-distance matrix from a correlation or covariance matrix.\n\nIf the input rho is a covariance matrix, it is first converted to a correlation matrix. The distance matrix is then computed using the formula distance = -log(|ρ|), where ρ is the correlation coefficient.\n\nArguments\n\n::Distance{<:LogDistance}: Distance estimator with LogDistance algorithm.\nrho: Correlation or covariance matrix.\nargs...: Additional arguments (ignored).\nkwargs...: Additional keyword arguments.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise log-distances.\n\nDetails\n\nIf rho is a covariance matrix, it is converted to a correlation matrix using StatsBase.cov2cor.\n\nRelated\n\nDistance\nLogDistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{Distance{<:LogDistance}, CovarianceEstimator, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(::Distance{<:LogDistance},\n             ce::StatsBase.CovarianceEstimator, X::AbstractMatrix; dims::Int = 1,\n             kwargs...)\n\nCompute both the absolute correlation matrix and the log-distance matrix from a covariance estimator and data matrix.\n\nThis method returns a tuple containing the absolute correlation matrix and the corresponding log-distance matrix, where the distance is computed as -log(|ρ|), with ρ the correlation coefficient.\n\nArguments\n\n::Distance{<:LogDistance}: Distance estimator with LogDistance algorithm.\nce: Covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation computation.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of absolute correlation matrix and log-distance matrix.\n\nRelated\n\nDistance\nLogDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{Distance{<:LogDistance}, Union{LTDCovariance, PortfolioOptimisersCovariance{<:LTDCovariance}}, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(::Distance{<:LogDistance},\n             ce::Union{<:LTDCovariance,\n                       <:PortfolioOptimisersCovariance{<:LTDCovariance, <:Any}},\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the correlation matrix and the log-distance matrix from a Lower Tail Dependence (LTD) covariance estimator and data matrix.\n\nThis method returns a tuple containing the correlation matrix and the corresponding log-distance matrix, where the distance is computed as -log(ρ), with ρ the correlation coefficient.\n\nArguments\n\n::Distance{<:LogDistance}: Distance estimator with LogDistance algorithm.\nce: LTD covariance estimator or a PortfolioOptimisersCovariance wrapping an LTD estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation computation.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of correlation matrix and log-distance matrix.\n\nRelated\n\nDistance\nLogDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.distance-Tuple{Distance{<:VariationInfoDistance}, Any, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.distance","text":"distance(de::Distance{<:VariationInfoDistance}, ::Any, X::AbstractMatrix;\n         dims::Int = 1, kwargs...)\n\nCompute the variation of information (VI) distance matrix from a data matrix.\n\nThis method computes the VI distance matrix for the input data matrix X using the configuration in the VariationInfoDistance algorithm. The VI distance is a measure of dissimilarity between random variables based on their mutual information, estimated via histogram binning.\n\nArguments\n\nde::Distance{<:VariationInfoDistance}: Distance estimator with VariationInfoDistance algorithm.\n::Any: Placeholder for compatibility; ignored.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance. If 2, the data is transposed.\nkwargs...: Additional keyword arguments (ignored).\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise variation of information distances.\n\nDetails\n\nThe number of bins and normalisation are taken from the VariationInfoDistance algorithm fields.\nIf dims == 2, the data matrix is transposed before computation.\n\nRelated\n\nDistance\nVariationInfoDistance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{Distance{<:VariationInfoDistance}, CovarianceEstimator, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(de::Distance{<:VariationInfoDistance},\n             ce::StatsBase.CovarianceEstimator, X::AbstractMatrix; dims::Int = 1,\n             kwargs...)\n\nCompute both the correlation matrix and the variation of information (VI) distance matrix from a covariance estimator and data matrix.\n\nThis method returns a tuple containing the correlation matrix and the corresponding VI distance matrix, where the VI distance is a measure of dissimilarity between random variables based on their mutual information, estimated via histogram binning.\n\nArguments\n\nde::Distance{<:VariationInfoDistance}: Distance estimator with VariationInfoDistance algorithm.\nce: Covariance estimator (used to compute the correlation matrix).\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the correlation. If 2, the data is transposed.\nkwargs...: Additional keyword arguments passed to the correlation computation.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of correlation matrix and VI distance matrix.\n\nDetails\n\nThe number of bins and normalisation are taken from the VariationInfoDistance algorithm fields.\nIf dims == 2, the data matrix is transposed before computation.\n\nRelated\n\nDistance\nVariationInfoDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.distance-Tuple{Distance{<:CorrelationDistance}, CovarianceEstimator, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.distance","text":"distance(::Distance{<:CorrelationDistance}, ce::StatsBase.CovarianceEstimator,\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the correlation distance matrix from a covariance estimator and data matrix.\n\nThis method computes the correlation matrix using the provided covariance estimator ce and data matrix X, then transforms it into a distance matrix using the formula distance = sqrt(clamp(1 - ρ, 0, 1)), where ρ is the correlation coefficient.\n\nArguments\n\n::Distance{<:CorrelationDistance}: Distance estimator with CorrelationDistance algorithm.\nce: Covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation computation.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise correlation distances.\n\nRelated\n\nDistance\nCorrelationDistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.distance-Tuple{Distance{<:CorrelationDistance}, AbstractMatrix, Vararg{Any}}","page":"Distance","title":"PortfolioOptimisers.distance","text":"distance(::Distance{<:CorrelationDistance}, rho::AbstractMatrix, args...; kwargs...)\n\nCompute the correlation distance matrix from a correlation or covariance matrix.\n\nIf the input rho is a covariance matrix, it is first converted to a correlation matrix. The distance matrix is then computed using the formula distance = sqrt(clamp(1 - ρ, 0, 1)), where ρ is the correlation coefficient.\n\nArguments\n\n::Distance{<:CorrelationDistance}: Distance estimator with CorrelationDistance algorithm.\nrho: Correlation or covariance matrix.\nargs...: Additional arguments (ignored).\nkwargs...: Additional keyword arguments.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise correlation distances.\n\nDetails\n\nIf rho is a covariance matrix, it is converted to a correlation matrix using StatsBase.cov2cor.\n\nRelated\n\nDistance\nCorrelationDistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{Distance{<:CorrelationDistance}, CovarianceEstimator, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(::Distance{<:CorrelationDistance}, ce::StatsBase.CovarianceEstimator,\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the correlation matrix and the correlation distance matrix from a covariance estimator and data matrix.\n\nThis method returns a tuple containing the correlation matrix and the corresponding correlation distance matrix, where the distance is computed as sqrt(clamp(1 - ρ, 0, 1)), with ρ the correlation coefficient.\n\nArguments\n\n::Distance{<:CorrelationDistance}: Distance estimator with CorrelationDistance algorithm.\nce: Covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation computation.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of correlation matrix and correlation distance matrix.\n\nRelated\n\nDistance\nCorrelationDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.distance-Tuple{Distance{<:CanonicalDistance}, MutualInfoCovariance, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.distance","text":"distance(::Distance{<:CanonicalDistance}, ce::MutualInfoCovariance,\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the canonical distance matrix using a mutual information covariance estimator and data matrix.\n\nThis method dispatches to the VariationInfoDistance algorithm, using the number of bins and normalisation from the provided MutualInfoCovariance estimator.\n\nArguments\n\n::Distance{<:CanonicalDistance}: Distance estimator with CanonicalDistance algorithm.\nce::MutualInfoCovariance: Mutual information covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise canonical distances.\n\nRelated\n\nDistance\nVariationInfoDistance\nMutualInfoCovariance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.distance-Tuple{Distance{<:CanonicalDistance}, PortfolioOptimisersCovariance{<:MutualInfoCovariance}, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.distance","text":"distance(::Distance{<:CanonicalDistance},\n         ce::PortfolioOptimisersCovariance{<:MutualInfoCovariance, <:Any},\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the canonical distance matrix using a wrapped mutual information covariance estimator and data matrix.\n\nThis method dispatches to the VariationInfoDistance algorithm, using the number of bins and normalisation from the wrapped MutualInfoCovariance estimator.\n\nArguments\n\n::Distance{<:CanonicalDistance}: Distance estimator with CanonicalDistance algorithm.\nce: Wrapped mutual information covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise canonical distances.\n\nRelated\n\nDistance\nVariationInfoDistance\nMutualInfoCovariance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.distance-Tuple{Distance{<:CanonicalDistance}, Union{LTDCovariance, PortfolioOptimisersCovariance{<:LTDCovariance}}, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.distance","text":"distance(::Distance{<:CanonicalDistance},\n         ce::Union{<:LTDCovariance,\n                   <:PortfolioOptimisersCovariance{<:LTDCovariance, <:Any}},\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the canonical distance matrix using a lower tail dependence covariance estimator and data matrix.\n\nThis method dispatches to the LogDistance algorithm.\n\nArguments\n\n::Distance{<:CanonicalDistance}: Distance estimator with CanonicalDistance algorithm.\nce: LTD covariance estimator or a wrapped LTD estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise canonical distances.\n\nRelated\n\nDistance\nLogDistance\nLTDCovariance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.distance-Tuple{Distance{<:CanonicalDistance}, Union{DistanceCovariance, PortfolioOptimisersCovariance{<:DistanceCovariance}}, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.distance","text":"distance(::Distance{<:CanonicalDistance},\n         ce::Union{<:DistanceCovariance,\n                   <:PortfolioOptimisersCovariance{<:DistanceCovariance, <:Any}},\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the canonical distance matrix using a distance covariance estimator and data matrix.\n\nThis method dispatches to the CorrelationDistance algorithm.\n\nArguments\n\n::Distance{<:CanonicalDistance}: Distance estimator with CanonicalDistance algorithm.\nce: Distance covariance estimator or a wrapped distance covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise canonical distances.\n\nRelated\n\nDistance\nCorrelationDistance\nDistanceCovariance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.distance-Tuple{Distance{<:CanonicalDistance}, CovarianceEstimator, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.distance","text":"distance(::Distance{<:CanonicalDistance}, ce::StatsBase.CovarianceEstimator,\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the canonical distance matrix using a generic covariance estimator and data matrix.\n\nThis method dispatches to the SimpleDistance algorithm.\n\nArguments\n\n::Distance{<:CanonicalDistance}: Distance estimator with CanonicalDistance algorithm.\nce: Covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise canonical distances.\n\nRelated\n\nDistance\nSimpleDistance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.distance-Tuple{Distance{<:CanonicalDistance}, AbstractMatrix, Vararg{Any}}","page":"Distance","title":"PortfolioOptimisers.distance","text":"distance(::Distance{<:CanonicalDistance}, rho::AbstractMatrix, args...; kwargs...)\n\nCompute the canonical distance matrix from a correlation or covariance matrix.\n\nThis method dispatches to the SimpleDistance algorithm.\n\nArguments\n\n::Distance{<:CanonicalDistance}: Distance estimator with CanonicalDistance algorithm.\nrho: Correlation or covariance matrix.\nargs...: Additional arguments (ignored).\nkwargs...: Additional keyword arguments.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise canonical distances.\n\nRelated\n\nDistance\nSimpleDistance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{Distance{<:CanonicalDistance}, MutualInfoCovariance, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(::Distance{<:CanonicalDistance}, ce::MutualInfoCovariance,\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the correlation matrix and the canonical distance matrix using a mutual information covariance estimator and data matrix.\n\nThis method dispatches to the VariationInfoDistance algorithm, using the number of bins and normalisation from the provided MutualInfoCovariance estimator.\n\nArguments\n\n::Distance{<:CanonicalDistance}: Distance estimator with CanonicalDistance algorithm.\nce: Mutual information covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of correlation matrix and canonical distance matrix.\n\nRelated\n\nDistance\nVariationInfoDistance\nMutualInfoCovariance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{Distance{<:CanonicalDistance}, PortfolioOptimisersCovariance{<:MutualInfoCovariance}, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(::Distance{<:CanonicalDistance},\n             ce::PortfolioOptimisersCovariance{<:MutualInfoCovariance, <:Any},\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the correlation matrix and the canonical distance matrix using a wrapped mutual information covariance estimator and data matrix.\n\nThis method dispatches to the VariationInfoDistance algorithm, using the number of bins and normalisation from the wrapped MutualInfoCovariance estimator.\n\nArguments\n\n::Distance{<:CanonicalDistance}: Distance estimator with CanonicalDistance algorithm.\nce: Wrapped mutual information covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of correlation matrix and canonical distance matrix.\n\nRelated\n\nDistance\nVariationInfoDistance\nMutualInfoCovariance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{Distance{<:CanonicalDistance}, Union{LTDCovariance, PortfolioOptimisersCovariance{<:LTDCovariance}}, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(::Distance{<:CanonicalDistance},\n             ce::Union{<:LTDCovariance,\n                       <:PortfolioOptimisersCovariance{<:LTDCovariance, <:Any}},\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the correlation matrix and the canonical distance matrix using a lower tail dependence covariance estimator and data matrix.\n\nThis method dispatches to the LogDistance algorithm.\n\nArguments\n\n::Distance{<:CanonicalDistance}: Distance estimator with CanonicalDistance algorithm.\nce: LTD covariance estimator or a wrapped LTD estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of correlation matrix and canonical distance matrix.\n\nRelated\n\nDistance\nLogDistance\nLTDCovariance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{Distance{<:CanonicalDistance}, Union{DistanceCovariance, PortfolioOptimisersCovariance{<:DistanceCovariance}}, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(::Distance{<:CanonicalDistance},\n             ce::Union{<:DistanceCovariance,\n                       <:PortfolioOptimisersCovariance{<:DistanceCovariance, <:Any}},\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the correlation matrix and the canonical distance matrix using a distance covariance estimator and data matrix.\n\nThis method dispatches to the CorrelationDistance algorithm.\n\nArguments\n\n::Distance{<:CanonicalDistance}: Distance estimator with CanonicalDistance algorithm.\nce: Distance covariance estimator or a wrapped distance covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of correlation matrix and canonical distance matrix.\n\nRelated\n\nDistance\nCorrelationDistance\nDistanceCovariance\n\n\n\n\n\n","category":"method"},{"location":"008-2-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{Distance{<:CanonicalDistance}, CovarianceEstimator, AbstractMatrix}","page":"Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(::Distance{<:CanonicalDistance}, ce::StatsBase.CovarianceEstimator,\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the correlation matrix and the canonical distance matrix using a generic covariance estimator and data matrix.\n\nThis method dispatches to the SimpleDistance algorithm.\n\nArguments\n\n::Distance{<:CanonicalDistance}: Distance estimator with CanonicalDistance algorithm.\nce: Covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of correlation matrix and canonical distance matrix.\n\nRelated\n\nDistance\nSimpleDistance\n\n\n\n\n\n","category":"method"},{"location":"003-PosdefMatrix/#PosdefMatrix","page":"PosdefMatrix","title":"PosdefMatrix","text":"","category":"section"},{"location":"003-PosdefMatrix/#PortfolioOptimisers.Posdef","page":"PosdefMatrix","title":"PortfolioOptimisers.Posdef","text":"struct Posdef{T1} <: AbstractPosdefEstimator\n    alg::T1\nend\n\nA concrete estimator type for projecting a matrix to the nearest positive definite (PD) matrix, typically used for covariance or correlation matrices.\n\nFields\n\nalg: The algorithm used for the nearest correlation matrix projection.\n\nConstructor\n\nPosdef(; alg = NearestCorrelationMatrix.Newton)\n\nCreates a new Posdef with the specified algorithm.\n\nRelated\n\nAbstractPosdefEstimator\nposdef!\nposdef\n\n\n\n\n\n","category":"type"},{"location":"003-PosdefMatrix/#PortfolioOptimisers.Posdef-Tuple{}","page":"PosdefMatrix","title":"PortfolioOptimisers.Posdef","text":"Posdef(; alg = NearestCorrelationMatrix.Newton)\n\nConstructor for Posdef. Defaults to the NearestCorrelationMatrix.Newton algorithm.\n\nArguments\n\nalg: The algorithm used for the nearest correlation matrix projection.\n\nExamples\n\njulia> using LinearAlgebra\n\njulia> est = Posdef()\nPosdef\n  alg | UnionAll: NearestCorrelationMatrix.Newton\n\nRelated\n\nAbstractPosdefEstimator\nposdef!\nposdef\n\n\n\n\n\n","category":"method"},{"location":"003-PosdefMatrix/#PortfolioOptimisers.posdef!","page":"PosdefMatrix","title":"PortfolioOptimisers.posdef!","text":"posdef!(method::Posdef, X::AbstractMatrix)\nposdef!(::Nothing, args...)\n\nIn-place projection of a matrix to the nearest positive definite (PD) matrix using the specified estimator.\n\nIf method is nothing, this is a no-op and returns nothing.\nIf method is a Posdef, the algorithm specified in method.alg is used to project X to the nearest PD matrix. If X is already positive definite, it is left unchanged.\n\nFor covariance matrices, the function internally converts to a correlation matrix, applies the projection, and then rescales back to covariance.\n\nArguments\n\nmethod: The estimator specifying the projection algorithm.\nX: The matrix to be projected in-place.\n\nReturns\n\nnothing. The input matrix X is modified in-place.\n\nValidation\n\nIf the matrix cannot be made positive definite, a warning is emitted.\n\nExamples\n\njulia> using LinearAlgebra\n\njulia> est = Posdef()\nPosdef\n  alg | UnionAll: NearestCorrelationMatrix.Newton\n\njulia> X = [1.0 0.9; 0.9 1.0];\n\njulia> X[1, 2] = 2.0;  # Not PD\n\njulia> posdef!(est, X)\n\njulia> X\n2×2 Matrix{Float64}:\n 1.0  1.0\n 1.0  1.0\n\njulia> isposdef(X)\ntrue\n\nRelated\n\nposdef\nPosdef\n\n\n\n\n\n","category":"function"},{"location":"003-PosdefMatrix/#PortfolioOptimisers.posdef","page":"PosdefMatrix","title":"PortfolioOptimisers.posdef","text":"posdef(method::Posdef, X::AbstractMatrix)\nposdef(::Nothing, args...)\n\nSame as posdef!, but returns a new matrix instead of modifying X in-place.\n\nIf method is nothing, this is a no-op and returns nothing.\n\nExamples\n\njulia> using LinearAlgebra\n\njulia> est = Posdef();\n\njulia> X = [1.0 2.0; 0.9 1.0];  # Not PD\n\njulia> X_pd = posdef(est, X);\n\njulia> isposdef(X_pd)\ntrue\n\njulia> X_pd\n2×2 Matrix{Float64}:\n 1.0  1.0\n 1.0  1.0\n\nRelated\n\nposdef!\nPosdef\n\n\n\n\n\n","category":"function"},{"location":"003-PosdefMatrix/#PortfolioOptimisers.AbstractPosdefEstimator","page":"PosdefMatrix","title":"PortfolioOptimisers.AbstractPosdefEstimator","text":"AbstractPosdefEstimator <: AbstractEstimator\n\nAbstract supertype for all positive definite matrix estimator types in PortfolioOptimisers.jl.\n\nAll concrete types that implement positive definite matrix projection or estimation (e.g., for covariance or correlation matrices) should subtype AbstractPosdefEstimator. This enables a consistent interface for positive definite matrix estimation routines throughout the package.\n\nRelated\n\nAbstractEstimator\nPosdef\nposdef!\nposdef\n\n\n\n\n\n","category":"type"},{"location":"007-17-Moments/#Cokurtosis","page":"Cokurtosis","title":"Cokurtosis","text":"","category":"section"},{"location":"007-17-Moments/#PortfolioOptimisers.CokurtosisEstimator","page":"Cokurtosis","title":"PortfolioOptimisers.CokurtosisEstimator","text":"abstract type CokurtosisEstimator <: AbstractEstimator end\n\nAbstract supertype for all cokurtosis estimators in PortfolioOptimisers.jl.\n\nAll concrete types implementing cokurtosis estimation algorithms should subtype CokurtosisEstimator. This enables a consistent interface for cokurtosis-based higher moment estimators throughout the package.\n\nRelated\n\nCokurtosis\nAbstractEstimator\n\n\n\n\n\n","category":"type"},{"location":"007-17-Moments/#PortfolioOptimisers.Cokurtosis","page":"Cokurtosis","title":"PortfolioOptimisers.Cokurtosis","text":"struct Cokurtosis{T1, T2, T3} <: CokurtosisEstimator\n    me::T1\n    mp::T2\n    alg::T3\nend\n\nContainer type for cokurtosis estimators.\n\nCokurtosis encapsulates the mean estimator, matrix processing estimator, and moment algorithm for cokurtosis estimation. This enables modular workflows for higher-moment portfolio analysis.\n\nFields\n\nme: Mean estimator for expected returns.\nmp: Matrix processing estimator for cokurtosis tensors.\nalg: Moment algorithm.\n\nConstructor\n\nCokurtosis(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns(),\n            mp::AbstractMatrixProcessingEstimator = DefaultMatrixProcessing(),\n            alg::AbstractMomentAlgorithm = Full())\n\nConstruct a Cokurtosis estimator with the specified mean estimator, matrix processing estimator, and moment algorithm.\n\nRelated\n\nCokurtosisEstimator\nAbstractExpectedReturnsEstimator\nAbstractMatrixProcessingEstimator\nAbstractMomentAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"007-17-Moments/#PortfolioOptimisers.Cokurtosis-Tuple{}","page":"Cokurtosis","title":"PortfolioOptimisers.Cokurtosis","text":"Cokurtosis(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns(),\n            mp::AbstractMatrixProcessingEstimator = DefaultMatrixProcessing(),\n            alg::AbstractMomentAlgorithm = Full())\n\nConstruct a Cokurtosis estimator for cokurtosis computation.\n\nArguments\n\nme: Mean estimator for expected returns.\nmp: Matrix processing estimator.\nalg: Moment algorithm.\n\nReturns\n\nCokurtosis: Configured cokurtosis estimator.\n\nExamples\n\njulia> Cokurtosis()\nCokurtosis\n   me | SimpleExpectedReturns\n      |   w | nothing\n   mp | DefaultMatrixProcessing\n      |       pdm | Posdef\n      |           |   alg | UnionAll: NearestCorrelationMatrix.Newton\n      |   denoise | nothing\n      |    detone | nothing\n      |       alg | nothing\n  alg | Full()\n\nRelated\n\nAbstractExpectedReturnsEstimator\nAbstractMatrixProcessingEstimator\nAbstractMomentAlgorithm\n\n\n\n\n\n","category":"method"},{"location":"007-17-Moments/#PortfolioOptimisers._cokurtosis","page":"Cokurtosis","title":"PortfolioOptimisers._cokurtosis","text":"_cokurtosis(X::AbstractMatrix, mp::AbstractMatrixProcessingEstimator)\n\nInternal helper for cokurtosis computation.\n\n_cokurtosis computes the cokurtosis tensor for the input data matrix and applies matrix processing using the specified estimator.\n\nArguments\n\nX: Data matrix (observations × assets).\nmp: Matrix processing estimator.\n\nReturns\n\nckurt::Matrix{<:Real}: Cokurtosis tensor after matrix processing.\n\nRelated\n\nCokurtosis\nmatrix_processing!\ncokurtosis\n\n\n\n\n\n","category":"function"},{"location":"007-17-Moments/#PortfolioOptimisers.cokurtosis","page":"Cokurtosis","title":"PortfolioOptimisers.cokurtosis","text":"cokurtosis(ke::Union{Nothing, <:Cokurtosis}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\nCompute the cokurtosis tensor for a dataset.\n\nThis method computes the cokurtosis tensor using the estimator's mean and matrix processing algorithm. For Full, it uses all centered data; for Semi, it uses only negative deviations. If the estimator is nothing, returns nothing.\n\nArguments\n\nke::Cokurtosis{<:Any, <:Any, <:Full}: Cokurtosis estimator with Full moment algorithm.\nke::Cokurtosis{<:Any, <:Any, <:Semi}: Cokurtosis estimator with Semi moment algorithm.\nke::Nothing: No-op cokurtosis computation, returns nothing.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the mean.\nmean: Optional mean vector. If not provided, computed using the estimator's mean estimator.\nkwargs...: Additional keyword arguments passed to the mean estimator.\n\nReturns\n\nckurt::Matrix{<:Real}: Cokurtosis tensor (assets^2 × assets^2).\n\nExamples\n\njulia> using StableRNGs\n\njulia> rng = StableRNG(123456789);\n\njulia> X = randn(rng, 10, 2);\n\njulia> cokurtosis(Cokurtosis(), X)\n4×4 Matrix{Float64}:\n  1.33947   -0.246726  -0.246726   0.493008\n -0.246726   0.493008   0.493008  -0.201444\n -0.246726   0.493008   0.493008  -0.201444\n  0.493008  -0.201444  -0.201444   0.300335\n\nRelated\n\nCokurtosis\n_cokurtosis\n\n\n\n\n\n","category":"function"},{"location":"007-07-Moments/#Distance-Covariance","page":"Distance Covariance","title":"Distance Covariance","text":"","category":"section"},{"location":"007-07-Moments/#PortfolioOptimisers.DistanceCovariance","page":"Distance Covariance","title":"PortfolioOptimisers.DistanceCovariance","text":"struct DistanceCovariance{T1, T2, T3, T4, T5} <: AbstractCovarianceEstimator\n    dist::T1\n    args::T2\n    kwargs::T3\n    w::T4\n    threads::T5\nend\n\nA flexible container type for configuring and applying distance-based covariance estimators in PortfolioOptimisers.jl.\n\nDistanceCovariance encapsulates all components required for distance covariance or correlation estimation, including the distance metric, additional arguments and keyword arguments for the metric, optional weights, and parallel execution strategy. This enables modular and extensible workflows for robust covariance estimation using distance statistics.\n\nFields\n\ndist: Distance metric used for pairwise computations.\nargs: Additional positional arguments for the distance metric.\nkwargs: Additional keyword arguments for the distance metric.\nw: Optional weights for observations.\nthreads: Parallel execution strategy.\n\nConstructor\n\nDistanceCovariance(; dist::Distances.Metric = Distances.Euclidean(),\n                  args::Tuple = (), kwargs::NamedTuple = (;),\n                  w::Union{Nothing, <:AbstractWeights} = nothing,\n                  threads::FLoops.Transducers.Executor = ThreadedEx())\n\nConstruct a DistanceCovariance estimator with the specified metric, arguments, weights, and threading strategy.\n\nRelated\n\nAbstractCovarianceEstimator\nDistances.Metric\nStatsBase.AbstractWeights\nFLoops.Transducers.Executor\n\n\n\n\n\n","category":"type"},{"location":"007-07-Moments/#PortfolioOptimisers.DistanceCovariance-Tuple{}","page":"Distance Covariance","title":"PortfolioOptimisers.DistanceCovariance","text":"DistanceCovariance(; dist::Distances.Metric = Distances.Euclidean(),\n                   args::Tuple = (), kwargs::NamedTuple = (;),\n                   w::Union{Nothing, <:AbstractWeights} = nothing,\n                   threads::FLoops.Transducers.Executor = ThreadedEx())\n\nConstruct a DistanceCovariance estimator for robust distance-based covariance or correlation estimation.\n\nThis constructor creates a DistanceCovariance object using the specified distance metric, additional positional and keyword arguments, optional weights, and parallel execution strategy. The estimator is highly modular, allowing users to select from different distance metrics, provide custom arguments, and configure parallelism.\n\nArguments\n\ndist: Distance metric used for pairwise computations.\nargs: Additional positional arguments for the distance metric.\nkwargs: Additional keyword arguments for the distance metric.\nw: Optional weights for observations.\nthreads: Parallel execution strategy.\n\nReturns\n\nDistanceCovariance: A configured distance covariance estimator.\n\nExamples\n\njulia> ce = DistanceCovariance()\nDistanceCovariance\n     dist | Distances.Euclidean: Distances.Euclidean(0.0)\n     args | Tuple{}: ()\n   kwargs | @NamedTuple{}: NamedTuple()\n        w | nothing\n  threads | Transducers.ThreadedEx{@NamedTuple{}}: Transducers.ThreadedEx()\n\nRelated\n\nDistanceCovariance\nDistances.Metric\nStatsBase.AbstractWeights\nFLoops.Transducers.Executor\n\n\n\n\n\n","category":"method"},{"location":"007-07-Moments/#PortfolioOptimisers.cor_distance-Tuple{DistanceCovariance, AbstractVector, AbstractVector}","page":"Distance Covariance","title":"PortfolioOptimisers.cor_distance","text":"cor_distance(ce::DistanceCovariance, v1::AbstractVector, v2::AbstractVector)\n\nCompute the distance correlation between two vectors using a configured DistanceCovariance estimator.\n\nThis function calculates the distance correlation between v1 and v2 using the specified distance metric, optional weights, and any additional arguments or keyword arguments provided in the estimator. The computation follows the standard distance correlation procedure, centering the pairwise distance matrices and normalizing the result.\n\nArguments\n\nce: Distance covariance estimator.\nv1: First data vector.\nv2: Second data vector.\n\nReturns\n\nρ::Float64: The computed distance correlation between v1 and v2.\n\nDetails\n\nComputes pairwise distance matrices for v1 and v2 using the estimator's metric and configuration.\nCenters the distance matrices by subtracting row and column means and adding the grand mean.\nCalculates the squared distance covariance and normalizes to obtain the distance correlation.\n\nValidation\n\nAsserts that v1 and v2 have the same length and at least two elements.\n\nRelated\n\nDistanceCovariance\ncor_distance(ce::DistanceCovariance, X::AbstractMatrix)\n\n\n\n\n\n","category":"method"},{"location":"007-07-Moments/#PortfolioOptimisers.cov_distance-Tuple{DistanceCovariance, AbstractVector, AbstractVector}","page":"Distance Covariance","title":"PortfolioOptimisers.cov_distance","text":"cov_distance(ce::DistanceCovariance, v1::AbstractVector, v2::AbstractVector)\n\nCompute the distance covariance between two vectors using a configured DistanceCovariance estimator.\n\nThis function calculates the distance covariance between v1 and v2 using the specified distance metric, optional weights, and any additional arguments or keyword arguments provided in the estimator. The computation follows the standard distance covariance procedure, centering the pairwise distance matrices and aggregating the result.\n\nArguments\n\nce: Distance covariance estimator.\nv1: First data vector.\nv2: Second data vector.\n\nReturns\n\nrho::Real: The computed distance covariance between v1 and v2.\n\nDetails\n\nComputes pairwise distance matrices for v1 and v2 using the estimator's metric and configuration.\nCenters the distance matrices by subtracting row and column means and adding the grand mean.\nCalculates the squared distance covariance and returns its square root.\n\nValidation\n\nAsserts that v1 and v2 have the same length and at least two elements.\n\nRelated\n\nDistanceCovariance\ncov_distance(ce::DistanceCovariance, X::AbstractMatrix)\n\n\n\n\n\n","category":"method"},{"location":"007-07-Moments/#PortfolioOptimisers.cor_distance-Tuple{DistanceCovariance, AbstractMatrix}","page":"Distance Covariance","title":"PortfolioOptimisers.cor_distance","text":"cor_distance(ce::DistanceCovariance, X::AbstractMatrix)\n\nCompute the pairwise distance correlation matrix for all columns in a data matrix using a configured DistanceCovariance estimator.\n\nThis function calculates the distance correlation between each pair of columns in X, using the specified distance metric, optional weights, and parallel execution strategy. The resulting matrix is symmetric, with each entry representing the distance correlation between two assets.\n\nArguments\n\nce: Distance covariance estimator.\nX: Data matrix (observations × assets).\n\nReturns\n\nrho::Matrix{<:Real}: Distance correlation matrix.\n\nDetails\n\nIterates over all pairs of columns in X, computing the distance correlation for each pair using cor_distance(ce, v1, v2).\nParallelizes computation using the estimator's threads field.\n\nRelated\n\nDistanceCovariance\ncor_distance(ce::DistanceCovariance, v1::AbstractVector, v2::AbstractVector)\n\n\n\n\n\n","category":"method"},{"location":"007-07-Moments/#PortfolioOptimisers.cov_distance-Tuple{DistanceCovariance, AbstractMatrix}","page":"Distance Covariance","title":"PortfolioOptimisers.cov_distance","text":"cov_distance(ce::DistanceCovariance, X::AbstractMatrix)\n\nCompute the pairwise distance covariance matrix for all columns in a data matrix using a configured DistanceCovariance estimator.\n\nThis function calculates the distance covariance between each pair of columns in X, using the specified distance metric, optional weights, and parallel execution strategy. The resulting matrix is symmetric, with each entry representing the distance covariance between two assets.\n\nArguments\n\nce: Distance covariance estimator.\nX: Data matrix (observations × assets).\n\nReturns\n\nsigma::Matrix{<:Real}: Symmetric matrix of pairwise distance covariances.\n\nDetails\n\nIterates over all pairs of columns in X, computing the distance covariance for each pair using cov_distance(ce, v1, v2).\nParallelizes computation using the estimator's threads field.\n\nRelated\n\nDistanceCovariance\ncov_distance(ce::DistanceCovariance, v1::AbstractVector, v2::AbstractVector)\n\n\n\n\n\n","category":"method"},{"location":"007-07-Moments/#Statistics.cor-Tuple{DistanceCovariance, AbstractMatrix}","page":"Distance Covariance","title":"Statistics.cor","text":"Statistics.cor(ce::DistanceCovariance, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the pairwise distance correlation matrix for all columns in a data matrix using a configured DistanceCovariance estimator.\n\nArguments\n\nce: Distance covariance estimator.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute correlations.\nkwargs...: Additional keyword arguments (currently unused).\n\nReturns\n\nrho::Matrix{<:Real}: Symmetric matrix of pairwise distance correlations.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nExamples\n\njulia> ce = DistanceCovariance()\nDistanceCovariance\n     dist | Distances.Euclidean: Distances.Euclidean(0.0)\n     args | Tuple{}: ()\n   kwargs | @NamedTuple{}: NamedTuple()\n        w | nothing\n  threads | Transducers.ThreadedEx{@NamedTuple{}}: Transducers.ThreadedEx()\n\njulia> X = [1.0 2.0; 2.0 4.0; 3.0 6.0];\n\njulia> cor(ce, X)\n2×2 Matrix{Float64}:\n 1.0  1.0\n 1.0  1.0\n\nRelated\n\nDistanceCovariance\ncor_distance(ce::DistanceCovariance, X::AbstractMatrix)\ncov(ce::DistanceCovariance, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"007-07-Moments/#Statistics.cov-Tuple{DistanceCovariance, AbstractMatrix}","page":"Distance Covariance","title":"Statistics.cov","text":"Statistics.cov(ce::DistanceCovariance, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the pairwise distance covariance matrix for all columns in a data matrix using a configured DistanceCovariance estimator.\n\nArguments\n\nce: Distance covariance estimator.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute covariances.\nkwargs...: Additional keyword arguments (currently unused).\n\nReturns\n\nsigma::Matrix{<:Real}: Symmetric matrix of pairwise distance covariances.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nExamples\n\njulia> ce = DistanceCovariance()\nDistanceCovariance\n     dist | Distances.Euclidean: Distances.Euclidean(0.0)\n     args | Tuple{}: ()\n   kwargs | @NamedTuple{}: NamedTuple()\n        w | nothing\n  threads | Transducers.ThreadedEx{@NamedTuple{}}: Transducers.ThreadedEx()\n\njulia> X = [1.0 2.0; 2.0 4.0; 3.0 6.0];\n\njulia> cov(ce, X)\n2×2 Matrix{Float64}:\n 0.702728  0.993808\n 0.993808  1.40546\n\nRelated\n\nDistanceCovariance\ncov_distance(ce::DistanceCovariance, X::AbstractMatrix)\ncor(ce::DistanceCovariance, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"010-OWA/#Ordered-Weights-Array","page":"Ordered Weights Array","title":"Ordered Weights Array","text":"","category":"section"},{"location":"010-OWA/#PortfolioOptimisers.AbstractOrderedWeightsArrayEstimator","page":"Ordered Weights Array","title":"PortfolioOptimisers.AbstractOrderedWeightsArrayEstimator","text":"abstract type AbstractOrderedWeightsArrayEstimator <: AbstractEstimator end\n\nAbstract supertype for all Ordered Weights Array (OWA) estimator types in PortfolioOptimisers.jl.\n\nAll concrete types implementing OWA estimation algorithms should subtype AbstractOrderedWeightsArrayEstimator. This enables a consistent interface for OWA-based estimators throughout the package.\n\nRelated\n\nAbstractOrderedWeightsArrayAlgorithm\nOWAJuMP\nNormalisedConstantRelativeRiskAversion\n\n\n\n\n\n","category":"type"},{"location":"010-OWA/#PortfolioOptimisers.AbstractOrderedWeightsArrayAlgorithm","page":"Ordered Weights Array","title":"PortfolioOptimisers.AbstractOrderedWeightsArrayAlgorithm","text":"abstract type AbstractOrderedWeightsArrayAlgorithm <: AbstractAlgorithm end\n\nAbstract supertype for all Ordered Weights Array (OWA) algorithm types in PortfolioOptimisers.jl.\n\nAll concrete types implementing specific OWA algorithms should subtype AbstractOrderedWeightsArrayAlgorithm. This enables flexible extension and dispatch of OWA routines.\n\nRelated\n\nMaximumEntropy\nMinimumSquareDistance\nMinimumSumSquares\n\n\n\n\n\n","category":"type"},{"location":"010-OWA/#PortfolioOptimisers.MaximumEntropy","page":"Ordered Weights Array","title":"PortfolioOptimisers.MaximumEntropy","text":"struct MaximumEntropy <: AbstractOrderedWeightsArrayAlgorithm end\n\nRepresents the Maximum Entropy algorithm for Ordered Weights Array (OWA) estimation.\n\nThe Maximum Entropy algorithm seeks the OWA weights that maximize entropy, resulting in the most \"uninformative\" or uniform distribution of weights subject to the imposed constraints. This is often used as a default or reference OWA weighting scheme.\n\nRelated\n\nAbstractOrderedWeightsArrayAlgorithm\nOWAJuMP\n\n\n\n\n\n","category":"type"},{"location":"010-OWA/#PortfolioOptimisers.MinimumSquareDistance","page":"Ordered Weights Array","title":"PortfolioOptimisers.MinimumSquareDistance","text":"struct MinimumSquareDistance <: AbstractOrderedWeightsArrayAlgorithm end\n\nRepresents the Minimum Square Distance algorithm for Ordered Weights Array (OWA) estimation.\n\nThe Minimum Square Distance algorithm finds OWA weights that minimize the squared distance from a target or reference vector, subject to the OWA constraints. This approach is useful for regularizing OWA weights towards a desired profile.\n\nRelated\n\nAbstractOrderedWeightsArrayAlgorithm\nOWAJuMP\n\n\n\n\n\n","category":"type"},{"location":"010-OWA/#PortfolioOptimisers.MinimumSumSquares","page":"Ordered Weights Array","title":"PortfolioOptimisers.MinimumSumSquares","text":"struct MinimumSumSquares <: AbstractOrderedWeightsArrayAlgorithm end\n\nRepresents the Minimum Sum of Squares algorithm for Ordered Weights Array (OWA) estimation.\n\nThe Minimum Sum of Squares algorithm minimizes the sum of squared OWA weights, promoting sparsity or concentration in the resulting weights. This can be used to emphasize extreme order statistics in OWA-based risk measures.\n\nRelated\n\nAbstractOrderedWeightsArrayAlgorithm\nOWAJuMP\n\n\n\n\n\n","category":"type"},{"location":"010-OWA/#PortfolioOptimisers.NormalisedConstantRelativeRiskAversion","page":"Ordered Weights Array","title":"PortfolioOptimisers.NormalisedConstantRelativeRiskAversion","text":"struct NormalisedConstantRelativeRiskAversion{T1} <: AbstractOrderedWeightsArrayEstimator\n    g::T1\nend\n\nEstimator type for normalised constant relative risk aversion (CRRA) OWA weights.\n\nThis struct represents an estimator for Ordered Weights Array (OWA) weights based on a normalised constant relative risk aversion parameter g. The CRRA approach generates OWA weights that interpolate between risk-neutral and risk-averse profiles, controlled by the parameter g.\n\nFields\n\ng: Risk aversion parameter, must satisfy 0 < g < 1.\n\nConstructor\n\nNormalisedConstantRelativeRiskAversion(; g::Real = 0.5)\n\nRelated\n\nAbstractOrderedWeightsArrayEstimator\nowa_l_moment_crm\n\n\n\n\n\n","category":"type"},{"location":"010-OWA/#PortfolioOptimisers.NormalisedConstantRelativeRiskAversion-Tuple{}","page":"Ordered Weights Array","title":"PortfolioOptimisers.NormalisedConstantRelativeRiskAversion","text":"NormalisedConstantRelativeRiskAversion(; g::Real = 0.5)\n\nConstruct a NormalisedConstantRelativeRiskAversion estimator for OWA weights.\n\nCreates an estimator using the specified risk aversion parameter g, which must be in the open interval (0, 1). The resulting estimator can be used with OWA-based risk measures and moment calculations.\n\nArguments\n\ng: Risk aversion parameter.\n\nReturns\n\nNormalisedConstantRelativeRiskAversion: Configured estimator.\n\nValidation\n\nAsserts that 0 < g < 1.\n\nExamples\n\njulia> NormalisedConstantRelativeRiskAversion()\nNormalisedConstantRelativeRiskAversion\n  g | Float64: 0.5\n\nRelated\n\nNormalisedConstantRelativeRiskAversion\nowa_l_moment_crm\n\n\n\n\n\n","category":"method"},{"location":"010-OWA/#PortfolioOptimisers.OWAJuMP","page":"Ordered Weights Array","title":"PortfolioOptimisers.OWAJuMP","text":"struct OWAJuMP{T1, T2, T3, T4, T5} <: AbstractOrderedWeightsArrayEstimator\n    slv::T1\n    max_phi::T2\n    sc::T3\n    so::T4\n    alg::T5\nend\n\nEstimator type for OWA weights using JuMP-based optimization.\n\nOWAJuMP encapsulates all configuration required to estimate OWA weights via mathematical programming using JuMP. It supports multiple algorithms and solver backends, and allows fine control over constraints and scaling.\n\nFields\n\nslv: Solver or vector of solvers to use.\nmax_phi: Maximum allowed value for any OWA weight.\nsc: Scaling parameter for constraints.\nso: Scaling parameter for the objective.\nalg: Algorithm for OWA weight estimation.\n\nConstructor\n\nOWAJuMP(; slv::Union{<:Solver, <:AbstractVector{<:Solver}} = Solver(),\n         max_phi::Real = 0.5, sc::Real = 1.0, so::Real = 1.0,\n         alg::AbstractOrderedWeightsArrayAlgorithm = MaximumEntropy())\n\nRelated\n\nAbstractOrderedWeightsArrayEstimator\nAbstractOrderedWeightsArrayAlgorithm\nowa_l_moment_crm\nSolver\n\n\n\n\n\n","category":"type"},{"location":"010-OWA/#PortfolioOptimisers.OWAJuMP-Tuple{}","page":"Ordered Weights Array","title":"PortfolioOptimisers.OWAJuMP","text":"OWAJuMP(; slv::Union{<:Solver, <:AbstractVector{<:Solver}} = Solver(),\n         max_phi::Real = 0.5, sc::Real = 1.0, so::Real = 1.0,\n         alg::AbstractOrderedWeightsArrayAlgorithm = MaximumEntropy())\n\nConstruct a OWAJuMP estimator for OWA weights using JuMP-based optimization.\n\nCreates an estimator with the specified solver(s), maximum OWA weight, constraint/objective scaling, and OWA algorithm. This estimator can be used for flexible OWA weight estimation in portfolio optimization workflows.\n\nArguments\n\nslv: Solver or vector of solvers to use.\nmax_phi: Maximum allowed value for any OWA weight.\nsc: Scaling parameter for constraints.\nso: Scaling parameter for the objective.\nalg: Algorithm for OWA weight estimation.\n\nReturns\n\nOWAJuMP: Configured estimator.\n\nValidation\n\nAsserts that slv is non-empty if a vector.\nAsserts that 0 < max_phi < 1.\nAsserts that sc and so are positive and finite.\n\nExamples\n\njulia> OWAJuMP()\nOWAJuMP\n      slv | Solver\n          |          name | String: \"\"\n          |        solver | nothing\n          |      settings | nothing\n          |     check_sol | @NamedTuple{}: NamedTuple()\n          |   add_bridges | Bool: true\n  max_phi | Float64: 0.5\n       sc | Float64: 1.0\n       so | Float64: 1.0\n      alg | MaximumEntropy()\n\nRelated\n\nOWAJuMP\nAbstractOrderedWeightsArrayAlgorithm\nowa_l_moment_crm\n\n\n\n\n\n","category":"method"},{"location":"010-OWA/#PortfolioOptimisers.ncrra_weights","page":"Ordered Weights Array","title":"PortfolioOptimisers.ncrra_weights","text":"ncrra_weights(weights::AbstractMatrix{<:Real}, g::Real = 0.5)\n\nCompute normalised constant relative risk aversion (CRRA) Ordered Weights Array (OWA) weights.\n\nThis function generates OWA weights using a normalised CRRA scheme, parameterised by g. The CRRA approach interpolates between risk-neutral and risk-averse weighting profiles, controlled by the risk aversion parameter g. The resulting weights are normalised to sum to one and are suitable for use in OWA-based risk measures.\n\nArguments\n\nweights: Matrix of weights (typically order statistics or moment weights).\ng: Risk aversion parameter, must satisfy 0 < g < 1.\n\nReturns\n\nw::Vector: Vector of OWA weights, normalised to sum to one.\n\nDetails\n\nThe function computes the OWA weights as follows:\n\nFor each order statistic, recursively compute the CRRA weight using the formula:\ne *= g + i - 1\nphis[i] = e / factorial(i + 1)\nThe vector phis is normalised to sum to one.\nThe final OWA weights are computed as a weighted sum of the input weights and phis, with monotonicity enforced by taking the maximum up to each index.\n\nExamples\n\njulia> w = [1.0 0.5; 0.5 1.0]\n2×2 Matrix{Float64}:\n 1.0  0.5\n 0.5  1.0\n\njulia> PortfolioOptimisers.ncrra_weights(w, 0.5)\n2-element Vector{Float64}:\n 0.8333333333333333\n 0.8333333333333333\n\nRelated\n\nNormalisedConstantRelativeRiskAversion\nowa_l_moment_crm\n\n\n\n\n\n","category":"function"},{"location":"010-OWA/#PortfolioOptimisers.owa_model_setup","page":"Ordered Weights Array","title":"PortfolioOptimisers.owa_model_setup","text":"owa_model_setup(method::OWAJuMP, weights::AbstractMatrix{<:Real})\n\nConstruct a JuMP model for Ordered Weights Array (OWA) weight estimation.\n\nThis function sets up a JuMP optimization model for OWA weights, given an OWAJuMP estimator and a matrix of weights (e.g., order statistics or moment weights). The model includes variables for the OWA weights (phi) and auxiliary variables (theta), and enforces constraints for non-negativity, upper bounds, sum-to-one, monotonicity, and consistency with the input weights.\n\nArguments\n\nmethod: OWA estimator containing solver, scaling, and algorithm configuration.\nweights: Matrix of weights (typically order statistics or moment weights).\n\nReturns\n\nmodel::JuMP.Model: Configured JuMP model with variables and constraints for OWA weight estimation.\n\nConstraints\n\nphi (OWA weights) are non-negative and bounded above by max_phi.\nThe sum of phi is 1.\ntheta is constrained to be equal to the weighted sum of the input weights and phi.\nMonotonicity is enforced on phi and theta.\n\nRelated\n\nOWAJuMP\nowa_l_moment_crm\n\n\n\n\n\n","category":"function"},{"location":"010-OWA/#PortfolioOptimisers.owa_model_solve","page":"Ordered Weights Array","title":"PortfolioOptimisers.owa_model_solve","text":"owa_model_solve(model::JuMP.Model, method::OWAJuMP, weights::AbstractMatrix)\n\nSolve a JuMP model for OWA weight estimation and extract the resulting OWA weights.\n\nThis function solves the provided JuMP model using the solver(s) specified in the OWAJuMP estimator. If the optimization is successful, it extracts the OWA weights (phi), normalises them to sum to one, and computes the final OWA weights as a weighted sum with the input weights. If the optimization fails, a warning is issued and a fallback to ncrra_weights is used.\n\nArguments\n\nmodel: JuMP model for OWA weight estimation.\nmethod: OWA estimator containing solver configuration.\nweights: Matrix of weights (typically order statistics or moment weights).\n\nReturns\n\nw::Vector: Vector of OWA weights, normalised to sum to one.\n\nDetails\n\nIf the solver succeeds, the solution is extracted from the phi variable and normalised.\nIf the solver fails, a warning is issued and the fallback ncrra_weights(weights, 0.5) is returned.\n\nRelated\n\nowa_model_setup\nOWAJuMP\nncrra_weights\n\n\n\n\n\n","category":"function"},{"location":"010-OWA/#PortfolioOptimisers.owa_l_moment_crm","page":"Ordered Weights Array","title":"PortfolioOptimisers.owa_l_moment_crm","text":"owa_l_moment_crm(method::AbstractOrderedWeightsArrayEstimator, weights::AbstractMatrix{<:Real})\n\nCompute Ordered Weights Array (OWA) linear moment convex risk measure (CRM) weights using various estimation methods.\n\nThis function dispatches on the estimator method to compute OWA weights from a matrix of moment or order-statistic weights. It supports several OWA estimation approaches, including normalised constant relative risk aversion (CRRA) and JuMP-based optimization with different algorithms.\n\nArguments\n\nmethod::NormalisedConstantRelativeRiskAversion: Computes OWA weights using the normalised CRRA scheme, parameterised by the risk aversion parameter g in method. The resulting weights interpolate between risk-neutral and risk-averse profiles and are normalised to sum to one.\nmethod::OWAJuMP{<:Any, <:Any, <:Any, <:Any, <:MaximumEntropy}: Computes OWA weights by solving a maximum entropy optimization problem using JuMP. This yields the most \"uninformative\" or uniform OWA weights subject to the imposed constraints.\nmethod::OWAJuMP{<:Any, <:Any, <:Any, <:Any, <:MinimumSquareDistance}: Computes OWA weights by minimizing the squared distance from a target or reference vector, regularizing the OWA weights towards a desired profile.\nmethod::OWAJuMP{<:Any, <:Any, <:Any, <:Any, <:MinimumSumSquares}: Computes OWA weights by minimizing the sum of squared OWA weights, promoting sparsity or concentration in the resulting weights.\nweights: Matrix of weights (e.g., order statistics or moment weights).\n\nReturns\n\nw::Vector: Vector of OWA weights, normalised to sum to one.\n\nRelated\n\nNormalisedConstantRelativeRiskAversion\nOWAJuMP\nMaximumEntropy\nMinimumSquareDistance\nMinimumSumSquares\nncrra_weights\n\n\n\n\n\nowa_l_moment_crm(T::Integer; k::Integer = 2,\n                 method::AbstractOrderedWeightsArrayEstimator = NormalisedConstantRelativeRiskAversion())\n\nCompute the ordered weights array (OWA) linear moments convex risk measure (CRM) weights for a given number of observations and moment order.\n\nThis function constructs the OWA linear moment CRM weights matrix for order statistics of size T and moment orders from 2 up to k, and then applies the specified OWA estimation method to produce the final OWA weights.\n\nArguments\n\nT: Number of observations.\nk: Highest moment order to include.\nmethod: OWA estimator.\n\nValidation\n\nAsserts that k >= 2.\n\nReturns\n\nw::Vector: Vector of OWA weights of length T, normalised to sum to one.\n\nDetails\n\nConstructs a matrix of OWA moment weights for each moment order from 2 to k.\nApplies the specified OWA estimation method to aggregate the moment weights into a single OWA weight vector.\n\nRelated\n\nowa_l_moment\nNormalisedConstantRelativeRiskAversion\nOWAJuMP\n\n\n\n\n\n","category":"function"},{"location":"010-OWA/#PortfolioOptimisers.owa_l_moment","page":"Ordered Weights Array","title":"PortfolioOptimisers.owa_l_moment","text":"owa_l_moment(T::Integer, k::Integer = 2)\n\nCompute the linear moment weights for the linear moments convex risk measure (CRM).\n\nThis function returns the vector of weights for the OWA linear moment of order k for T observations. The weights are derived from combinatorial expressions and are used to construct higher-order moment risk measures.\n\nArguments\n\nT: Number of observations.\nk: Moment order.\n\nReturns\n\nw::Vector: Vector of OWA weights of length T.\n\nRelated\n\nowa_l_moment_crm\n\n\n\n\n\n","category":"function"},{"location":"007-20-Moments/#Dimensional-Reduction-Regression","page":"Dimensional Reduction Regression","title":"Dimensional Reduction Regression","text":"","category":"section"},{"location":"007-20-Moments/#PortfolioOptimisers.DimensionReductionTarget","page":"Dimensional Reduction Regression","title":"PortfolioOptimisers.DimensionReductionTarget","text":"abstract type DimensionReductionTarget <: AbstractRegressionAlgorithm end\n\nAbstract supertype for all dimension reduction regression algorithm targets in PortfolioOptimisers.jl.\n\nAll concrete types implementing dimension reduction algorithms for regression (such as PCA or PPCA) should subtype DimensionReductionTarget. This enables a consistent and extensible interface for specifying dimension reduction strategies within regression-based moment estimation.\n\nThese types are used to specify the dimension reduction method when constructing a DimensionReductionRegression estimator.\n\nRelated\n\nDimensionReductionRegression\nPCA\nPPCA\nAbstractRegressionAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"007-20-Moments/#PortfolioOptimisers.PCA","page":"Dimensional Reduction Regression","title":"PortfolioOptimisers.PCA","text":"struct PCA{T1} <: DimensionReductionTarget\n    kwargs::T1\nend\n\nPrincipal Component Analysis (PCA) dimension reduction target.\n\nPCA is used to specify principal component analysis as the dimension reduction method for regression-based moment estimation. The kwargs field stores keyword arguments to be passed to the underlying PCA implementation (e.g., from MultivariateStats.jl).\n\nFields\n\nkwargs: Keyword arguments for MultivariateStats.fit.\n\nRelated\n\nDimensionReductionTarget\nDimensionReductionRegression\nPPCA\n\n\n\n\n\n","category":"type"},{"location":"007-20-Moments/#PortfolioOptimisers.PCA-Tuple{}","page":"Dimensional Reduction Regression","title":"PortfolioOptimisers.PCA","text":"PCA(; kwargs::NamedTuple = (;))\n\nConstruct a PCA dimension reduction target.\n\nThis constructor creates a PCA object with the specified keyword arguments, which are passed to MultivariateStats.fit.\n\nArguments\n\nkwargs: Keyword arguments for configuring the PCA algorithm.\n\nReturns\n\nPCA: A PCA dimension reduction target.\n\nConstructor\n\nPCA(; kwargs::NamedTuple = (;))\n\nExamples\n\njulia> PCA()\nPCA\n  kwargs | @NamedTuple{}: NamedTuple()\n\nRelated\n\nPCA\nDimensionReductionTarget\nDimensionReductionRegression\n\n\n\n\n\n","category":"method"},{"location":"007-20-Moments/#StatsAPI.fit-Tuple{PCA, AbstractMatrix}","page":"Dimensional Reduction Regression","title":"StatsAPI.fit","text":"StatsAPI.fit(drtgt::PCA, X::AbstractMatrix)\n\nFit a Principal Component Analysis (PCA) model to the data matrix X using the configuration in drtgt.\n\nThis method applies PCA as a dimension reduction technique for regression-based moment estimation. The keyword arguments stored in drtgt.kwargs are passed to MultivariateStats.fit.\n\nArguments\n\ndrtgt: A PCA dimension reduction target, specifying keyword arguments for PCA.\nX: Data matrix (observations × features) to which PCA will be fitted.\n\nReturns\n\nmodel: A fitted PCA model object from MultivariateStats.jl.\n\nRelated\n\nPCA\nDimensionReductionTarget\nDimensionReductionRegression\n\n\n\n\n\n","category":"method"},{"location":"007-20-Moments/#PortfolioOptimisers.PPCA","page":"Dimensional Reduction Regression","title":"PortfolioOptimisers.PPCA","text":"struct PPCA{T1} <: DimensionReductionTarget\n    kwargs::T1\nend\n\nProbabilistic Principal Component Analysis (PPCA) dimension reduction target.\n\nPPCA is used to specify probabilistic principal component analysis as the dimension reduction method for regression-based moment estimation. The kwargs field stores keyword arguments to be passed to the underlying PPCA implementation (e.g., from MultivariateStats.jl).\n\nFields\n\nkwargs: Keyword arguments for MultivariateStats.fit.\n\nConstructor\n\nPPCA(; kwargs::NamedTuple = ())\n\nRelated\n\nDimensionReductionTarget\nDimensionReductionRegression\nPCA\n\n\n\n\n\n","category":"type"},{"location":"007-20-Moments/#PortfolioOptimisers.PPCA-Tuple{}","page":"Dimensional Reduction Regression","title":"PortfolioOptimisers.PPCA","text":"PPCA(; kwargs::NamedTuple = (;))\n\nConstruct a PPCA dimension reduction target.\n\nThis constructor creates a PPCA object with the specified keyword arguments, which are passed to the underlying PPCA algorithm.\n\nArguments\n\nkwargs: Keyword arguments for MultivariateStats.fit.\n\nReturns\n\nPPCA: A PPCA dimension reduction target.\n\nExamples\n\njulia> PPCA()\nPPCA\n  kwargs | @NamedTuple{}: NamedTuple()\n\nRelated\n\nPPCA\nDimensionReductionTarget\nDimensionReductionRegression\n\n\n\n\n\n","category":"method"},{"location":"007-20-Moments/#StatsAPI.fit-Tuple{PPCA, AbstractMatrix}","page":"Dimensional Reduction Regression","title":"StatsAPI.fit","text":"StatsAPI.fit(drtgt::PPCA, X::AbstractMatrix)\n\nFit a Probabilistic Principal Component Analysis (PPCA) model to the data matrix X using the configuration in drtgt.\n\nThis method applies PPCA as a dimension reduction technique for regression-based moment estimation. The keyword arguments stored in drtgt.kwargs are passed to MultivariateStats.fit.\n\nArguments\n\ndrtgt: A PPCA dimension reduction target, specifying keyword arguments for PPCA.\nX: Data matrix (observations × features) to which PPCA will be fitted.\n\nReturns\n\nmodel: A fitted PPCA model object from MultivariateStats.jl.\n\nRelated\n\nPPCA\nDimensionReductionTarget\nDimensionReductionRegression\n\n\n\n\n\n","category":"method"},{"location":"007-20-Moments/#PortfolioOptimisers.DimensionReductionRegression","page":"Dimensional Reduction Regression","title":"PortfolioOptimisers.DimensionReductionRegression","text":"struct DimensionReductionRegression{T1, T2, T3, T4} <: AbstractRegressionEstimator\n    me::T1\n    ve::T2\n    drtgt::T3\n    retgt::T4\nend\n\nEstimator for dimension reduction regression-based moment estimation.\n\nDimensionReductionRegression is a flexible estimator type for performing regression with dimension reduction, such as PCA or PPCA, as a preprocessing step. It allows users to specify the expected returns estimator, variance estimator, dimension reduction target (e.g., PCA, PPCA), and the regression target (e.g., LinearModel). This enables modular workflows for moment estimation in high-dimensional settings.\n\nFields\n\nme: Expected returns estimator.\nve: Variance estimator.\ndrtgt: Dimension reduction target.\nretgt: Regression target type.\n\nConstructor\n\nDimensionReductionRegression(;\n                             me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns(),\n                             ve::AbstractVarianceEstimator = SimpleVariance(),\n                             drtgt::DimensionReductionTarget = PCA(),\n                             retgt::AbstractRegressionTarget = LinearModel())\n\nRelated\n\nDimensionReductionRegression\nAbstractExpectedReturnsEstimator\nAbstractVarianceEstimator\nDimensionReductionTarget\nAbstractRegressionTarget\n\n\n\n\n\n","category":"type"},{"location":"007-20-Moments/#PortfolioOptimisers.DimensionReductionRegression-Tuple{}","page":"Dimensional Reduction Regression","title":"PortfolioOptimisers.DimensionReductionRegression","text":"DimensionReductionRegression(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns(),\n                              ve::AbstractVarianceEstimator = SimpleVariance(),\n                              drtgt::DimensionReductionTarget = PCA(),\n                              retgt::AbstractRegressionTarget = LinearModel())\n\nConstruct a DimensionReductionRegression estimator for regression-based moment estimation with dimension reduction.\n\nThis constructor creates a DimensionReductionRegression object with the specified expected returns estimator, variance estimator, dimension reduction target, and regression target.\n\nArguments\n\nme: Expected returns estimator.\nve: Variance estimator.\ndrtgt: Dimension reduction target.\nretgt: Regression target type.\n\nReturns\n\nDimensionReductionRegression: A configured dimension reduction regression estimator.\n\nExamples\n\njulia> DimensionReductionRegression()\nDimensionReductionRegression\n     me | SimpleExpectedReturns\n        |   w | nothing\n     ve | SimpleVariance\n        |          me | SimpleExpectedReturns\n        |             |   w | nothing\n        |           w | nothing\n        |   corrected | Bool: true\n  drtgt | PCA\n        |   kwargs | @NamedTuple{}: NamedTuple()\n  retgt | LinearModel\n        |   kwargs | @NamedTuple{}: NamedTuple()\n\nRelated\n\nDimensionReductionRegression\nAbstractExpectedReturnsEstimator\nAbstractVarianceEstimator\nDimensionReductionTarget\nAbstractRegressionTarget\n\n\n\n\n\n","category":"method"},{"location":"007-20-Moments/#PortfolioOptimisers.prep_dim_red_reg","page":"Dimensional Reduction Regression","title":"PortfolioOptimisers.prep_dim_red_reg","text":"prep_dim_red_reg(drtgt::DimensionReductionTarget, X::AbstractMatrix)\n\nPrepare data for dimension reduction regression.\n\nThis helper function standardizes the feature matrix X (using Z-score normalization), fits the specified dimension reduction model (e.g., PCA or PPCA), and projects the standardized data into the reduced-dimensional space. It returns the projected data (with an intercept column) and the projection matrix.\n\nArguments\n\ndrtgt: Dimension reduction target (e.g., PCA(), PPCA()).\nX: Feature matrix (observations × features) to be reduced.\n\nReturns\n\nx1::AbstractMatrix{<:Real}: Projected feature matrix with an intercept column prepended.\nVp::AbstractMatrix{<:Real}: Projection matrix from the fitted dimension reduction model.\n\nDetails\n\nStandardizes X using Z-score normalization (mean 0, variance 1).\nFits the dimension reduction model specified by drtgt to the standardized data.\nProjects the standardized data into the reduced space.\nPrepends a column of ones to the projected data for use as an intercept in regression.\n\nRelated\n\nDimensionReductionRegression\nPCA\nPPCA\n\n\n\n\n\n","category":"function"},{"location":"007-20-Moments/#PortfolioOptimisers.regression-Tuple{PortfolioOptimisers.AbstractRegressionTarget, AbstractVector, AbstractVector, AbstractVector, AbstractMatrix, AbstractMatrix}","page":"Dimensional Reduction Regression","title":"PortfolioOptimisers.regression","text":"regression(retgt::AbstractRegressionTarget, y::AbstractVector, mu::AbstractVector,\n           sigma::AbstractVector, x1::AbstractMatrix, Vp::AbstractMatrix)\n\nFit a regression model in reduced-dimensional space and recover coefficients in the original feature space.\n\nThis function fits a regression model (as specified by retgt) to the response vector y using the projected feature matrix x1 (typically obtained from a dimension reduction method such as PCA or PPCA). It then transforms the estimated coefficients from the reduced space back to the original feature space using the projection matrix Vp and rescales them by the standard deviations sigma. The intercept is adjusted to account for the mean of y and the means of the original features.\n\nArguments\n\nretgt: Regression target type (e.g., LinearModel()).\ny: Response vector.\nmu: Mean vector of the original features.\nsigma: Standard deviation vector of the original features.\nx1: Projected feature matrix with intercept column (from dimension reduction).\nVp: Projection matrix from the fitted dimension reduction model.\n\nReturns\n\nbeta::Vector{<:Real}: Vector of regression coefficients in the original feature space, with the intercept as the first element.\n\nDetails\n\nFits the regression model in the reduced space using x1 and y.\nExtracts the coefficients for the principal components (excluding the intercept).\nTransforms the coefficients back to the original feature space using Vp and rescales by sigma.\nComputes the intercept so that predictions are unbiased with respect to the means.\n\nRelated\n\nDimensionReductionRegression\nAbstractRegressionTarget\nprep_dim_red_reg\n\n\n\n\n\n","category":"method"},{"location":"007-20-Moments/#PortfolioOptimisers.regression-Tuple{DimensionReductionRegression, AbstractMatrix, AbstractMatrix}","page":"Dimensional Reduction Regression","title":"PortfolioOptimisers.regression","text":"regression(re::DimensionReductionRegression, X::AbstractMatrix, F::AbstractMatrix)\n\nApply dimension reduction regression to each column of a response matrix.\n\nThis method fits a regression model with dimension reduction (e.g., PCA or PPCA) to each column of the response matrix X, using the feature matrix F as predictors. For each response vector (column of X), the features are first standardized and projected into a lower-dimensional space using the dimension reduction target specified in re.drtgt. A regression model (specified by re.retgt) is then fitted in the reduced space, and the coefficients are mapped back to the original feature space.\n\nArguments\n\nre: Dimension reduction regression estimator specifying the expected returns estimator, variance estimator, dimension reduction target, and regression target.\nX: Response matrix (observations × targets/assets).\nF: Feature matrix (observations × features).\n\nReturns\n\nRegression: A regression result object containing:\nb: Vector of intercepts for each response.\nM: Matrix of coefficients for each response and feature (in the original feature space).\nL: Matrix of coefficients in the reduced (projected) space.\n\nDetails\n\nFor each column in X, the features in F are standardized, projected using the dimension reduction model, and a regression is fitted in the reduced space.\nThe resulting coefficients are transformed back to the original feature space and rescaled.\nThe output Regression object contains the intercepts, coefficient matrix in the original space, and the projected coefficients.\n\nRelated\n\nDimensionReductionRegression\nprep_dim_red_reg\nRegression\n\n\n\n\n\n","category":"method"},{"location":"011-4-DBTH/#Direct-Bubble-Hierarchy-Tree","page":"Direct Bubble Hierarchy Tree","title":"Direct Bubble Hierarchy Tree","text":"","category":"section"},{"location":"011-4-DBTH/#PortfolioOptimisers.AbstractSimilarityMatrixAlgorithm","page":"Direct Bubble Hierarchy Tree","title":"PortfolioOptimisers.AbstractSimilarityMatrixAlgorithm","text":"\n\n\n\n","category":"type"},{"location":"011-4-DBTH/#PortfolioOptimisers.PMFG_T2s","page":"Direct Bubble Hierarchy Tree","title":"PortfolioOptimisers.PMFG_T2s","text":"PMFG_T2s(W::AbstractMatrix{<:Real}, nargout::Integer = 3)\n\nConstructs a Triangulated Maximally Filtered Graph (TMFG) starting from a tetrahedron and recursively inserting vertices inside existing triangles (T2 move) in order to approximate a Maximal Planar Graph with the largest total weight, aka Planar Maximally Filtered Graph (PMFG). All weights are non-negative [1].\n\nArguments\n\nW: N×N matrix of non-negative weights.\nnargout: number of output arguments, the same arguments are always returne, this only controls whether some arguments are empty or not.\n\nOutputs\n\nA: adjacency matrix of the PMFG with weights.\ntri: list of triangles (triangular faces).\nclique3: list of 3-cliques taht are not triangular faces, all 3-cliques are given by [tri; clique3].\ncliques: list of all 4-cliques, if nargout <= 3, this will be returned as an empty array.\ncliqueTree: 4-cliques tree structure (adjacency matrix), if nargout <= 4, it is returned as an empty array.\n\n\n\n\n\n","category":"function"},{"location":"007-06-Moments/#Smyth-Broby-Covariance","page":"Smyth-Broby Covariance","title":"Smyth-Broby Covariance","text":"","category":"section"},{"location":"007-06-Moments/#PortfolioOptimisers.BaseSmythBrobyCovariance","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.BaseSmythBrobyCovariance","text":"abstract type BaseSmythBrobyCovariance <: BaseGerberCovariance end\n\nAbstract supertype for all Smyth-Broby covariance estimators in PortfolioOptimisers.jl.\n\nAll concrete types implementing Smyth-Broby covariance estimation algorithms should subtype BaseSmythBrobyCovariance. This enables a consistent interface for Smyth-Broby-based covariance estimators throughout the package.\n\nRelated\n\nSmythBrobyCovariance\nSmythBrobyCovarianceAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"007-06-Moments/#PortfolioOptimisers.SmythBrobyCovarianceAlgorithm","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.SmythBrobyCovarianceAlgorithm","text":"abstract type SmythBrobyCovarianceAlgorithm <: AbstractMomentAlgorithm end\n\nAbstract supertype for all Smyth-Broby covariance algorithm types in PortfolioOptimisers.jl.\n\nAll concrete types implementing specific Smyth-Broby covariance algorithms should subtype SmythBrobyCovarianceAlgorithm. This enables flexible extension and dispatch of Smyth-Broby covariance routines.\n\nThese types are used to specify the algorithm when constructing a SmythBrobyCovariance estimator.\n\nRelated\n\nBaseSmythBrobyCovariance\nUnNormalisedSmythBrobyCovarianceAlgorithm\nNormalisedSmythBrobyCovarianceAlgorithm\nSmythBrobyCovariance\n\n\n\n\n\n","category":"type"},{"location":"007-06-Moments/#PortfolioOptimisers.UnNormalisedSmythBrobyCovarianceAlgorithm","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.UnNormalisedSmythBrobyCovarianceAlgorithm","text":"abstract type UnNormalisedSmythBrobyCovarianceAlgorithm <: SmythBrobyCovarianceAlgorithm end\n\nAbstract supertype for all unnormalised Smyth-Broby covariance algorithm types.\n\nConcrete types implementing unnormalised Smyth-Broby covariance algorithms should subtype UnNormalisedSmythBrobyCovarianceAlgorithm.\n\nRelated\n\nSmythBrobyCovarianceAlgorithm\nSmythBroby0\nSmythBroby1\nSmythBroby2\nSmythBrobyGerber0\nSmythBrobyGerber1\nSmythBrobyGerber2\nSmythBrobyCovariance\n\n\n\n\n\n","category":"type"},{"location":"007-06-Moments/#PortfolioOptimisers.NormalisedSmythBrobyCovarianceAlgorithm","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.NormalisedSmythBrobyCovarianceAlgorithm","text":"abstract type NormalisedSmythBrobyCovarianceAlgorithm <: SmythBrobyCovarianceAlgorithm end\n\nAbstract supertype for all normalised Smyth-Broby covariance algorithm types. These Z-transform the data before applying the Smyth-Broby covariance algorithm.\n\nConcrete types implementing normalised Smyth-Broby covariance algorithms should subtype NormalisedSmythBrobyCovarianceAlgorithm.\n\nRelated\n\nSmythBrobyCovarianceAlgorithm\nNormalisedSmythBroby0\nNormalisedSmythBroby1\nNormalisedSmythBroby2\nNormalisedSmythBrobyGerber0\nNormalisedSmythBrobyGerber1\nNormalisedSmythBrobyGerber2\nSmythBrobyCovariance\n\n\n\n\n\n","category":"type"},{"location":"007-06-Moments/#PortfolioOptimisers.SmythBroby0","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.SmythBroby0","text":"struct SmythBroby0 <: UnNormalisedSmythBrobyCovarianceAlgorithm end\n\nImplements the original Smyth-Broby covariance algorithm (unnormalised variant).\n\nRelated\n\nUnNormalisedSmythBrobyCovarianceAlgorithm\nSmythBrobyCovariance\nSmythBroby1\nSmythBroby2\n\n\n\n\n\n","category":"type"},{"location":"007-06-Moments/#PortfolioOptimisers.SmythBroby1","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.SmythBroby1","text":"struct SmythBroby1 <: UnNormalisedSmythBrobyCovarianceAlgorithm end\n\nImplements the first variant of the Smyth-Broby covariance algorithm (unnormalised).\n\nRelated\n\nUnNormalisedSmythBrobyCovarianceAlgorithm\nSmythBrobyCovariance\nSmythBroby0\nSmythBroby2\n\n\n\n\n\n","category":"type"},{"location":"007-06-Moments/#PortfolioOptimisers.SmythBroby2","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.SmythBroby2","text":"struct SmythBroby2 <: UnNormalisedSmythBrobyCovarianceAlgorithm end\n\nImplements the second variant of the Smyth-Broby covariance algorithm (unnormalised).\n\nRelated\n\nUnNormalisedSmythBrobyCovarianceAlgorithm\nSmythBrobyCovariance\nSmythBroby0\nSmythBroby1\n\n\n\n\n\n","category":"type"},{"location":"007-06-Moments/#PortfolioOptimisers.SmythBrobyGerber0","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.SmythBrobyGerber0","text":"struct SmythBrobyGerber0 <: UnNormalisedSmythBrobyCovarianceAlgorithm end\n\nImplements the original Gerber-style variant of the Smyth-Broby covariance algorithm (unnormalised).\n\nRelated\n\nUnNormalisedSmythBrobyCovarianceAlgorithm\nSmythBrobyCovariance\nSmythBrobyGerber1\nSmythBrobyGerber2\n\n\n\n\n\n","category":"type"},{"location":"007-06-Moments/#PortfolioOptimisers.SmythBrobyGerber1","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.SmythBrobyGerber1","text":"struct SmythBrobyGerber1 <: UnNormalisedSmythBrobyCovarianceAlgorithm end\n\nImplements the first Gerber-style variant of the Smyth-Broby covariance algorithm (unnormalised).\n\nRelated\n\nUnNormalisedSmythBrobyCovarianceAlgorithm\nSmythBrobyCovariance\nSmythBrobyGerber0\nSmythBrobyGerber2\n\n\n\n\n\n","category":"type"},{"location":"007-06-Moments/#PortfolioOptimisers.SmythBrobyGerber2","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.SmythBrobyGerber2","text":"struct SmythBrobyGerber2 <: UnNormalisedSmythBrobyCovarianceAlgorithm end\n\nImplements the second Gerber-style variant of the Smyth-Broby covariance algorithm (unnormalised).\n\nRelated\n\nUnNormalisedSmythBrobyCovarianceAlgorithm\nSmythBrobyCovariance\nSmythBrobyGerber0\nSmythBrobyGerber1\n\n\n\n\n\n","category":"type"},{"location":"007-06-Moments/#PortfolioOptimisers.NormalisedSmythBroby0","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.NormalisedSmythBroby0","text":"struct NormalisedSmythBroby0 <: NormalisedSmythBrobyCovarianceAlgorithm end\n\nImplements the original Smyth-Broby covariance algorithm on Z-transformed data (normalised variant).\n\nRelated\n\nNormalisedSmythBrobyCovarianceAlgorithm\nSmythBrobyCovariance\nNormalisedSmythBroby1\nNormalisedSmythBroby2\n\n\n\n\n\n","category":"type"},{"location":"007-06-Moments/#PortfolioOptimisers.NormalisedSmythBroby1","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.NormalisedSmythBroby1","text":"struct NormalisedSmythBroby1 <: NormalisedSmythBrobyCovarianceAlgorithm end\n\nImplements the first variant of the Smyth-Broby covariance algorithm on Z-transformed data (normalised).\n\nRelated\n\nNormalisedSmythBrobyCovarianceAlgorithm\nSmythBrobyCovariance\nNormalisedSmythBroby0\nNormalisedSmythBroby2\n\n\n\n\n\n","category":"type"},{"location":"007-06-Moments/#PortfolioOptimisers.NormalisedSmythBroby2","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.NormalisedSmythBroby2","text":"struct NormalisedSmythBroby2 <: NormalisedSmythBrobyCovarianceAlgorithm end\n\nImplements the second variant of the Smyth-Broby covariance algorithm on Z-transformed data (normalised).\n\nRelated\n\nNormalisedSmythBrobyCovarianceAlgorithm\nSmythBrobyCovariance\nNormalisedSmythBroby0\nNormalisedSmythBroby1\n\n\n\n\n\n","category":"type"},{"location":"007-06-Moments/#PortfolioOptimisers.NormalisedSmythBrobyGerber0","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.NormalisedSmythBrobyGerber0","text":"struct NormalisedSmythBrobyGerber0 <: NormalisedSmythBrobyCovarianceAlgorithm end\n\nImplements the original Gerber-style variant of the Smyth-Broby covariance algorithm on Z-transformed data (normalised).\n\nRelated\n\nNormalisedSmythBrobyCovarianceAlgorithm\nSmythBrobyCovariance\nNormalisedSmythBrobyGerber1\nNormalisedSmythBrobyGerber2\n\n\n\n\n\n","category":"type"},{"location":"007-06-Moments/#PortfolioOptimisers.NormalisedSmythBrobyGerber1","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.NormalisedSmythBrobyGerber1","text":"struct NormalisedSmythBrobyGerber1 <: NormalisedSmythBrobyCovarianceAlgorithm end\n\nImplements the first Gerber-style variant of the Smyth-Broby covariance algorithm on Z-transformed data (normalised).\n\nRelated\n\nNormalisedSmythBrobyCovarianceAlgorithm\nSmythBrobyCovariance\nNormalisedSmythBrobyGerber0\nNormalisedSmythBrobyGerber2\n\n\n\n\n\n","category":"type"},{"location":"007-06-Moments/#PortfolioOptimisers.NormalisedSmythBrobyGerber2","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.NormalisedSmythBrobyGerber2","text":"struct NormalisedSmythBrobyGerber2 <: NormalisedSmythBrobyCovarianceAlgorithm end\n\nImplements the second Gerber-style variant of the Smyth-Broby covariance algorithm on Z-transformed data (normalised).\n\nRelated\n\nNormalisedSmythBrobyCovarianceAlgorithm\nSmythBrobyCovariance\nNormalisedSmythBrobyGerber0\nNormalisedSmythBrobyGerber1\n\n\n\n\n\n","category":"type"},{"location":"007-06-Moments/#PortfolioOptimisers.SmythBrobyCovariance","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.SmythBrobyCovariance","text":"struct SmythBrobyCovariance{T1, T2, T3, T4, T5, T6, T7, T8, T9, T10} <:\n       BaseSmythBrobyCovariance\n    me::T1\n    ve::T2\n    pdm::T3\n    threshold::T4\n    c1::T5\n    c2::T6\n    c3::T7\n    n::T8\n    alg::T9\n    threads::T10\nend\n\nA flexible container type for configuring and applying Smyth-Broby covariance estimators in PortfolioOptimisers.jl.\n\nSmythBrobyCovariance encapsulates all components required for Smyth-Broby-based covariance or correlation estimation, including the expected returns estimator, variance estimator, positive definite matrix estimator, algorithm parameters, and the specific Smyth-Broby algorithm variant. This enables modular and extensible workflows for robust covariance estimation using Smyth-Broby statistics.\n\nFields\n\nme: Expected returns estimator.\nve: Variance estimator.\npdm: Positive definite matrix estimator (see Posdef).\nthreshold: Threshold parameter for Smyth-Broby covariance computation (typically in (0, 1)).\nc1: Zone of confusion parameter (typically in (0, 1]).\nc2: Zone of indecision lower bound (typically in (0, 1]).\nc3: Zone of indecision upper bound (must satisfy c3 > c2).\nn: Exponent parameter for the Smyth-Broby kernel.\nalg: Smyth-Broby covariance algorithm variant.\nthreads: Parallel execution strategy.\n\nConstructor\n\nSmythBrobyCovariance(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns(),\n                      ve::StatsBase.CovarianceEstimator = SimpleVariance(),\n                      pdm::Union{Nothing, <:Posdef} = Posdef(),\n                      threshold::Real = 0.5, c1::Real = 0.5, c2::Real = 0.5,\n                      c3::Real = 4.0, n::Real = 2.0,\n                      alg::SmythBrobyCovarianceAlgorithm = SmythBrobyGerber1(),\n                      threads::FLoops.Transducers.Executor = ThreadedEx())\n\nConstruct a SmythBrobyCovariance estimator with the specified algorithm, estimators, parameters, and threading strategy.\n\nRelated\n\nBaseSmythBrobyCovariance\nAbstractExpectedReturnsEstimator\nSimpleExpectedReturns\nStatsBase.CovarianceEstimator\nSimpleVariance\nPosdef\nSmythBrobyCovarianceAlgorithm\nSmythBroby0\nSmythBroby1\nSmythBroby2\nNormalisedSmythBroby0\nNormalisedSmythBroby1\nNormalisedSmythBroby2\nSmythBrobyGerber0\nSmythBrobyGerber1\nSmythBrobyGerber2\nNormalisedSmythBrobyGerber0\nNormalisedSmythBrobyGerber1\nNormalisedSmythBrobyGerber2\nFLoops.Transducers.Executor\n\n\n\n\n\n","category":"type"},{"location":"007-06-Moments/#PortfolioOptimisers.SmythBrobyCovariance-Tuple{}","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.SmythBrobyCovariance","text":"SmythBrobyCovariance(;\n    me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns(),\n    ve::StatsBase.CovarianceEstimator = SimpleVariance(),\n    pdm::Union{Nothing, <:Posdef} = Posdef(),\n    threshold::Real = 0.5,\n    c1::Real = 0.5,\n    c2::Real = 0.5,\n    c3::Real = 4.0,\n    n::Real = 2.0,\n    alg::SmythBrobyCovarianceAlgorithm = SmythBrobyGerber1(),\n    threads::FLoops.Transducers.Executor = ThreadedEx()\n)\n\nConstruct a SmythBrobyCovariance estimator for robust Smyth-Broby-based covariance or correlation estimation.\n\nThis constructor creates a SmythBrobyCovariance object using the specified Smyth-Broby algorithm, expected returns estimator, variance estimator, positive definite matrix estimator, algorithm parameters, and threading strategy. The estimator is highly modular, allowing users to select from different Smyth-Broby algorithm variants, as well as custom estimators and parallel execution strategies.\n\nArguments\n\nme: Expected returns estimator.\nve: Variance estimator.\npdm: Positive definite matrix estimator.\nthreshold: Threshold parameter for Smyth-Broby covariance computation (must satisfy 0 < threshold < 1).\nc1: Zone of confusion parameter (must satisfy 0 < c1 ≤ 1).\nc2: Zone of indecision lower bound (must satisfy 0 < c2 ≤ 1).\nc3: Zone of indecision upper bound (must satisfy c3 > c2).\nn: Exponent parameter for the Smyth-Broby kernel.\nalg: Smyth-Broby covariance algorithm variant.\nthreads: Parallel execution strategy.\n\nReturns\n\nSmythBrobyCovariance: A configured Smyth-Broby covariance estimator.\n\nValidation\n\nAsserts that threshold is strictly in (0, 1).\nAsserts that c1 is in (0, 1].\nAsserts that c2 is in (0, 1] and c3 > c2.\n\nExamples\n\njulia> ce = SmythBrobyCovariance()\nSmythBrobyCovariance\n         me | SimpleExpectedReturns\n            |   w | nothing\n         ve | SimpleVariance\n            |          me | SimpleExpectedReturns\n            |             |   w | nothing\n            |           w | nothing\n            |   corrected | Bool: true\n        pdm | Posdef\n            |   alg | UnionAll: NearestCorrelationMatrix.Newton\n  threshold | Float64: 0.5\n         c1 | Float64: 0.5\n         c2 | Float64: 0.5\n         c3 | Float64: 4.0\n          n | Float64: 2.0\n        alg | SmythBrobyGerber1()\n    threads | Transducers.ThreadedEx{@NamedTuple{}}: Transducers.ThreadedEx()\n\nRelated\n\nSmythBrobyCovariance\nBaseSmythBrobyCovariance\nAbstractExpectedReturnsEstimator\nSimpleExpectedReturns\nStatsBase.CovarianceEstimator\nSimpleVariance\nPosdef\nSmythBrobyCovarianceAlgorithm\nSmythBroby0\nSmythBroby1\nSmythBroby2\nNormalisedSmythBroby0\nNormalisedSmythBroby1\nNormalisedSmythBroby2\nSmythBrobyGerber0\nSmythBrobyGerber1\nSmythBrobyGerber2\nNormalisedSmythBrobyGerber0\nNormalisedSmythBrobyGerber1\nNormalisedSmythBrobyGerber2\nFLoops.Transducers.Executor\n\n\n\n\n\n","category":"method"},{"location":"007-06-Moments/#PortfolioOptimisers.sb_delta","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.sb_delta","text":"sb_delta(xi::Real, xj::Real, mui::Real, muj::Real, sigmai::Real, sigmaj::Real,\n         c1::Real, c2::Real, c3::Real, n::Real)\n\nSmyth-Broby kernel function for covariance and correlation computation.\n\nThis function computes the kernel value for a pair of asset returns, applying the Smyth-Broby logic for zones of confusion and indecision. It is used to aggregate positive and negative co-movements in Smyth-Broby covariance algorithms.\n\nArguments\n\nxi: Return for asset i.\nxj: Return for asset j.\nmui: Mean for asset i.\nmuj: Mean for asset j.\nsigmai: Standard deviation for asset i.\nsigmaj: Standard deviation for asset j.\nc1: Zone of confusion parameter (typically in (0, 1]).\nc2: Zone of indecision lower bound (typically in (0, 1]).\nc3: Zone of indecision upper bound (must satisfy c3 > c2).\nn: Exponent parameter for the kernel.\n\nReturns\n\nscore::Real: The computed score for the pair (xi, xj).\n\nDetails\n\nIf both returns are within the zone of confusion (abs(xi) < sigmai * c1 and abs(xj) < sigmaj * c1), returns zero.\nComputes centered and scaled returns ri, rj.\nIf both are within the zone of indecision (ri < c2 && rj < c2) or both are above the upper bound (ri > c3 && rj > c3), returns zero.\nOtherwise, returns sqrt((1 + ri) * (1 + rj)) / (1 + abs(ri - rj)^n).\n\nRelated\n\nSmythBrobyCovariance\nsmythbroby\n\n\n\n\n\n","category":"function"},{"location":"007-06-Moments/#PortfolioOptimisers.smythbroby-Tuple{SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBroby0}, AbstractMatrix, AbstractArray, AbstractArray}","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.smythbroby","text":"smythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any,\n                                    <:Any, <:Any, <:SmythBroby0, <:Any},\n           X::AbstractMatrix, mean_vec::AbstractArray, std_vec::AbstractArray)\n\nImplements the original Smyth-Broby covariance/correlation algorithm (unnormalised variant).\n\nThis method computes the Smyth-Broby correlation or covariance matrix for the input data matrix X using the original SmythBroby0 algorithm. The computation is based on thresholding the data, applying the Smyth-Broby kernel, and aggregating positive and negative co-movements.\n\nArguments\n\nce: Smyth-Broby covariance estimator configured with the SmythBroby0 algorithm.\nX: Data matrix (observations × assets).\nmean_vec: Vector of means for each asset, used for centering.\nstd_vec: Vector of standard deviations for each asset, used for scaling and thresholding.\n\nReturns\n\nrho::Matrix{<:Real}: The Smyth-Broby correlation matrix, projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each pair of assets (i, j), iterate over all observations.\nFor each observation, compute the centered and scaled returns for assets i and j.\nApply the threshold to classify joint positive and negative co-movements.\nUse the sb_delta kernel to accumulate positive (pos) and negative (neg) contributions.\nThe correlation is computed as (pos - neg) / (pos + neg) if the denominator is nonzero, otherwise zero.\nThe resulting matrix is projected to the nearest positive definite matrix using posdef!.\n\nRelated\n\nSmythBrobyCovariance\nSmythBroby0\nsb_delta\nposdef!\n\n\n\n\n\n","category":"method"},{"location":"007-06-Moments/#PortfolioOptimisers.smythbroby-Tuple{SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBroby0}, AbstractMatrix}","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.smythbroby","text":"smythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any,\n                                    <:Any, <:Any, <:NormalisedSmythBroby0, <:Any},\n           X::AbstractMatrix)\n\nImplements the original Smyth-Broby covariance/correlation algorithm on Z-transformed data (normalised variant).\n\nThis method computes the Smyth-Broby correlation or covariance matrix for the input data matrix X using the original NormalisedSmythBroby0 algorithm. The computation is performed on data that has already been Z-transformed (mean-centered and standardised), and is based on thresholding the data, applying the Smyth-Broby kernel, and aggregating positive and negative co-movements.\n\nArguments\n\nce: Smyth-Broby covariance estimator configured with the NormalisedSmythBroby0 algorithm.\nX: Z-transformed data matrix (observations × assets).\n\nReturns\n\nrho::Matrix{<:Real}: The Smyth-Broby correlation matrix, projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each pair of assets (i, j), iterate over all observations.\nFor each observation, use the Z-transformed returns for assets i and j.\nApply the threshold to classify joint positive and negative co-movements.\nUse the sb_delta kernel (with mean 0 and standard deviation 1) to accumulate positive (pos) and negative (neg) contributions.\nThe correlation is computed as (pos - neg) / (pos + neg) if the denominator is nonzero, otherwise zero.\nThe resulting matrix is projected to the nearest positive definite matrix using posdef!.\n\nRelated\n\nSmythBrobyCovariance\nNormalisedSmythBroby0\nsb_delta\nposdef!\n\n\n\n\n\n","category":"method"},{"location":"007-06-Moments/#PortfolioOptimisers.smythbroby-Tuple{SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBroby1}, AbstractMatrix, AbstractArray, AbstractArray}","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.smythbroby","text":"smythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any,\n                                    <:Any, <:Any, <:NormalisedSmythBroby0, <:Any},\n           X::AbstractMatrix)\n\nImplements the original Smyth-Broby covariance/correlation algorithm on Z-transformed data (normalised variant).\n\nThis method computes the Smyth-Broby correlation or covariance matrix for the input data matrix X using the original NormalisedSmythBroby0 algorithm. The computation is performed on data that has already been Z-transformed (mean-centered and standardised), and is based on thresholding the data, applying the Smyth-Broby kernel, and aggregating positive and negative co-movements.\n\nArguments\n\nce: Smyth-Broby covariance estimator configured with the NormalisedSmythBroby0 algorithm.\nX: Z-transformed data matrix (observations × assets).\n\nReturns\n\nrho::Matrix{<:Real}: The Smyth-Broby correlation matrix, projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each pair of assets (i, j), iterate over all observations.\nFor each observation, use the Z-transformed returns for assets i and j.\nApply the threshold to classify joint positive and negative co-movements.\nUse the sb_delta kernel (with mean 0 and standard deviation 1) to accumulate positive (pos) and negative (neg) contributions.\nThe correlation is computed as (pos - neg) / (pos + neg) if the denominator is nonzero, otherwise zero.\nThe resulting matrix is projected to the nearest positive definite matrix using posdef!.\n\nRelated\n\nSmythBrobyCovariance\nNormalisedSmythBroby0\nsb_delta\nposdef!\n\n\n\n\n\n","category":"method"},{"location":"007-06-Moments/#PortfolioOptimisers.smythbroby-Tuple{SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBroby1}, AbstractMatrix}","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.smythbroby","text":"smythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any,\n                                    <:Any, <:Any, <:NormalisedSmythBroby1, <:Any},\n           X::AbstractMatrix)\n\nImplements the first variant of the Smyth-Broby covariance/correlation algorithm on Z-transformed data (normalised).\n\nThis method computes the Smyth-Broby correlation or covariance matrix for the input data matrix X using the NormalisedSmythBroby1 algorithm. The computation is performed on data that has already been Z-transformed (mean-centered and standardised), and is based on thresholding the data, applying the Smyth-Broby kernel, and aggregating positive, negative, and neutral (non-exceedance) co-movements.\n\nArguments\n\nce: Smyth-Broby covariance estimator configured with the NormalisedSmythBroby1 algorithm.\nX: Z-transformed data matrix (observations × assets).\n\nReturns\n\nrho::Matrix{<:Real}: The Smyth-Broby correlation matrix, projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each pair of assets (i, j), iterate over all observations.\nFor each observation, use the Z-transformed returns for assets i and j.\nApply the threshold to classify joint positive, negative, and neutral co-movements.\nUse the sb_delta kernel (with mean 0 and standard deviation 1) to accumulate positive (pos), negative (neg), and neutral (nn) contributions.\nThe correlation is computed as (pos - neg) / (pos + neg + nn) if the denominator is nonzero, otherwise zero.\nThe resulting matrix is projected to the nearest positive definite matrix using posdef!.\n\nRelated\n\nSmythBrobyCovariance\nNormalisedSmythBroby1\nsb_delta\nposdef!\n\n\n\n\n\n","category":"method"},{"location":"007-06-Moments/#PortfolioOptimisers.smythbroby-Tuple{SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBroby2}, AbstractMatrix, AbstractArray, AbstractArray}","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.smythbroby","text":"smythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any,\n                                    <:Any, <:Any, <:SmythBroby2, <:Any},\n           X::AbstractMatrix, mean_vec::AbstractArray, std_vec::AbstractArray)\n\nImplements the second variant of the Smyth-Broby covariance/correlation algorithm (unnormalised).\n\nThis method computes the Smyth-Broby correlation or covariance matrix for the input data matrix X using the SmythBroby2 algorithm. The computation is based on thresholding the data, applying the Smyth-Broby kernel, and aggregating positive and negative co-movements. The resulting matrix is then normalised by the geometric mean of its diagonal elements.\n\nArguments\n\nce: Smyth-Broby covariance estimator configured with the SmythBroby2 algorithm.\nX: Data matrix (observations × assets).\nmean_vec: Vector of means for each asset, used for centering.\nstd_vec: Vector of standard deviations for each asset, used for scaling and thresholding.\n\nReturns\n\nrho::Matrix{<:Real}: The Smyth-Broby correlation matrix, normalised and projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each pair of assets (i, j), iterate over all observations.\nFor each observation, compute the centered and scaled returns for assets i and j.\nApply the threshold to classify joint positive and negative co-movements.\nUse the sb_delta kernel to accumulate positive (pos) and negative (neg) contributions.\nThe raw correlation is computed as pos - neg.\nThe resulting matrix is normalised by dividing each element by the geometric mean of the corresponding diagonal elements.\nThe matrix is projected to the nearest positive definite matrix using posdef!.\n\nRelated\n\nSmythBrobyCovariance\nSmythBroby2\nsb_delta\nposdef!\n\n\n\n\n\n","category":"method"},{"location":"007-06-Moments/#PortfolioOptimisers.smythbroby-Tuple{SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBroby2}, AbstractMatrix}","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.smythbroby","text":"smythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any,\n                                    <:Any, <:Any, <:NormalisedSmythBroby2, <:Any},\n           X::AbstractMatrix)\n\nImplements the second variant of the Smyth-Broby covariance/correlation algorithm on Z-transformed data (normalised).\n\nThis method computes the Smyth-Broby correlation or covariance matrix for the input data matrix X using the NormalisedSmythBroby2 algorithm. The computation is performed on data that has already been Z-transformed (mean-centered and standardised), and is based on thresholding the data, applying the Smyth-Broby kernel, and aggregating positive and negative co-movements. The resulting matrix is then normalised by the geometric mean of its diagonal elements.\n\nArguments\n\nce: Smyth-Broby covariance estimator configured with the NormalisedSmythBroby2 algorithm.\nX: Z-transformed data matrix (observations × assets).\n\nReturns\n\nrho::Matrix{<:Real}: The Smyth-Broby correlation matrix, normalised and projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each pair of assets (i, j), iterate over all observations.\nFor each observation, use the Z-transformed returns for assets i and j.\nApply the threshold to classify joint positive and negative co-movements.\nUse the sb_delta kernel (with mean 0 and standard deviation 1) to accumulate positive (pos) and negative (neg) contributions.\nThe raw correlation is computed as pos - neg.\nThe resulting matrix is normalised by dividing each element by the geometric mean of the corresponding diagonal elements.\nThe matrix is projected to the nearest positive definite matrix using posdef!.\n\nRelated\n\nSmythBrobyCovariance\nNormalisedSmythBroby2\nsb_delta\nposdef!\n\n\n\n\n\n","category":"method"},{"location":"007-06-Moments/#PortfolioOptimisers.smythbroby-Tuple{SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBrobyGerber0}, AbstractMatrix, AbstractArray, AbstractArray}","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.smythbroby","text":"smythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any,\n                                    <:Any, <:Any, <:SmythBrobyGerber0, <:Any},\n           X::AbstractMatrix, mean_vec::AbstractArray, std_vec::AbstractArray)\n\nImplements the original Gerber-style variant of the Smyth-Broby covariance/correlation algorithm (unnormalised).\n\nThis method computes the Smyth-Broby correlation or covariance matrix for the input data matrix X using the SmythBrobyGerber0 algorithm. The computation is based on thresholding the data, applying the Smyth-Broby kernel, and aggregating positive and negative co-movements, with additional weighting by the count of co-movements.\n\nArguments\n\nce: Smyth-Broby covariance estimator configured with the SmythBrobyGerber0 algorithm.\nX: Data matrix (observations × assets).\nmean_vec: Vector of means for each asset, used for centering.\nstd_vec: Vector of standard deviations for each asset, used for scaling and thresholding.\n\nReturns\n\nrho::Matrix{<:Real}: The Smyth-Broby correlation matrix, projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each pair of assets (i, j), iterate over all observations.\nFor each observation, compute the centered and scaled returns for assets i and j.\nApply the threshold to classify joint positive and negative co-movements.\nUse the sb_delta kernel to accumulate positive (pos) and negative (neg) contributions, and count the number of positive (cpos) and negative (cneg) co-movements.\nThe correlation is computed as (pos * cpos - neg * cneg) / (pos * cpos + neg * cneg) if the denominator is nonzero, otherwise zero.\nThe resulting matrix is projected to the nearest positive definite matrix using posdef!.\n\nRelated\n\nSmythBrobyCovariance\nSmythBrobyGerber0\nsb_delta\nposdef!\n\n\n\n\n\n","category":"method"},{"location":"007-06-Moments/#PortfolioOptimisers.smythbroby-Tuple{SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBrobyGerber0}, AbstractMatrix}","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.smythbroby","text":"smythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any,\n                                    <:Any, <:Any, <:NormalisedSmythBrobyGerber0, <:Any},\n           X::AbstractMatrix)\n\nImplements the original Gerber-style variant of the Smyth-Broby covariance/correlation algorithm on Z-transformed data (normalised).\n\nThis method computes the Smyth-Broby correlation or covariance matrix for the input data matrix X using the NormalisedSmythBrobyGerber0 algorithm. The computation is performed on data that has already been Z-transformed (mean-centered and standardised), and is based on thresholding the data, applying the Smyth-Broby kernel, and aggregating positive and negative co-movements, with additional weighting by the count of co-movements.\n\nArguments\n\nce: Smyth-Broby covariance estimator configured with the NormalisedSmythBrobyGerber0 algorithm.\nX: Z-transformed data matrix (observations × assets).\n\nReturns\n\nrho::Matrix{<:Real}: The Smyth-Broby correlation matrix, projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each pair of assets (i, j), iterate over all observations.\nFor each observation, use the Z-transformed returns for assets i and j.\nApply the threshold to classify joint positive and negative co-movements.\nUse the sb_delta kernel (with mean 0 and standard deviation 1) to accumulate positive (pos) and negative (neg) contributions, and count the number of positive (cpos) and negative (cneg) co-movements.\nThe correlation is computed as (pos * cpos - neg * cneg) / (pos * cpos + neg * cneg) if the denominator is nonzero, otherwise zero.\nThe resulting matrix is projected to the nearest positive definite matrix using posdef!.\n\nRelated\n\nSmythBrobyCovariance\nNormalisedSmythBrobyGerber0\nsb_delta\nposdef!\n\n\n\n\n\n","category":"method"},{"location":"007-06-Moments/#PortfolioOptimisers.smythbroby-Tuple{SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBrobyGerber1}, AbstractMatrix, AbstractArray, AbstractArray}","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.smythbroby","text":"smythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any,\n                                    <:Any, <:Any, <:SmythBrobyGerber1, <:Any},\n           X::AbstractMatrix, mean_vec::AbstractArray, std_vec::AbstractArray)\n\nImplements the first Gerber-style variant of the Smyth-Broby covariance/correlation algorithm (unnormalised).\n\nThis method computes the Smyth-Broby correlation or covariance matrix for the input data matrix X using the SmythBrobyGerber1 algorithm. The computation is based on thresholding the data, applying the Smyth-Broby kernel, and aggregating positive, negative, and neutral co-movements, with additional weighting by the count of co-movements.\n\nArguments\n\nce: Smyth-Broby covariance estimator configured with the SmythBrobyGerber1 algorithm.\nX: Data matrix (observations × assets).\nmean_vec: Vector of means for each asset, used for centering.\nstd_vec: Vector of standard deviations for each asset, used for scaling and thresholding.\n\nReturns\n\nrho::Matrix{<:Real}: The Smyth-Broby correlation matrix, projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each pair of assets (i, j), iterate over all observations.\nFor each observation, compute the centered and scaled returns for assets i and j.\nApply the threshold to classify joint positive, negative, and neutral co-movements.\nUse the sb_delta kernel to accumulate positive (pos), negative (neg), and neutral (nn) contributions, and count the number of positive (cpos), negative (cneg), and neutral (cnn) co-movements.\nThe correlation is computed as (pos * cpos - neg * cneg) / (pos * cpos + neg * cneg + nn * cnn) if the denominator is nonzero, otherwise zero.\nThe resulting matrix is projected to the nearest positive definite matrix using posdef!.\n\nRelated\n\nSmythBrobyCovariance\nSmythBrobyGerber1\nsb_delta\nposdef!\n\n\n\n\n\n","category":"method"},{"location":"007-06-Moments/#PortfolioOptimisers.smythbroby-Tuple{SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBrobyGerber1}, AbstractMatrix}","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.smythbroby","text":"smythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any,\n                                    <:Any, <:Any, <:NormalisedSmythBrobyGerber1, <:Any},\n           X::AbstractMatrix)\n\nImplements the first Gerber-style variant of the Smyth-Broby covariance/correlation algorithm on Z-transformed data (normalised).\n\nThis method computes the Smyth-Broby correlation or covariance matrix for the input data matrix X using the NormalisedSmythBrobyGerber1 algorithm. The computation is performed on data that has already been Z-transformed (mean-centered and standardised), and is based on thresholding the data, applying the Smyth-Broby kernel, and aggregating positive, negative, and neutral co-movements, with additional weighting by the count of co-movements.\n\nArguments\n\nce: Smyth-Broby covariance estimator configured with the NormalisedSmythBrobyGerber1 algorithm.\nX: Z-transformed data matrix (observations × assets).\n\nReturns\n\nrho::Matrix{<:Real}: The Smyth-Broby correlation matrix, projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each pair of assets (i, j), iterate over all observations.\nFor each observation, use the Z-transformed returns for assets i and j.\nApply the threshold to classify joint positive, negative, and neutral co-movements.\nUse the sb_delta kernel (with mean 0 and standard deviation 1) to accumulate positive (pos), negative (neg), and neutral (nn) contributions, and count the number of positive (cpos), negative (cneg), and neutral (cnn) co-movements.\nThe correlation is computed as (pos * cpos - neg * cneg) / (pos * cpos + neg * cneg + nn * cnn) if the denominator is nonzero, otherwise zero.\nThe resulting matrix is projected to the nearest positive definite matrix using posdef!.\n\nRelated\n\nSmythBrobyCovariance\nNormalisedSmythBrobyGerber1\nsb_delta\nposdef!\n\n\n\n\n\n","category":"method"},{"location":"007-06-Moments/#PortfolioOptimisers.smythbroby-Tuple{SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBrobyGerber2}, AbstractMatrix, AbstractArray, AbstractArray}","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.smythbroby","text":"smythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any,\n                                    <:Any, <:Any, <:SmythBrobyGerber2, <:Any},\n           X::AbstractMatrix, mean_vec::AbstractArray, std_vec::AbstractArray)\n\nImplements the second Gerber-style variant of the Smyth-Broby covariance/correlation algorithm (unnormalised).\n\nThis method computes the Smyth-Broby correlation or covariance matrix for the input data matrix X using the SmythBrobyGerber2 algorithm. The computation is based on thresholding the data, applying the Smyth-Broby kernel, and aggregating positive and negative co-movements, with additional weighting by the count of co-movements. The resulting matrix is then normalised by the geometric mean of its diagonal elements.\n\nArguments\n\nce: Smyth-Broby covariance estimator configured with the SmythBrobyGerber2 algorithm.\nX: Data matrix (observations × assets).\nmean_vec: Vector of means for each asset, used for centering.\nstd_vec: Vector of standard deviations for each asset, used for scaling and thresholding.\n\nReturns\n\nrho::Matrix{<:Real}: The Smyth-Broby correlation matrix, normalised and projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each pair of assets (i, j), iterate over all observations.\nFor each observation, compute the centered and scaled returns for assets i and j.\nApply the threshold to classify joint positive and negative co-movements.\nUse the sb_delta kernel to accumulate positive (pos) and negative (neg) contributions, and count the number of positive (cpos) and negative (cneg) co-movements.\nThe raw correlation is computed as pos * cpos - neg * cneg.\nThe resulting matrix is normalised by dividing each element by the geometric mean of the corresponding diagonal elements.\nThe matrix is projected to the nearest positive definite matrix using posdef!.\n\nRelated\n\nSmythBrobyCovariance\nSmythBrobyGerber2\nsb_delta\nposdef!\n\n\n\n\n\n","category":"method"},{"location":"007-06-Moments/#PortfolioOptimisers.smythbroby-Tuple{SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBrobyGerber2}, AbstractMatrix}","page":"Smyth-Broby Covariance","title":"PortfolioOptimisers.smythbroby","text":"smythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any,\n                                    <:Any, <:Any, <:NormalisedSmythBrobyGerber2, <:Any},\n           X::AbstractMatrix)\n\nImplements the second Gerber-style variant of the Smyth-Broby covariance/correlation algorithm on Z-transformed data (normalised).\n\nThis method computes the Smyth-Broby correlation or covariance matrix for the input data matrix X using the NormalisedSmythBrobyGerber2 algorithm. The computation is performed on data that has already been Z-transformed (mean-centered and standardised), and is based on thresholding the data, applying the Smyth-Broby kernel, and aggregating positive and negative co-movements, with additional weighting by the count of co-movements. The resulting matrix is then normalised by the geometric mean of its diagonal elements.\n\nArguments\n\nce: Smyth-Broby covariance estimator configured with the NormalisedSmythBrobyGerber2 algorithm.\nX: Z-transformed data matrix (observations × assets).\n\nReturns\n\nrho::Matrix{<:Real}: The Smyth-Broby correlation matrix, normalised and projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each pair of assets (i, j), iterate over all observations.\nFor each observation, use the Z-transformed returns for assets i and j.\nApply the threshold to classify joint positive and negative co-movements.\nUse the sb_delta kernel (with mean 0 and standard deviation 1) to accumulate positive (pos) and negative (neg) contributions, and count the number of positive (cpos) and negative (cneg) co-movements.\nThe raw correlation is computed as pos * cpos - neg * cneg.\nThe resulting matrix is normalised by dividing each element by the geometric mean of the corresponding diagonal elements.\nThe matrix is projected to the nearest positive definite matrix using posdef!.\n\nRelated\n\nSmythBrobyCovariance\nNormalisedSmythBrobyGerber2\nsb_delta\nposdef!\n\n\n\n\n\n","category":"method"},{"location":"007-06-Moments/#Statistics.cov-Tuple{SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:PortfolioOptimisers.UnNormalisedSmythBrobyCovarianceAlgorithm}, AbstractMatrix}","page":"Smyth-Broby Covariance","title":"Statistics.cov","text":"cov(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any,\n                             <:Any, <:Any,\n                             <:UnNormalisedSmythBrobyCovarianceAlgorithm,\n                             <:Any}, X::AbstractMatrix; dims::Int = 1,\n    mean = nothing, kwargs...)\n\nCompute the Smyth-Broby covariance matrix using an unnormalised Smyth-Broby covariance estimator.\n\nThis method computes the Smyth-Broby covariance matrix for the input data matrix X using the specified unnormalised Smyth-Broby covariance estimator UnNormalisedSmythBrobyCovarianceAlgorithm. The mean and standard deviation vectors are computed using the estimator's expected returns and variance estimators. The Smyth-Broby correlation is computed via smythbroby, and the result is rescaled to a covariance matrix using the standard deviation vector.\n\nArguments\n\nce: Smyth-Broby covariance estimator.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the covariance.\nmean: Optional mean vector for centering. If not provided, computed using ce.me.\nkwargs...: Additional keyword arguments passed to the mean and standard deviation estimators.\n\nReturns\n\nsigma::Matrix{<:Real}: The Smyth-Broby covariance matrix.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nRelated\n\nSmythBrobyCovariance\nUnNormalisedSmythBrobyCovarianceAlgorithm\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBroby0, <:Any}, X::AbstractMatrix)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBroby1, <:Any}, X::AbstractMatrix)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBroby2, <:Any}, X::AbstractMatrix)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBrobyGerber0, <:Any}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBrobyGerber1, <:Any}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBrobyGerber2, <:Any}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\ncor(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:UnNormalisedSmythBrobyCovarianceAlgorithm, <:Any}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"007-06-Moments/#Statistics.cor-Tuple{SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:PortfolioOptimisers.UnNormalisedSmythBrobyCovarianceAlgorithm}, AbstractMatrix}","page":"Smyth-Broby Covariance","title":"Statistics.cor","text":"cor(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any,\n                             <:Any, <:Any,\n                             <:UnNormalisedSmythBrobyCovarianceAlgorithm,\n                             <:Any}, X::AbstractMatrix; dims::Int = 1,\n    mean = nothing, kwargs...)\n\nCompute the Smyth-Broby correlation matrix using an unnormalised Smyth-Broby covariance estimator.\n\nThis method computes the Smyth-Broby correlation matrix for the input data matrix X using the specified unnormalised Smyth-Broby covariance estimator UnNormalisedSmythBrobyCovarianceAlgorithm. The mean and standard deviation vectors are computed using the estimator's expected returns and variance estimators. The Smyth-Broby correlation is then computed via smythbroby.\n\nArguments\n\nce: Smyth-Broby covariance estimator.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the correlation.\nmean: Optional mean vector for centering. If not provided, computed using ce.me.\nkwargs...: Additional keyword arguments passed to the mean and standard deviation estimators.\n\nReturns\n\nrho::Matrix{<:Real}: The Smyth-Broby correlation matrix.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nRelated\n\nSmythBrobyCovariance\nUnNormalisedSmythBrobyCovarianceAlgorithm\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBroby0, <:Any}, X::AbstractMatrix)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBroby1, <:Any}, X::AbstractMatrix)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBroby2, <:Any}, X::AbstractMatrix)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBrobyGerber0, <:Any}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBrobyGerber1, <:Any}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:SmythBrobyGerber2, <:Any}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\ncov(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:UnNormalisedSmythBrobyCovarianceAlgorithm, <:Any}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"007-06-Moments/#Statistics.cov-Tuple{SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:PortfolioOptimisers.NormalisedSmythBrobyCovarianceAlgorithm}, AbstractMatrix}","page":"Smyth-Broby Covariance","title":"Statistics.cov","text":"cov(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any,\n                             <:Any, <:Any, <:NormalisedSmythBrobyCovarianceAlgorithm,\n                             <:Any}, X::AbstractMatrix; dims::Int = 1,\n    mean = nothing, kwargs...)\n\nCompute the Smyth-Broby covariance matrix using a normalised Smyth-Broby covariance estimator.\n\nThis method computes the Smyth-Broby covariance matrix for the input data matrix X using the specified normalised Smyth-Broby covariance estimator NormalisedSmythBrobyCovarianceAlgorithm. The mean and standard deviation vectors are computed using the estimator's expected returns and variance estimators, and the data is Z-transformed before applying the Smyth-Broby algorithm. The resulting correlation matrix is rescaled to a covariance matrix using the standard deviation vector.\n\nArguments\n\nce: Smyth-Broby covariance estimator.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the covariance.\nmean: Optional mean vector for centering. If not provided, computed using ce.me.\nkwargs...: Additional keyword arguments passed to the mean and standard deviation estimators.\n\nReturns\n\nsigma::Matrix{<:Real}: The Smyth-Broby covariance matrix.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nDetails\n\nThe input data is Z-transformed (mean-centered and standardised) before applying the Smyth-Broby algorithm.\nThe resulting correlation matrix is rescaled to a covariance matrix using the standard deviation vector.\n\nRelated\n\nSmythBrobyCovariance\nNormalisedSmythBrobyCovarianceAlgorithm\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBroby0, <:Any}, X::AbstractMatrix)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBroby1, <:Any}, X::AbstractMatrix)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBroby2, <:Any}, X::AbstractMatrix)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBrobyGerber0, <:Any}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBrobyGerber1, <:Any}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBrobyGerber2, <:Any}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\ncor(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBrobyCovarianceAlgorithm, <:Any}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"007-06-Moments/#Statistics.cor-Tuple{SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:PortfolioOptimisers.NormalisedSmythBrobyCovarianceAlgorithm}, AbstractMatrix}","page":"Smyth-Broby Covariance","title":"Statistics.cor","text":"cor(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any,\n                             <:Any, <:Any, <:NormalisedSmythBrobyCovarianceAlgorithm,\n                             <:Any}, X::AbstractMatrix; dims::Int = 1,\n    mean = nothing, kwargs...)\n\nCompute the Smyth-Broby correlation matrix using a normalised Smyth-Broby covariance estimator.\n\nThis method computes the Smyth-Broby correlation matrix for the input data matrix X using the specified normalised Smyth-Broby covariance estimator NormalisedSmythBrobyCovarianceAlgorithm. The mean and standard deviation vectors are computed using the estimator's expected returns and variance estimators, and the data is Z-transformed before applying the Smyth-Broby algorithm.\n\nArguments\n\nce: Smyth-Broby covariance estimator.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the correlation.\nmean: Optional mean vector for centering. If not provided, computed using ce.me.\nkwargs...: Additional keyword arguments passed to the mean and standard deviation estimators.\n\nReturns\n\nrho::Matrix{<:Real}: The Smyth-Broby correlation matrix.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nDetails\n\nThe input data is Z-transformed (mean-centered and standardised) before applying the Smyth-Broby algorithm.\n\nRelated\n\nSmythBrobyCovariance\nNormalisedSmythBrobyCovarianceAlgorithm\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBroby0, <:Any}, X::AbstractMatrix)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBroby1, <:Any}, X::AbstractMatrix)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBroby2, <:Any}, X::AbstractMatrix)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBrobyGerber0, <:Any}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBrobyGerber1, <:Any}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nsmythbroby(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBrobyGerber2, <:Any}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\ncov(ce::SmythBrobyCovariance{<:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:Any, <:NormalisedSmythBrobyCovarianceAlgorithm, <:Any}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"The source files for all examples can be found in /examples.","category":"page"},{"location":"examples/4-Pareto-Surface/#Example-4:-Pareto-surface","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"","category":"section"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"This example kicks up the complexity a couple of notches. We will introduce a new optimisation estimator, NearOptimalCentering optimiser.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"using PortfolioOptimisers, PrettyTables\n# Format for pretty tables.\ntsfmt = (v, i, j) -> begin\n    if j == 1\n        return Date(v)\n    else\n        return v\n    end\nend;\nresfmt = (v, i, j) -> begin\n    if j == 1\n        return v\n    else\n        return isa(v, Number) ? \"$(round(v*100, digits=3)) %\" : v\n    end\nend;\nnothing #hide","category":"page"},{"location":"examples/4-Pareto-Surface/#1.-ReturnsResult-data","page":"Example 4: Pareto surface","title":"1. ReturnsResult data","text":"","category":"section"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"We will use the same data as the previous example.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"using CSV, TimeSeries, DataFrames\n\nX = TimeArray(CSV.File(joinpath(@__DIR__, \"SP500.csv.gz\")); timestamp = :Date)[(end - 252):end]\npretty_table(X[(end - 5):end]; formatters = tsfmt)\n\n# Compute the returns\nrd = prices_to_returns(X)","category":"page"},{"location":"examples/4-Pareto-Surface/#2.-Preparing-solvers-for-pareto-surface","page":"Example 4: Pareto surface","title":"2. Preparing solvers for pareto surface","text":"","category":"section"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"The pareto surface is a generalisation of the efficient frontier, in fact, we can even think of hypersurfaces if we provide more parameters, but that would be difficult to visualise, so we will stick to a 2D surface in 3D space.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"We'll provide a vector of solvers beacause the optimisation type we'll be using is more complex, and will contain various constraints.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"using Clarabel\nslv = [Solver(; name = :clarabel1, solver = Clarabel.Optimizer,\n              settings = Dict(\"verbose\" => false),\n              check_sol = (; allow_local = true, allow_almost = true)),\n       Solver(; name = :clarabel2, solver = Clarabel.Optimizer,\n              settings = Dict(\"verbose\" => false, \"max_step_fraction\" => 0.95),\n              check_sol = (; allow_local = true, allow_almost = true)),\n       Solver(; name = :clarabel3, solver = Clarabel.Optimizer,\n              settings = Dict(\"verbose\" => false, \"max_step_fraction\" => 0.9),\n              check_sol = (; allow_local = true, allow_almost = true)),\n       Solver(; name = :clarabel4, solver = Clarabel.Optimizer,\n              settings = Dict(\"verbose\" => false, \"max_step_fraction\" => 0.85),\n              check_sol = (; allow_local = true, allow_almost = true)),\n       Solver(; name = :clarabel5, solver = Clarabel.Optimizer,\n              settings = Dict(\"verbose\" => false, \"max_step_fraction\" => 0.8),\n              check_sol = (; allow_local = true, allow_almost = true)),\n       Solver(; name = :clarabel6, solver = Clarabel.Optimizer,\n              settings = Dict(\"verbose\" => false, \"max_step_fraction\" => 0.75),\n              check_sol = (; allow_local = true, allow_almost = true)),\n       Solver(; name = :clarabel7, solver = Clarabel.Optimizer,\n              settings = Dict(\"verbose\" => false, \"max_step_fraction\" => 0.70),\n              check_sol = (; allow_local = true, allow_almost = true))];\nnothing #hide","category":"page"},{"location":"examples/4-Pareto-Surface/#3.-High-order-prior-statistics","page":"Example 4: Pareto surface","title":"3. High order prior statistics","text":"","category":"section"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"We will once again precompute the prior statistics because otherwise they'd have to be recomputed a few times.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"We will be using high order risk measures, so we need to compute high order moments, we can do this with a HighOrderPriorEstimator, which needs a prior estimator that computes low order moments. Since we are only using a year of data, we will denoise our positive definite matrices by eliminating the eigenvalues corresponding to random noise. Denoising the non-positive definite matrix for the data we're using creates a negative square root, so we will not denoise it.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"Note how many options this estimator contains.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"de = Denoise(; alg = SpectralDenoise(;))\nmp = DefaultMatrixProcessing(; denoise = de)\npe = HighOrderPriorEstimator(;\n                             # Prior estimator for low order moments\n                             pe = EmpiricalPrior(;\n                                                 ce = PortfolioOptimisersCovariance(;\n                                                                                    mp = mp)),\n                             # Estimator for cokurtosis\n                             kte = Cokurtosis(; mp = mp),\n                             # Estimator for coskewness\n                             ske = Coskewness())","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"Lets compute the prior statistics.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"pr = prior(pe, rd)","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"In order to generate a pareto surface/hyper-surface, we need more dimensions than we've previously explored. We can do this by adding more risk measure sweeps (and taking their product) to generate a mesh. PortfolioOptimisers does this internally and generally, but we will limit ourselves to two risk measures. This will generate a 2D surface which we can visualise in 3D.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"We will use the square root NegativeSkewness and SquareRootKurtosis.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"r1 = NegativeSkewness()\nr2 = SquareRootKurtosis()","category":"page"},{"location":"examples/4-Pareto-Surface/#4.-Near-optimal-centering-pareto-surface","page":"Example 4: Pareto surface","title":"4. Near optimal centering pareto surface","text":"","category":"section"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"First we need to get the bounds of our pareto surface. We can do this in many different ways, the simplest are:","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"Minimise the risk using both risk measures simultaneously subject to optional constraints.\nMaximise the return, utility or ratio subject to optional constraints.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"We will simply maximise the risk-return ratio for both risk measures on their own with no added constraints. This will not give a complete surface, but it will give us a reasonable range of values.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"The NearOptimalCentering estimator will not return the portfolio which satisfies the traditional MeanRisk constraints, but rather a portfolio which is at the centre of an analytical region (neighbourhood) around the optimal solution. The region is parametrised by binning the efficient frontier, we will use the automatic bins here, but it is possible to define them manually.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"# Risk-free rate of 4.2/100/252\nrf = 4.2 / 100 / 252\nopt = JuMPOptimiser(; pe = pr, slv = slv)\nobj = MaximumRatio(; rf = rf)\nopt1 = NearOptimalCentering(; r = r1, obj = obj, opt = opt)\nopt2 = NearOptimalCentering(; r = r2, obj = obj, opt = opt)","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"Note the number of options in the estimator. In particular the alg property. Which in this case means the NearOptimalCentering alg will not have any external constraints applied to it.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"Lets optimise the portfolios.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"res1 = optimise!(opt1)\nres2 = optimise!(opt2)","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"In order to allow for multiple risk measures in optimisations, certain measures can take different parameters. In this case, NegativeSkewness and SquareRootKurtosis take the moment matrices, which are used to compute the risk measures. We can use the factory function to create a new risk measure with the same parameters as the original, but with the moment matrices from the prior. Other risk measures require a solver, and this function is also used in those cases.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"r1 = factory(r1, pr)\nr2 = factory(r2, pr)","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"Lets compute the risk bounds for the pareto surface. We need to compute four risks because we have two risk measures and two optimisations. This will let us pick the lower and upper bounds for each risk measure, as we explore the pareto surface from one optimisation to the other.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"sk_rk1 = expected_risk(r1, res1.w, pr.X);\nkt_rk1 = expected_risk(r2, res1.w, pr.X);\nsk_rk2 = expected_risk(r1, res2.w, pr.X);\nkt_rk2 = expected_risk(r2, res2.w, pr.X);\nnothing #hide","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"We will now create new risk measures bounded by these values. We will also use factories from the get-go. The optimisation procedure prioritises the parameters in the risk measures over the ones in the prior. This lets users provide the same risk measure with different parameters in the same optimisation. We will use two ranges of 5. The total number of points in the pareto surface will be the product of the points of each range.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"Since we don't know which sk_rk1 or sk_r2, kt_rk1 or kt_rk2 is bigger or smaller, we need to use min, max.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"r1 = factory(NegativeSkewness(;\n                              settings = RiskMeasureSettings(;\n                                                             # Risk upper bounds go from the minimum to maximum risk given the optimisations.\n                                                             ub = range(;\n                                                                        start = min(sk_rk1,\n                                                                                    sk_rk2),\n                                                                        stop = max(sk_rk1,\n                                                                                   sk_rk2),\n                                                                        length = 5))), pr);\nr2 = factory(SquareRootKurtosis(;\n                                settings = RiskMeasureSettings(;\n                                                               ub = range(;\n                                                                          start = min(kt_rk1,\n                                                                                      kt_rk2),\n                                                                          stop = max(kt_rk1,\n                                                                                     kt_rk2),\n                                                                          length = 5))), pr);\nnothing #hide","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"Now we only need to maximise the return given both risk measures. Internally, the optimisation will generate the mesh as a product of the ranges in the order in which the risk measures were provided. This also works with the MeanRisk estimatro, in fact, NearOptimalCentering uses it internally.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"Since we are using an unconstrained NearOptimalCentering, the risk bound constraints will not be satisfied by the solution. If we wish to satisfy them, we can provide alg = ConstrainedNearOptimalCentering(), but would also make the optimisations harder, which may cause them to fail.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"opt3 = NearOptimalCentering(; r = [r1, r2], obj = MaximumReturn(), opt = opt)","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"See how r is a vector of risk measures with populated properties. We can now optimise the porftolios.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"res3 = optimise!(opt3)","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"As expected, there are 5 × 5 = 25 solutions. Thankfully there are no warnings about failed optimisations, so there is no need to check the solutions.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"The NearOptimalCentering estimator contains various return codes because it may need to compute some MeanRisk optimisations, it has a retcode which summarises whether all other optimisations succeeded. We can check this to make sure it was a success.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"isa(res3.retcode, OptimisationSuccess)","category":"page"},{"location":"examples/4-Pareto-Surface/#5.-Visualising-the-pareto-surface","page":"Example 4: Pareto surface","title":"5. Visualising the pareto surface","text":"","category":"section"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"Lets view how the weights evolve along the pareto surface.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"using StatsPlots, GraphRecipes\nplot_stacked_area_composition(res3.w, rd.nx)","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"Now we can view the parteo surface. For the z-axis and colourbar, we will use the conditional drawdown at risk to return ratio.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"plot_measures(res3.w, pr; x = r1, y = r2,\n              z = RatioRiskMeasure(; rk = ConditionalDrawdownatRisk(),\n                                   rt = ArithmeticReturn(), rf = rf),\n              c = RatioRiskMeasure(; rk = ConditionalDrawdownatRisk(),\n                                   rt = ArithmeticReturn(), rf = rf),\n              title = \"Pareto Surface\", xlabel = \"Sqrt NSke\", ylabel = \"Sqrt Kt\",\n              zlabel = \"CDaR/Return\")","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"We can view it in 2D as well.","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"gr()\nplot_measures(res3.w, pr; x = r1, y = r2,\n              c = RatioRiskMeasure(; rk = ConditionalDrawdownatRisk(),\n                                   rt = ArithmeticReturn(), rf = rf),\n              title = \"Pareto Front\", xlabel = \"Sqrt NSke\", ylabel = \"Sqrt Kt\",\n              colorbar_title = \"\\n\\nCDaR/Return\", right_margin = 8Plots.mm)","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"","category":"page"},{"location":"examples/4-Pareto-Surface/","page":"Example 4: Pareto surface","title":"Example 4: Pareto surface","text":"This page was generated using Literate.jl.","category":"page"},{"location":"007-05-Moments/#Gerber-Covariance","page":"Gerber Covariance","title":"Gerber Covariance","text":"","category":"section"},{"location":"007-05-Moments/#PortfolioOptimisers.BaseGerberCovariance","page":"Gerber Covariance","title":"PortfolioOptimisers.BaseGerberCovariance","text":"abstract type BaseGerberCovariance <: AbstractCovarianceEstimator end\n\nAbstract supertype for all Gerber covariance estimators in PortfolioOptimisers.jl.\n\nAll concrete types implementing Gerber covariance estimation algorithms should subtype BaseGerberCovariance. This enables a consistent interface for Gerber-based covariance estimators throughout the package.\n\nRelated\n\nGerberCovariance\nGerberCovarianceAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"007-05-Moments/#PortfolioOptimisers.GerberCovarianceAlgorithm","page":"Gerber Covariance","title":"PortfolioOptimisers.GerberCovarianceAlgorithm","text":"abstract type GerberCovarianceAlgorithm <: AbstractMomentAlgorithm end\n\nAbstract supertype for all Gerber covariance algorithm types in PortfolioOptimisers.jl.\n\nAll concrete types implementing specific Gerber covariance algorithms should subtype GerberCovarianceAlgorithm. This enables flexible extension and dispatch of Gerber covariance routines.\n\nThese types are used to specify the algorithm when constructing a GerberCovariance estimator.\n\nRelated\n\nBaseGerberCovariance\nUnNormalisedGerberCovarianceAlgorithm\nNormalisedGerberCovarianceAlgorithm\nGerberCovariance\n\n\n\n\n\n","category":"type"},{"location":"007-05-Moments/#PortfolioOptimisers.UnNormalisedGerberCovarianceAlgorithm","page":"Gerber Covariance","title":"PortfolioOptimisers.UnNormalisedGerberCovarianceAlgorithm","text":"abstract type UnNormalisedGerberCovarianceAlgorithm <: GerberCovarianceAlgorithm end\n\nAbstract supertype for all unnormalised Gerber covariance algorithm types.\n\nConcrete types implementing unnormalised Gerber covariance algorithms should subtype UnNormalisedGerberCovarianceAlgorithm.\n\nRelated\n\nGerberCovarianceAlgorithm\nGerber0\nGerber1\nGerber2\nGerberCovariance\n\n\n\n\n\n","category":"type"},{"location":"007-05-Moments/#PortfolioOptimisers.NormalisedGerberCovarianceAlgorithm","page":"Gerber Covariance","title":"PortfolioOptimisers.NormalisedGerberCovarianceAlgorithm","text":"abstract type NormalisedGerberCovarianceAlgorithm <: GerberCovarianceAlgorithm end\n\nAbstract supertype for all normalised Gerber covariance algorithm types. These Z-transform the data before applying the Gerber covariance algorithm.\n\nConcrete types implementing normalised Gerber covariance algorithms should subtype NormalisedGerberCovarianceAlgorithm.\n\nRelated\n\nGerberCovarianceAlgorithm\nNormalisedGerber0\nNormalisedGerber1\nNormalisedGerber2\nGerberCovariance\n\n\n\n\n\n","category":"type"},{"location":"007-05-Moments/#PortfolioOptimisers.Gerber0","page":"Gerber Covariance","title":"PortfolioOptimisers.Gerber0","text":"struct Gerber0 <: UnNormalisedGerberCovarianceAlgorithm end\n\nImplements the original Gerber covariance algorithm.\n\nRelated\n\nUnNormalisedGerberCovarianceAlgorithm\nGerberCovariance\nGerber1\nGerber2\n\n\n\n\n\n","category":"type"},{"location":"007-05-Moments/#PortfolioOptimisers.Gerber1","page":"Gerber Covariance","title":"PortfolioOptimisers.Gerber1","text":"struct Gerber1 <: UnNormalisedGerberCovarianceAlgorithm end\n\nImplements the first variant of the Gerber covariance algorithm.\n\nRelated\n\nUnNormalisedGerberCovarianceAlgorithm\nGerberCovariance\nGerber0\nGerber2\n\n\n\n\n\n","category":"type"},{"location":"007-05-Moments/#PortfolioOptimisers.Gerber2","page":"Gerber Covariance","title":"PortfolioOptimisers.Gerber2","text":"struct Gerber2 <: UnNormalisedGerberCovarianceAlgorithm end\n\nImplements the second variant of the Gerber covariance algorithm.\n\nRelated\n\nUnNormalisedGerberCovarianceAlgorithm\nGerberCovariance\nGerber0\nGerber1\n\n\n\n\n\n","category":"type"},{"location":"007-05-Moments/#PortfolioOptimisers.NormalisedGerber0","page":"Gerber Covariance","title":"PortfolioOptimisers.NormalisedGerber0","text":"struct NormalisedGerber0{T1} <: NormalisedGerberCovarianceAlgorithm\n    me::T1\nend\n\nImplements the original Gerber covariance algorithm on Z-transformed data.\n\nFields\n\nme: Expected returns estimator used for mean-centering prior to normalisation.\n\nConstructor\n\nNormalisedGerber0(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns()): Construct the original normalised Gerber covariance algorithm.\n\nRelated\n\nNormalisedGerberCovarianceAlgorithm\nGerberCovariance\nAbstractExpectedReturnsEstimator\nSimpleExpectedReturns\nNormalisedGerber1\nNormalisedGerber2\n\n\n\n\n\n","category":"type"},{"location":"007-05-Moments/#PortfolioOptimisers.NormalisedGerber0-Tuple{}","page":"Gerber Covariance","title":"PortfolioOptimisers.NormalisedGerber0","text":"NormalisedGerber0(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns())\n\nCreates a NormalisedGerber0 object using the specified expected returns estimator for mean-centering prior to normalisation.\n\nArguments\n\nme: Expected returns estimator used for mean-centering before normalisation.\n\nReturns\n\nNormalisedGerber0: An instance of the original normalised Gerber covariance algorithm.\n\nExamples\n\njulia> ng0 = NormalisedGerber0()\nNormalisedGerber0\n  me | SimpleExpectedReturns\n     |   w | nothing\n\nRelated\n\nNormalisedGerber0\nGerberCovariance\nAbstractExpectedReturnsEstimator\nSimpleExpectedReturns\n\n\n\n\n\n","category":"method"},{"location":"007-05-Moments/#PortfolioOptimisers.NormalisedGerber1","page":"Gerber Covariance","title":"PortfolioOptimisers.NormalisedGerber1","text":"struct NormalisedGerber1{T1} <: NormalisedGerberCovarianceAlgorithm\n    me::T1\nend\n\nImplements the first variant of the Gerber covariance algorithm on Z-transformed data.\n\nFields\n\nme: Expected returns estimator used for mean-centering prior to normalisation.\n\nConstructor\n\nNormalisedGerber1(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns()): Construct the first variant of the normalised Gerber covariance algorithm.\n\nRelated\n\nNormalisedGerberCovarianceAlgorithm\nGerberCovariance\nAbstractExpectedReturnsEstimator\nSimpleExpectedReturns\nNormalisedGerber0\nNormalisedGerber2\n\n\n\n\n\n","category":"type"},{"location":"007-05-Moments/#PortfolioOptimisers.NormalisedGerber1-Tuple{}","page":"Gerber Covariance","title":"PortfolioOptimisers.NormalisedGerber1","text":"NormalisedGerber1(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns())\n\nCreates a NormalisedGerber1 object using the specified expected returns estimator for mean-centering prior to normalisation.\n\nArguments\n\nme: Expected returns estimator used for mean-centering before normalisation.\n\nReturns\n\nNormalisedGerber1: An instance of the original normalised Gerber covariance algorithm.\n\nExamples\n\njulia> ng0 = NormalisedGerber1()\nNormalisedGerber1\n  me | SimpleExpectedReturns\n     |   w | nothing\n\nRelated\n\nNormalisedGerber1\nGerberCovariance\nAbstractExpectedReturnsEstimator\nSimpleExpectedReturns\n\n\n\n\n\n","category":"method"},{"location":"007-05-Moments/#PortfolioOptimisers.NormalisedGerber2","page":"Gerber Covariance","title":"PortfolioOptimisers.NormalisedGerber2","text":"struct NormalisedGerber2{T1} <: NormalisedGerberCovarianceAlgorithm\n    me::T1\nend\n\nImplements the second variant of the Gerber covariance algorithm on Z-transformed data.\n\nFields\n\nme: Expected returns estimator used for mean-centering prior to normalisation.\n\nConstructors\n\nNormalisedGerber2(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns()): Construct the second variant of the normalised Gerber covariance algorithm.\n\nThese types are used to specify the algorithm when constructing a GerberCovariance estimator with normalisation.\n\nRelated\n\nNormalisedGerberCovarianceAlgorithm\nGerberCovariance\nAbstractExpectedReturnsEstimator\nSimpleExpectedReturns\nNormalisedGerber0\nNormalisedGerber1\n\n\n\n\n\n","category":"type"},{"location":"007-05-Moments/#PortfolioOptimisers.NormalisedGerber2-Tuple{}","page":"Gerber Covariance","title":"PortfolioOptimisers.NormalisedGerber2","text":"NormalisedGerber2(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns())\n\nCreates a NormalisedGerber2 object using the specified expected returns estimator for mean-centering prior to normalisation.\n\nArguments\n\nme: Expected returns estimator used for mean-centering before normalisation.\n\nReturns\n\nNormalisedGerber2: An instance of the original normalised Gerber covariance algorithm.\n\nExamples\n\njulia> ng0 = NormalisedGerber2()\nNormalisedGerber2\n  me | SimpleExpectedReturns\n     |   w | nothing\n\nRelated\n\nNormalisedGerber2\nGerberCovariance\nAbstractExpectedReturnsEstimator\nSimpleExpectedReturns\n\n\n\n\n\n","category":"method"},{"location":"007-05-Moments/#PortfolioOptimisers.GerberCovariance","page":"Gerber Covariance","title":"PortfolioOptimisers.GerberCovariance","text":"struct GerberCovariance{T1, T2, T3, T4} <: BaseGerberCovariance\n    ve::T1\n    pdm::T2\n    threshold::T3\n    alg::T4\nend\n\nA flexible container type for configuring and applying Gerber covariance estimators in PortfolioOptimisers.jl.\n\nGerberCovariance encapsulates all components required for Gerber-based covariance or correlation estimation, including the variance estimator, positive definite matrix estimator, threshold parameter, and the specific Gerber algorithm variant. This enables modular and extensible workflows for robust covariance estimation using Gerber statistics.\n\nFields\n\nve: Variance estimator.\npdm: Positive definite matrix estimator (see Posdef).\nthreshold: Threshold parameter for Gerber covariance computation (typically in (0, 1)).\nalg: Gerber covariance algorithm variant.\n\nConstructor\n\nGerberCovariance(; alg::GerberCovarianceAlgorithm = Gerber1(),\n                  ve::StatsBase.CovarianceEstimator = SimpleVariance(),\n                  pdm::Union{Nothing, <:Posdef} = Posdef(),\n                  threshold::Real = 0.5)\n\nConstruct a GerberCovariance estimator with the specified algorithm, variance estimator, positive definite estimator, and threshold.\n\nRelated\n\nBaseGerberCovariance\nGerberCovarianceAlgorithm\nStatsBase.CovarianceEstimator\nSimpleVariance\nPosdef\nGerber0\nGerber1\nGerber2\nNormalisedGerber0\nNormalisedGerber1\nNormalisedGerber2\n\n\n\n\n\n","category":"type"},{"location":"007-05-Moments/#PortfolioOptimisers.GerberCovariance-Tuple{}","page":"Gerber Covariance","title":"PortfolioOptimisers.GerberCovariance","text":"GerberCovariance(; ve::StatsBase.CovarianceEstimator = SimpleVariance(),\n                 pdm::Union{Nothing, <:Posdef} = Posdef(),\n                 threshold::Real = 0.5,\n                 alg::GerberCovarianceAlgorithm = Gerber1())\n\nConstruct a GerberCovariance estimator for robust Gerber-based covariance or correlation estimation.\n\nThis constructor creates a GerberCovariance object using the specified Gerber algorithm, variance estimator, positive definite matrix estimator, and threshold parameter. The estimator is highly modular, allowing users to select from different Gerber algorithm variants, and positive definite projections.\n\nArguments\n\nve: Variance estimator.\npdm: Positive definite matrix estimator.\nthreshold: Threshold parameter for Gerber covariance computation.\nalg: Gerber covariance algorithm variant.\n\nReturns\n\nGerberCovariance: A configured Gerber covariance estimator.\n\nValidation\n\nAsserts that threshold is strictly in (0, 1).\n\nExamples\n\njulia> gc = GerberCovariance()\nGerberCovariance\n         ve | SimpleVariance\n            |          me | SimpleExpectedReturns\n            |             |   w | nothing\n            |           w | nothing\n            |   corrected | Bool: true\n        pdm | Posdef\n            |   alg | UnionAll: NearestCorrelationMatrix.Newton\n  threshold | Float64: 0.5\n        alg | Gerber1()\n\nRelated\n\nGerberCovariance\nGerberCovarianceAlgorithm\nStatsBase.CovarianceEstimator\nSimpleVariance\nPosdef\nGerber0\nGerber1\nGerber2\nNormalisedGerber0\nNormalisedGerber1\nNormalisedGerber2\n\n\n\n\n\n","category":"method"},{"location":"007-05-Moments/#Statistics.cov-Tuple{GerberCovariance{<:Any, <:Any, <:Any, <:PortfolioOptimisers.UnNormalisedGerberCovarianceAlgorithm}, AbstractMatrix}","page":"Gerber Covariance","title":"Statistics.cov","text":"cov(ce::GerberCovariance{<:Any, <:Any, <:Any, <:UnNormalisedGerberCovarianceAlgorithm},\n    X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the Gerber covariance matrix using an unnormalised Gerber covariance estimator.\n\nThis method computes the Gerber covariance matrix for the input data matrix X using the specified unnormalised Gerber covariance estimator. The standard deviation vector is computed using the estimator's variance estimator. The Gerber correlation is computed via gerber, and the result is rescaled to a covariance matrix using the standard deviation vector.\n\nArguments\n\nce: Gerber covariance estimator.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the covariance.\nkwargs...: Additional keyword arguments passed to the standard deviation estimator.\n\nReturns\n\nsigma::Matrix{<:Real}: The Gerber covariance matrix.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nRelated\n\nGerberCovariance\ngerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:Gerber0}, X::AbstractMatrix, std_vec::AbstractArray)\ngerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:Gerber1}, X::AbstractMatrix, std_vec::AbstractArray)\ngerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:Gerber2}, X::AbstractMatrix, std_vec::AbstractArray)\ncor(ce::GerberCovariance{<:Any, <:Any, <:Any, <:UnNormalisedGerberCovarianceAlgorithm}, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"007-05-Moments/#Statistics.cov-Tuple{GerberCovariance{<:Any, <:Any, <:Any, <:PortfolioOptimisers.NormalisedGerberCovarianceAlgorithm}, AbstractMatrix}","page":"Gerber Covariance","title":"Statistics.cov","text":"cov(ce::GerberCovariance{<:Any, <:Any, <:Any, <:NormalisedGerberCovarianceAlgorithm},\n    X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the Gerber covariance matrix using a normalised Gerber covariance estimator.\n\nThis method computes the Gerber covariance matrix for the input data matrix X using the specified normalised Gerber covariance estimator. The standard deviation vector is computed using the estimator's variance estimator. The Gerber correlation is computed via gerber, and the result is rescaled to a covariance matrix using the standard deviation vector.\n\nArguments\n\nce: Gerber covariance estimator.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the covariance.\nkwargs...: Additional keyword arguments passed to the standard deviation estimator.\n\nReturns\n\nsigma::Matrix{<:Real}: The Gerber covariance matrix.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nRelated\n\nGerberCovariance\ngerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:NormalisedGerber0}, X::AbstractMatrix)\ngerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:NormalisedGerber1}, X::AbstractMatrix)\ngerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:NormalisedGerber2}, X::AbstractMatrix)\ncor(ce::GerberCovariance{<:Any, <:Any, <:Any, <:NormalisedGerberCovarianceAlgorithm}, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"007-05-Moments/#Statistics.cor-Tuple{GerberCovariance{<:Any, <:Any, <:Any, <:PortfolioOptimisers.UnNormalisedGerberCovarianceAlgorithm}, AbstractMatrix}","page":"Gerber Covariance","title":"Statistics.cor","text":"cor(ce::GerberCovariance{<:Any, <:Any, <:Any, <:UnNormalisedGerberCovarianceAlgorithm},\n    X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the Gerber correlation matrix using an unnormalised Gerber covariance estimator.\n\nThis method computes the Gerber correlation matrix for the input data matrix X using the specified unnormalised Gerber covariance estimator. The standard deviation vector is computed using the estimator's variance estimator. The Gerber correlation is then computed via gerber.\n\nArguments\n\nce: Gerber covariance estimator.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the standard deviation estimator.\n\nReturns\n\nrho::Matrix{<:Real}: The Gerber correlation matrix.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nRelated\n\nGerberCovariance\ngerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:Gerber0}, X::AbstractMatrix, std_vec::AbstractArray)\ngerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:Gerber1}, X::AbstractMatrix, std_vec::AbstractArray)\ngerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:Gerber2}, X::AbstractMatrix, std_vec::AbstractArray)\ncov(ce::GerberCovariance{<:Any, <:Any, <:Any, <:UnNormalisedGerberCovarianceAlgorithm}, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"007-05-Moments/#Statistics.cor-Tuple{GerberCovariance{<:Any, <:Any, <:Any, <:PortfolioOptimisers.NormalisedGerberCovarianceAlgorithm}, AbstractMatrix}","page":"Gerber Covariance","title":"Statistics.cor","text":"cor(ce::GerberCovariance{<:Any, <:Any, <:Any, <:NormalisedGerberCovarianceAlgorithm},\n    X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the Gerber correlation matrix using a normalised Gerber covariance estimator.\n\nThis method computes the Gerber correlation matrix for the input data matrix X using the specified normalised Gerber covariance estimator. The standard deviation vector is computed using the estimator's variance estimator. The Gerber correlation is then computed via gerber.\n\nArguments\n\nce: Gerber covariance estimator.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the standard deviation estimator.\n\nReturns\n\nrho::Matrix{<:Real}: The Gerber correlation matrix.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nRelated\n\nGerberCovariance\ngerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:NormalisedGerber0}, X::AbstractMatrix)\ngerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:NormalisedGerber1}, X::AbstractMatrix)\ngerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:NormalisedGerber2}, X::AbstractMatrix)\ncov(ce::GerberCovariance{<:Any, <:Any, <:Any, <:NormalisedGerberCovarianceAlgorithm}, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"007-05-Moments/#PortfolioOptimisers.gerber-Tuple{GerberCovariance{<:Any, <:Any, <:Any, <:Gerber0}, AbstractMatrix, AbstractArray}","page":"Gerber Covariance","title":"PortfolioOptimisers.gerber","text":"gerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:Gerber0}, X::AbstractMatrix, std_vec::AbstractArray)\n\nImplements the original Gerber correlation algorithm.\n\nThis method computes the Gerber correlation or correlation matrix for the input data matrix X using the original Gerber0 algorithm. The computation is based on thresholding the standardized data and counting co-occurrences of threshold exceedances.\n\nArguments\n\nce: Gerber correlation estimator configured with the Gerber0 algorithm.\nX: Data matrix (observations × assets).\nstd_vec: Vector of standard deviations for each asset, used to scale the threshold.\n\nReturns\n\nrho::Matrix{<:Real}: The Gerber correlation, projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each entry in X, compute two Boolean matrices:\nU: Entries where X exceeds threshold * std_vec.\nD: Entries where X is less than -threshold * std_vec.\nCompute UmD = U - D and UpD = U + D.\nThe Gerber correlation is given by (UmD' * UmD) ⊘ (UpD' * UpD).\nThe result is projected to the nearest positive definite matrix using posdef!.\n\nRelated\n\nGerberCovariance\nGerber0\nposdef!\n\n\n\n\n\n","category":"method"},{"location":"007-05-Moments/#PortfolioOptimisers.gerber-Tuple{GerberCovariance{<:Any, <:Any, <:Any, <:NormalisedGerber0}, AbstractMatrix}","page":"Gerber Covariance","title":"PortfolioOptimisers.gerber","text":"gerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:NormalisedGerber0}, X::AbstractMatrix)\n\nImplements the original Gerber correlation algorithm on Z-transformed data.\n\nThis method computes the Gerber correlation or correlation matrix for the input data matrix X using the original NormalisedGerber0 algorithm. The computation is performed on data that has already been Z-transformed (mean-centered and standardised), and is based on thresholding and counting co-occurrences of threshold exceedances.\n\nArguments\n\nce: Gerber correlation estimator configured with the NormalisedGerber0 algorithm.\nX: Z-transformed data matrix (observations × assets).\n\nReturns\n\nrho::Matrix{<:Real}: The Gerber correlation matrix, projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each entry in X, compute two Boolean matrices:\nU: Entries where X exceeds ce.threshold.\nD: Entries where X is less than -ce.threshold.\nCompute UmD = U - D and UpD = U + D.\nThe Gerber correlation is given by (UmD' * UmD) ⊘ (UpD' * UpD).\nThe result is projected to the nearest positive definite matrix using posdef!.\n\nRelated\n\nGerberCovariance\nNormalisedGerber0\nposdef!\n\n\n\n\n\n","category":"method"},{"location":"007-05-Moments/#PortfolioOptimisers.gerber-Tuple{GerberCovariance{<:Any, <:Any, <:Any, <:Gerber1}, AbstractMatrix, AbstractArray}","page":"Gerber Covariance","title":"PortfolioOptimisers.gerber","text":"gerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:Gerber1}, X::AbstractMatrix, std_vec::AbstractArray)\n\nImplements the first variant of the Gerber correlation algorithm.\n\nThis method computes the Gerber correlation or correlation matrix for the input data matrix X using the Gerber1 algorithm. The computation is based on thresholding the standardized data, counting co-occurrences of threshold exceedances, and adjusting for non-exceedance events.\n\nArguments\n\nce: Gerber correlation estimator configured with the Gerber1 algorithm.\nX: Data matrix (observations × assets).\nstd_vec: Vector of standard deviations for each asset, used to scale the threshold.\n\nReturns\n\nrho::Matrix{<:Real}: The Gerber correlation matrix, projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each entry in X, compute three Boolean matrices:\nU: Entries where X exceeds threshold * std_vec.\nD: Entries where X is less than -threshold * std_vec.\nN: Entries where X is within [-threshold * std_vec, threshold * std_vec] (i.e., neither up nor down).\nCompute UmD = U - D.\nThe Gerber1 correlation is given by (UmD' * UmD) ⊘ (T .- (N' * N)), where T is the number of observations.\nThe result is projected to the nearest positive definite matrix using posdef!.\n\n\n\n\n\n","category":"method"},{"location":"007-05-Moments/#PortfolioOptimisers.gerber-Tuple{GerberCovariance{<:Any, <:Any, <:Any, <:NormalisedGerber1}, AbstractMatrix}","page":"Gerber Covariance","title":"PortfolioOptimisers.gerber","text":"gerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:NormalisedGerber1}, X::AbstractMatrix)\n\nImplements the first variant of the Gerber correlation algorithm on Z-transformed data.\n\nThis method computes the Gerber correlation or correlation matrix for the input data matrix X using the NormalisedGerber1 algorithm. The computation is performed on data that has already been Z-transformed (mean-centered and standardised), and is based on thresholding, counting co-occurrences of threshold exceedances, and adjusting for non-exceedance events.\n\nArguments\n\nce: Gerber correlation estimator configured with the NormalisedGerber1 algorithm.\nX: Z-transformed data matrix (observations × assets).\n\nReturns\n\nrho::Matrix{<:Real}: The Gerber correlation matrix, projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each entry in X, compute three Boolean matrices:\nU: Entries where X exceeds ce.threshold.\nD: Entries where X is less than -ce.threshold.\nN: Entries where X is within [-ce.threshold, ce.threshold] (i.e., neither up nor down).\nCompute UmD = U - D.\nThe Gerber1 correlation is given by (UmD' * UmD) ⊘ (T .- (N' * N)), where T is the number of observations.\nThe result is projected to the nearest positive definite matrix using posdef!.\n\nRelated\n\nGerberCovariance\nNormalisedGerber1\nposdef!\n\n\n\n\n\n","category":"method"},{"location":"007-05-Moments/#PortfolioOptimisers.gerber-Tuple{GerberCovariance{<:Any, <:Any, <:Any, <:Gerber2}, AbstractMatrix, AbstractArray}","page":"Gerber Covariance","title":"PortfolioOptimisers.gerber","text":"gerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:Gerber2}, X::AbstractMatrix, std_vec::AbstractArray)\n\nImplements the second variant of the Gerber correlation algorithm.\n\nThis method computes the Gerber correlation or correlation matrix for the input data matrix X using the Gerber2 algorithm. The computation is based on thresholding the standardized data, constructing a signed indicator matrix, and normalizing by the geometric mean of diagonal elements.\n\nArguments\n\nce: Gerber correlation estimator configured with the Gerber2 algorithm.\nX: Data matrix (observations × assets).\nstd_vec: Vector of standard deviations for each asset, used to scale the threshold.\n\nReturns\n\nrho::Matrix{<:Real}: The Gerber correlation or correlation matrix, projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each entry in X, compute two Boolean matrices:\nU: Entries where X exceeds threshold * std_vec.\nD: Entries where X is less than -threshold * std_vec.\nCompute the signed indicator matrix UmD = U - D.\nCompute the raw Gerber2 matrix H = UmD' * UmD.\nNormalize: rho = H ⊘ (h * h'), where h = sqrt.(diag(H)).\nThe result is projected to the nearest positive definite matrix using posdef!.\n\nRelated\n\nGerberCovariance\nGerber2\nposdef!\n\n\n\n\n\n","category":"method"},{"location":"007-05-Moments/#PortfolioOptimisers.gerber-Tuple{GerberCovariance{<:Any, <:Any, <:Any, <:NormalisedGerber2}, AbstractMatrix}","page":"Gerber Covariance","title":"PortfolioOptimisers.gerber","text":"gerber(ce::GerberCovariance{<:Any, <:Any, <:Any, <:NormalisedGerber2}, X::AbstractMatrix)\n\nImplements the second variant of the Gerber correlation algorithm on Z-transformed data.\n\nThis method computes the Gerber correlation or correlation matrix for the input data matrix X using the NormalisedGerber2 algorithm. The computation is performed on data that has already been Z-transformed (mean-centered and standardised), and is based on thresholding, constructing a signed indicator matrix, and normalizing by the geometric mean of diagonal elements.\n\nArguments\n\nce: Gerber correlation estimator configured with the NormalisedGerber2 algorithm.\nX: Z-transformed data matrix (observations × assets).\n\nReturns\n\nrho::Matrix{<:Real}: The Gerber correlation matrix, projected to be positive definite using the estimator's pdm field.\n\nDetails\n\nThe algorithm proceeds as follows:\n\nFor each entry in X, compute two Boolean matrices:\nU: Entries where X exceeds ce.threshold.\nD: Entries where X is less than -ce.threshold.\nCompute the signed indicator matrix UmD = U - D.\nCompute the raw Gerber2 matrix H = UmD' * UmD.\nNormalize: rho = H ⊘ (h * h'), where h = sqrt.(diag(H)).\nThe result is projected to the nearest positive definite matrix using posdef!.\n\nRelated\n\nGerberCovariance\nNormalisedGerber2\nposdef!\n\n\n\n\n\n","category":"method"},{"location":"007-09-Moments/#Rank-Covariances","page":"Rank Covariances","title":"Rank Covariances","text":"","category":"section"},{"location":"007-09-Moments/#PortfolioOptimisers.RankCovarianceEstimator","page":"Rank Covariances","title":"PortfolioOptimisers.RankCovarianceEstimator","text":"abstract type RankCovarianceEstimator <: AbstractCovarianceEstimator end\n\nAbstract supertype for all rank-based covariance estimators in PortfolioOptimisers.jl.\n\nAll concrete types implementing rank-based covariance estimation algorithms (such as Kendall's tau or Spearman's rho) should subtype RankCovarianceEstimator. This enables a consistent interface for rank-based covariance estimators throughout the package and allows for flexible extension and dispatch.\n\nRelated\n\nKendallCovariance\nSpearmanCovariance\nAbstractCovarianceEstimator\n\n\n\n\n\n","category":"type"},{"location":"007-09-Moments/#PortfolioOptimisers.KendallCovariance","page":"Rank Covariances","title":"PortfolioOptimisers.KendallCovariance","text":"struct KendallCovariance{T1} <: RankCovarianceEstimator\n\nRobust covariance estimator based on Kendall's tau rank correlation.\n\nKendallCovariance implements a covariance estimator that uses Kendall's tau rank correlation to measure the monotonic association between pairs of asset returns. This estimator is robust to outliers and non-Gaussian data, making it suitable for financial applications where heavy tails or non-linear dependencies are present.\n\nFields\n\nve: Variance estimator used to compute marginal standard deviations.\n\nConstructor\n\nKendallCovariance(; ve::AbstractVarianceEstimator = SimpleVariance())\n\nConstruct a KendallCovariance object with the specified variance estimator.\n\nRelated\n\nRankCovarianceEstimator\nSpearmanCovariance\nAbstractVarianceEstimator\nSimpleVariance\n\n\n\n\n\n","category":"type"},{"location":"007-09-Moments/#PortfolioOptimisers.KendallCovariance-Tuple{}","page":"Rank Covariances","title":"PortfolioOptimisers.KendallCovariance","text":"KendallCovariance(; ve::AbstractVarianceEstimator = SimpleVariance())\n\nConstruct a KendallCovariance estimator for robust rank-based covariance or correlation estimation using Kendall's tau.\n\nThis constructor creates a KendallCovariance object using the specified variance estimator. The estimator computes the covariance matrix by combining the Kendall's tau rank correlation matrix with the marginal standard deviations.\n\nArguments\n\nve: Variance estimator.\n\nReturns\n\nKendallCovariance: A configured Kendall's tau-based covariance estimator.\n\nExamples\n\njulia> ce = KendallCovariance()\nKendallCovariance\n  ve | SimpleVariance\n     |          me | SimpleExpectedReturns\n     |             |   w | nothing\n     |           w | nothing\n     |   corrected | Bool: true\n\nRelated\n\nKendallCovariance\nAbstractVarianceEstimator\nAbstractVarianceEstimator\nSimpleVariance\n\n\n\n\n\n","category":"method"},{"location":"007-09-Moments/#Statistics.cor-Tuple{KendallCovariance, AbstractMatrix}","page":"Rank Covariances","title":"Statistics.cor","text":"cor(::KendallCovariance, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the Kendall's tau rank correlation matrix using a KendallCovariance estimator.\n\nThis method computes the pairwise Kendall's tau rank correlation matrix for the input data matrix X. Kendall's tau measures the monotonic association between pairs of asset returns and is robust to outliers and non-Gaussian data.\n\nArguments\n\nce: Kendall's tau-based covariance estimator.\nX: Data matrix of asset returns (observations × assets).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments (currently unused).\n\nReturns\n\nrho::Matrix{<:Real}: Symmetric matrix of Kendall's tau rank correlation coefficients.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nRelated\n\nKendallCovariance\ncorkendall\n\n\n\n\n\n","category":"method"},{"location":"007-09-Moments/#Statistics.cov-Tuple{KendallCovariance, AbstractMatrix}","page":"Rank Covariances","title":"Statistics.cov","text":"cov(ce::KendallCovariance, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the Kendall's tau rank covariance matrix using a KendallCovariance estimator.\n\nThis method computes the covariance matrix for the input data matrix X by combining the Kendall's tau rank correlation matrix with the marginal standard deviations estimated by the variance estimator in ce. This approach is robust to outliers and non-Gaussian data.\n\nArguments\n\nce: Kendall's tau-based covariance estimator.\nX: Data matrix of asset returns (observations × assets).\ndims: Dimension along which to compute the covariance.\nkwargs...: Additional keyword arguments passed to the variance estimator.\n\nReturns\n\nsigma::Matrix{<:Real}: Symmetric matrix of Kendall's tau rank covariances.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nRelated\n\nKendallCovariance\ncorkendall\n\n\n\n\n\n","category":"method"},{"location":"007-09-Moments/#PortfolioOptimisers.SpearmanCovariance","page":"Rank Covariances","title":"PortfolioOptimisers.SpearmanCovariance","text":"struct SpearmanCovariance{T1} <: RankCovarianceEstimator\n\nRobust covariance estimator based on Spearman's rho rank correlation.\n\nSpearmanCovariance implements a covariance estimator that uses Spearman's rho rank correlation to measure the monotonic association between pairs of asset returns. This estimator is robust to outliers and non-Gaussian data, making it suitable for financial applications where heavy tails or non-linear dependencies are present.\n\nFields\n\nve: Variance estimator used to compute marginal standard deviations.\n\nConstructor\n\nSpearmanCovariance(; ve::AbstractVarianceEstimator = SimpleVariance())\n\nConstruct a SpearmanCovariance object with the specified variance estimator.\n\nRelated\n\nRankCovarianceEstimator\nKendallCovariance\nAbstractVarianceEstimator\nSimpleVariance\n\n\n\n\n\n","category":"type"},{"location":"007-09-Moments/#PortfolioOptimisers.SpearmanCovariance-Tuple{}","page":"Rank Covariances","title":"PortfolioOptimisers.SpearmanCovariance","text":"SpearmanCovariance(; ve::AbstractVarianceEstimator = SimpleVariance())\n\nConstruct a SpearmanCovariance estimator for robust rank-based covariance or correlation estimation using Spearman's rho.\n\nThis constructor creates a SpearmanCovariance object using the specified variance estimator. The estimator computes the covariance matrix by combining the Spearman's rho rank correlation matrix with the marginal standard deviations.\n\nArguments\n\nve: Variance estimator.\n\nReturns\n\nSpearmanCovariance: A configured Spearman's rho-based covariance estimator.\n\nExamples\n\njulia> ce = SpearmanCovariance()\nSpearmanCovariance\n  ve | SimpleVariance\n     |          me | SimpleExpectedReturns\n     |             |   w | nothing\n     |           w | nothing\n     |   corrected | Bool: true\n\nRelated\n\nSpearmanCovariance\nAbstractVarianceEstimator\nSimpleVariance\n\n\n\n\n\n","category":"method"},{"location":"007-09-Moments/#Statistics.cor-Tuple{SpearmanCovariance, AbstractMatrix}","page":"Rank Covariances","title":"Statistics.cor","text":"cor(::SpearmanCovariance, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the Spearman's rho rank correlation matrix using a SpearmanCovariance estimator.\n\nThis method computes the pairwise Spearman's rho rank correlation matrix for the input data matrix X. Spearman's rho measures the monotonic association between pairs of asset returns and is robust to outliers and non-Gaussian data.\n\nArguments\n\nce: Spearman's rho-based covariance estimator.\nX: Data matrix of asset returns (observations × assets).\ndims: Dimension along which to compute the correlation (1 = columns/assets, 2 = rows). Default is 1.\nkwargs...: Additional keyword arguments (currently unused).\n\nReturns\n\nrho::Matrix{<:Real}: Symmetric matrix of Spearman's rho rank correlation coefficients.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nRelated\n\nSpearmanCovariance\ncorspearman\n\n\n\n\n\n","category":"method"},{"location":"007-09-Moments/#Statistics.cov-Tuple{SpearmanCovariance, AbstractMatrix}","page":"Rank Covariances","title":"Statistics.cov","text":"cov(ce::SpearmanCovariance, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the Spearman's rho rank covariance matrix using a SpearmanCovariance estimator.\n\nThis method computes the covariance matrix for the input data matrix X by combining the Spearman's rho rank correlation matrix with the marginal standard deviations estimated by the variance estimator in ce. This approach is robust to outliers and non-Gaussian data.\n\nArguments\n\nce: Spearman's rho-based covariance estimator.\nX: Data matrix of asset returns (observations × assets).\ndims: Dimension along which to compute the covariance (1 = columns/assets, 2 = rows). Default is 1.\nkwargs...: Additional keyword arguments passed to the variance estimator.\n\nReturns\n\nsigma::Matrix{<:Real}: Symmetric matrix of Spearman's rho rank covariances.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nRelated\n\nSpearmanCovariance\ncorspearman\n\n\n\n\n\n","category":"method"},{"location":"#PortfolioOptimisers","page":"PortfolioOptimisers","title":"PortfolioOptimisers","text":"","category":"section"},{"location":"","page":"PortfolioOptimisers","title":"PortfolioOptimisers","text":"Documentation for PortfolioOptimisers.","category":"page"},{"location":"#Design-philosophy","page":"PortfolioOptimisers","title":"Design philosophy","text":"","category":"section"},{"location":"","page":"PortfolioOptimisers","title":"PortfolioOptimisers","text":"There are three overarching design choices in PortfolioOptimisers.jl:","category":"page"},{"location":"","page":"PortfolioOptimisers","title":"PortfolioOptimisers","text":"Well-defined type hierarchies:\nlets us define interfaces and leverage multiple dispatch to easily and quickly add new features.\nStrongly typed immutable structs:\nreduces runtime dispatch;\nallows the compiler to perform aggressive optimisations via specialisation and constant propagation;\nthere is always a single source of truth for every process, minimising bugs and ensuring valid structures throughout program execution.\nCompositional design:\nthere are many interactions within PortfolioOptimisers.jl, by using composition we can decouple and compartmentalise processes into self-contained units;\ncomplexity arises by combining these logical subunits, their immutability means that performing assertions at variable instantiation ensures their correctness throughout the program lifetime;\nmakes development and testing easier and fearless, as each component can be tested in isolation;\nensures the only way to break existing functionality is to modify an existing structure/function;\nwe try to keep the most basal parameters in the most basal data structures, improving code reusability and maintainability, reduces the memory footprint, and allows for more flexibility.","category":"page"},{"location":"","page":"PortfolioOptimisers","title":"PortfolioOptimisers","text":"These design choices increase initial usage and development friction by raising the skill floor and lowering convenience, but ensures correctness, robustness, performance, and maintainability.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"The source files for all examples can be found in /examples.","category":"page"},{"location":"examples/5-Budget-Constraints/#Example-5:-Budget-constraints","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"","category":"section"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"This example shows how to use basic budget constraints.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"Before starting it is worth mentioning that portfolio budget constraints are implemented on the actual weights, while the short budget constraints are implemented on a relaxation variable stand-in for the short weights. This means that in some cases, it may appear the short budget constraints are not satisfied when they actually are. This is because the relaxation variables that stand in for the short weights can take on a range of values as long as they are greater than or equal to the absolute value of the actual negative weights, and still satify the budget constraint placed on them.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"using PortfolioOptimisers, PrettyTables\n# Format for pretty tables.\ntsfmt = (v, i, j) -> begin\n    if j == 1\n        return Date(v)\n    else\n        return v\n    end\nend;\nresfmt = (v, i, j) -> begin\n    if j == 1\n        return v\n    else\n        return isa(v, Number) ? \"$(round(v*100, digits=3)) %\" : v\n    end\nend;\nmipresfmt = (v, i, j) -> begin\n    if j ∈ (1, 2, 3)\n        return v\n    else\n        return isa(v, Number) ? \"$(round(v*100, digits=3)) %\" : v\n    end\nend;\nnothing #hide","category":"page"},{"location":"examples/5-Budget-Constraints/#1.-ReturnsResult-data","page":"Example 5: Budget constraints","title":"1. ReturnsResult data","text":"","category":"section"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"We will use the same data as the previous example.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"using CSV, TimeSeries, DataFrames\n\nX = TimeArray(CSV.File(joinpath(@__DIR__, \"SP500.csv.gz\")); timestamp = :Date)[(end - 252):end]\npretty_table(X[(end - 5):end]; formatters = tsfmt)\n\n# Compute the returns\nrd = prices_to_returns(X)","category":"page"},{"location":"examples/5-Budget-Constraints/#2.-Preparatory-steps","page":"Example 5: Budget constraints","title":"2. Preparatory steps","text":"","category":"section"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"We'll provide a vector of continuous solvers beacause the optimisation type we'll be using is more complex, and will contain various constraints. We will also use a more exotic risk measure.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"For the mixed interger solvers, we can use a single one.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"using Clarabel, HiGHS\nslv = [Solver(; name = :clarabel1, solver = Clarabel.Optimizer,\n              settings = Dict(\"verbose\" => false),\n              check_sol = (; allow_local = true, allow_almost = true)),\n       Solver(; name = :clarabel3, solver = Clarabel.Optimizer,\n              settings = Dict(\"verbose\" => false, \"max_step_fraction\" => 0.9),\n              check_sol = (; allow_local = true, allow_almost = true)),\n       Solver(; name = :clarabel5, solver = Clarabel.Optimizer,\n              settings = Dict(\"verbose\" => false, \"max_step_fraction\" => 0.8),\n              check_sol = (; allow_local = true, allow_almost = true)),\n       Solver(; name = :clarabel7, solver = Clarabel.Optimizer,\n              settings = Dict(\"verbose\" => false, \"max_step_fraction\" => 0.70),\n              check_sol = (; allow_local = true, allow_almost = true))];\nmip_slv = Solver(; name = :highs1, solver = HiGHS.Optimizer,\n                 settings = Dict(\"log_to_console\" => false),\n                 check_sol = (; allow_local = true, allow_almost = true));\nnothing #hide","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"This time we will use the EntropicValueatRisk measure and we will once again precompute prior.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"r = EntropicValueatRisk()\npr = prior(EmpiricalPrior(), rd)","category":"page"},{"location":"examples/5-Budget-Constraints/#3.-Exact-budget-constraints","page":"Example 5: Budget constraints","title":"3. Exact budget constraints","text":"","category":"section"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"The budget is the value of the sum of a portfolio's weights.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"Here we will showcase various budget constraints. We will start simple, with a strict budget constraint. We will also show the impact this has on the finite allocation.","category":"page"},{"location":"examples/5-Budget-Constraints/#3.1-Strict-budget-constraints","page":"Example 5: Budget constraints","title":"3.1 Strict budget constraints","text":"","category":"section"},{"location":"examples/5-Budget-Constraints/#3.1.1-Fully-invested-long-only-portfolio","page":"Example 5: Budget constraints","title":"3.1.1 Fully invested long-only portfolio","text":"","category":"section"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"First the default case, where the budget is equal to 1, bgt = 1. This means the portfolio will be fully invested.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"opt1 = JuMPOptimiser(; pe = pr, slv = slv)\nmr1 = MeanRisk(; r = r, opt = opt1)","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"You can see that wb is of type WeightBounds, lb = 0.0 (asset weights lower bound), and ub = 1.0 (asset weights upper bound), and bgt = 1.0 (budget).","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"We can check that the constraints were satisfied.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"res1 = optimise!(mr1)\nprintln(\"budget: $(sum(res1.w))\")\nprintln(\"long budget: $(sum(res1.w[res1.w .>= zero(eltype(res1.w))]))\")\nprintln(\"short budget: $(sum(res1.w[res1.w .< zero(eltype(res1.w))]))\")\nprintln(\"weight bounds: $(all(x -> zero(x) <= x <= one(x), res1.w))\")","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"Now lets allocate a finite amount of capital, 4206.9, to this portfolio.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"da = DiscreteAllocation(; slv = mip_slv)\nmip_res1 = optimise!(da, res1.w, vec(values(X[end])), 4206.9)\npretty_table(DataFrame(:assets => rd.nx, :shares => mip_res1.shares, :cost => mip_res1.cost,\n                       :opt_weights => res1.w, :mip_weights => mip_res1.w);\n             formatters = mipresfmt)\nprintln(\"long cost + short cost = cost: $(sum(mip_res1.cost))\")\nprintln(\"long cost: $(sum(mip_res1.cost[mip_res1.cost .>= zero(eltype(mip_res1.cost))]))\")\nprintln(\"short cost: $(sum(mip_res1.cost[mip_res1.cost .< zero(eltype(mip_res1.cost))]))\")\nprintln(\"remaining cash: $(mip_res1.cash)\")\nprintln(\"used cash ≈ available cash: $(isapprox(sum(mip_res1.cost) + mip_res1.cash, 4206.9 * sum(res1.w)))\")","category":"page"},{"location":"examples/5-Budget-Constraints/#3.1.2-Maximum-risk-return-ratio-market-neutral-portfolio","page":"Example 5: Budget constraints","title":"3.1.2 Maximum risk-return ratio market neutral portfolio","text":"","category":"section"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"We will now create a maximum risk-return ratio market neutral portfolio. For a market neutral portfolio, the weights must sum to zero, which means the budget is zero. This means the long and short budgets must be equal in magnitude but opposite sign. In order to avoid all zero weights, we need to set a non-zero short budget, and negative lower weight bounds.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"The short budget is given as an absolute value (simplifies implementation details). The weight bounds can be negative. We will set the maximum weight bounds to ±1, the short budget to 1 (-1 in practice), and the portfolio budget to 0, therefore the long budget is 1.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"Minimising the risk under without additional constraints often yields all zeros. So we will maximise the risk-return ratio.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"rf = 4.2 / 100 / 252\nopt2 = JuMPOptimiser(; pe = pr, slv = slv,\n                     # Budget and short budget absolute values.\n                     bgt = 0, sbgt = 1,\n                     # Weight bounds.\n                     wb = WeightBounds(; lb = -1.0, ub = 1.0))\nmr2 = MeanRisk(; r = r, obj = MaximumRatio(; rf = rf), opt = opt2)\nres2 = optimise!(mr2)\nprintln(\"budget: $(sum(res2.w))\")\nprintln(\"long budget: $(sum(res2.w[res2.w .>= zero(eltype(res2.w))]))\")\nprintln(\"short budget: $(sum(res2.w[res2.w .< zero(eltype(res2.w))]))\")\nprintln(\"weight bounds: $(all(x -> -one(x) <= x <= one(x), res2.w))\")","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"Lets allocate a finite amount of capital. Since we set the long and short budgets equal to 1, the cost of the long and short positions will be approximately equal to the allocated value of 4206.9, and the sum of the costs will be close to zero. The discrepancies are due to the fact that we are allocating a finite amount of capital.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"The discrete allocation procedure automatically adjusts the cash amount depending on the optimal long and short weights, so there is no need to split the cash amount into long and short allocations.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"mip_res2 = optimise!(da, res2.w, vec(values(X[end])), 4206.9)\npretty_table(DataFrame(:assets => rd.nx, :shares => mip_res2.shares, :cost => mip_res2.cost,\n                       :opt_weights => res2.w, :mip_weights => mip_res2.w);\n             formatters = mipresfmt)\nprintln(\"long cost + short cost = cost: $(sum(mip_res2.cost))\")\nprintln(\"long cost: $(sum(mip_res2.cost[mip_res2.cost .>= zero(eltype(mip_res2.cost))]))\")\nprintln(\"short cost: $(sum(mip_res2.cost[mip_res2.cost .< zero(eltype(mip_res2.cost))]))\")\nprintln(\"remaining cash: $(mip_res2.cash)\")\nprintln(\"used cash ≈ available cash: $(isapprox(sum(abs.(mip_res2.cost)) + mip_res2.cash, 4206.9 * sum(abs.(res2.w))))\")","category":"page"},{"location":"examples/5-Budget-Constraints/#3.1.3-Short-only-portfolio","page":"Example 5: Budget constraints","title":"3.1.3 Short-only portfolio","text":"","category":"section"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"We will now create and discretely allocate a short-only portfolio. This is in general an anti-pattern but oen can use various combinations of budget, weight bounds and short budget constraints to create hedging portfolios.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"opt3 = JuMPOptimiser(; pe = pr, slv = slv,\n                     # Budget and short budget absolute values.\n                     bgt = -1, sbgt = 1,\n                     # Weight bounds.\n                     wb = WeightBounds(; lb = -1.0, ub = 0.0))\nmr3 = MeanRisk(; r = r, obj = MinimumRisk(), opt = opt3)\nres3 = optimise!(mr3)\nprintln(\"budget: $(sum(res3.w))\")\nprintln(\"long budget: $(sum(res3.w[res3.w .>= zero(eltype(res3.w))]))\")\nprintln(\"short budget: $(sum(res3.w[res3.w .< zero(eltype(res3.w))]))\")\nprintln(\"weight bounds: $(all(x -> -one(x) <= x <= zero(x), res3.w))\")","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"We can confirm that the finite allocation behaves as expected.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"mip_res3 = optimise!(da, res3.w, vec(values(X[end])), 4206.9)\npretty_table(DataFrame(:assets => rd.nx, :shares => mip_res3.shares, :cost => mip_res3.cost,\n                       :opt_weights => res3.w, :mip_weights => mip_res3.w);\n             formatters = mipresfmt)\nprintln(\"long cost + short cost = cost: $(sum(mip_res3.cost))\")\nprintln(\"long cost: $(sum(mip_res3.cost[mip_res3.cost .>= zero(eltype(mip_res3.cost))]))\")\nprintln(\"short cost: $(sum(mip_res3.cost[mip_res3.cost .< zero(eltype(mip_res3.cost))]))\")\nprintln(\"remaining cash: $(mip_res3.cash)\")\nprintln(\"used cash ≈ available cash: $(isapprox(sum(mip_res3.cost) - mip_res3.cash, 4206.9 * sum(res3.w)))\")","category":"page"},{"location":"examples/5-Budget-Constraints/#3.1.4-Leveraged-portfolios","page":"Example 5: Budget constraints","title":"3.1.4 Leveraged portfolios","text":"","category":"section"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"Lets try a leveraged long-only portfolio.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"opt4 = JuMPOptimiser(; pe = pr, slv = slv, bgt = 1.3)\nmr4 = MeanRisk(; r = r, opt = opt4)\nres4 = optimise!(mr4)\nprintln(\"budget: $(sum(res4.w))\")\nprintln(\"long budget: $(sum(res4.w[res4.w .>= zero(eltype(res4.w))]))\")\nprintln(\"short budget: $(sum(res4.w[res4.w .< zero(eltype(res4.w))]))\")\nprintln(\"weight bounds: $(all(x -> zero(x) <= x <= one(x), res4.w))\")","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"Again, the finite allocation respects the budget constraints.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"mip_res4 = optimise!(da, res4.w, vec(values(X[end])), 4206.9)\npretty_table(DataFrame(:assets => rd.nx, :shares => mip_res4.shares, :cost => mip_res4.cost,\n                       :opt_weights => res4.w, :mip_weights => mip_res4.w);\n             formatters = mipresfmt)\nprintln(\"long cost + short cost = cost: $(sum(mip_res4.cost))\")\nprintln(\"long cost: $(sum(mip_res4.cost[mip_res4.cost .>= zero(eltype(mip_res4.cost))]))\")\nprintln(\"short cost: $(sum(mip_res4.cost[mip_res4.cost .< zero(eltype(mip_res4.cost))]))\")\nprintln(\"remaining cash: $(mip_res4.cash)\")\nprintln(\"used cash ≈ available cash: $(isapprox(sum(mip_res4.cost) + mip_res4.cash, 4206.9 * sum(res4.w)))\")","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"We will now optimise an underleveraged long-short portfolio.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"Note that the short budget is not satisfied, this is because it is implemented as an equality constraint on a relaxation variable stand-in for the short weights. However, the portfolio budget constraint is satisfied because it is an equality constraint on the actual weights.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"It is also possible to set budget bounds for the short and portfolio bugets. They are implemented in the same way as the equality constraints. We will explore them in the next section.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"opt5 = JuMPOptimiser(; pe = pr, slv = slv,\n                     # Budget and short budget absolute values.\n                     bgt = 0.5, sbgt = 1,\n                     # Weight bounds.\n                     wb = WeightBounds(; lb = -1.0, ub = 1.0))\nmr5 = MeanRisk(; r = r, opt = opt5)\nres5 = optimise!(mr5)\nprintln(\"budget: $(sum(res5.w))\")\nprintln(\"long budget: $(sum(res5.w[res5.w .>= zero(eltype(res5.w))]))\")\nprintln(\"short budget: $(sum(res5.w[res5.w .< zero(eltype(res5.w))]))\")\nprintln(\"weight bounds: $(all(x -> -one(x) <= x <= one(x), res5.w))\")","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"For this portfolio, the sum of the long and short cost will be approximately equal to half the allocated value of 4206.9. Any discrepancies are due to the fact we are allocating a finite amount.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"mip_res5 = optimise!(da, res5.w, vec(values(X[end])), 4506.9)\npretty_table(DataFrame(:assets => rd.nx, :shares => mip_res5.shares, :cost => mip_res5.cost,\n                       :opt_weights => res5.w, :mip_weights => mip_res5.w);\n             formatters = mipresfmt)\nprintln(\"long cost + short cost = cost: $(sum(mip_res5.cost))\")\nprintln(\"long cost: $(sum(mip_res5.cost[mip_res5.cost .>= zero(eltype(mip_res5.cost))]))\")\nprintln(\"short cost: $(sum(mip_res5.cost[mip_res5.cost .< zero(eltype(mip_res5.cost))]))\")\nprintln(\"remaining cash: $(mip_res5.cash)\")\nprintln(\"used cash ≈ available cash: $(isapprox(sum(abs.(mip_res5.cost)) + mip_res5.cash, 4506.9 * sum(abs.(res5.w))))\")","category":"page"},{"location":"examples/5-Budget-Constraints/#4.-Budget-range","page":"Example 5: Budget constraints","title":"4. Budget range","text":"","category":"section"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"The other type of buget constraint we will explore in this example is the budget range constraint, BudgetRange. It allows the user to define upper and lower bounds on the budget and short budget. When using a BudgetRange, it is necessary to provide both the upper and lower bounds.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"We mentioned at the start of this example that the interaction between budget and short budget constraints might be unintuitive due to how the constraints are implemented. The following example will illustrate this.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"opt6 = JuMPOptimiser(; pe = pr, slv = slv,\n                     # Budget range.\n                     bgt = BudgetRange(; lb = -0.6, ub = 0.6),\n                     # Exact short budget\n                     sbgt = 0.5,\n                     # Weight bounds.\n                     wb = WeightBounds(; lb = -1.0, ub = 1.0))\nmr6 = MeanRisk(; r = r, obj = MaximumRatio(; rf = rf), opt = opt6)\nres6 = optimise!(mr6)\nprintln(\"budget: $(sum(res6.w))\")\nprintln(\"long budget: $(sum(res6.w[res6.w .>= zero(eltype(res6.w))]))\")\nprintln(\"short budget: $(sum(res6.w[res6.w .< zero(eltype(res6.w))]))\")\nprintln(\"weight bounds: $(all(x -> -one(x) <= x <= one(x), res6.w))\")","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"As you can see, the budget and weight constraints are satisfied, but not the short budget constraint. This happens even if we do not provide a short budget. This is a reflection of the fact that the weight and budget constraints are constraints on the actual weights. While the short budget constraints are constraints on relaxation variables, whose value must be greater than or equal to the absolute value of the negative weights. This gives them room to without violating the constraints and without directly constraining the short weights.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"In order to remedy this, we can provide a BudgetRange to the short budget which eliminates the slack on the relaxation variables. It is worth noting that when providing a BudgetRange to the short budget, the bounds cannot be negative.","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"opt7 = JuMPOptimiser(; pe = pr, slv = slv,\n                     # Budget range.\n                     bgt = BudgetRange(; lb = -0.6, ub = 0.6),\n                     # Remove the slack from the short budget.\n                     sbgt = BudgetRange(; lb = 0.5, ub = 0.5),\n                     # Weight bounds.\n                     wb = WeightBounds(; lb = -1.0, ub = 1.0))\nmr7 = MeanRisk(; r = r, obj = MaximumRatio(; rf = rf), opt = opt7)\nres7 = optimise!(mr7)\nprintln(\"budget: $(sum(res7.w))\")\nprintln(\"long budget: $(sum(res7.w[res7.w .>= zero(eltype(res7.w))]))\")\nprintln(\"short budget: $(sum(res7.w[res7.w .< zero(eltype(res7.w))]))\")\nprintln(\"weight bounds: $(all(x -> -one(x) <= x <= one(x), res7.w))\")","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"","category":"page"},{"location":"examples/5-Budget-Constraints/","page":"Example 5: Budget constraints","title":"Example 5: Budget constraints","text":"This page was generated using Literate.jl.","category":"page"},{"location":"002-Tools/#Tools","page":"Tools","title":"Tools","text":"","category":"section"},{"location":"002-Tools/#PortfolioOptimisers.ReturnsResult","page":"Tools","title":"PortfolioOptimisers.ReturnsResult","text":"struct ReturnsResult{T1, T2, T3, T4, T5, T6, T7} <: AbstractReturnsResult\n    nx::T1\n    X::T2\n    nf::T3\n    F::T4\n    ts::T5\n    iv::T6\n    ivpa::T7\nend\n\nA flexible container type for storing the results of asset and factor returns calculations in PortfolioOptimisers.jl.\n\nReturnsResult is the standard result type returned by returns-processing routines, such as prices_to_returns. It supports both asset and factor returns, as well as optional time series and implied volatility information, and is designed for downstream compatibility with optimization and analysis routines.\n\nFields\n\nnx: Names or identifiers of asset columns.\nX: Asset returns matrix (observations × assets).\nnf: Names or identifiers of factor columns.\nF: Factor returns matrix (observations × factors).\nts: Optional timestamps for each observation.\niv: Implied volatilities matrix.\nivpa: Implied volatility risk premium adjustment.\n\nConstructor\n\nReturnsResult(; nx=nothing, X=nothing, nf=nothing, F=nothing, ts=nothing, iv=nothing, ivpa=nothing)\n\nKeyword arguments correspond to the fields above. The constructor performs internal consistency checks (e.g., matching dimensions, non-emptiness, positivity for variances).\n\nRelated\n\nAbstractReturnsResult\nprices_to_returns\n\n\n\n\n\n","category":"type"},{"location":"002-Tools/#PortfolioOptimisers.ReturnsResult-Tuple{}","page":"Tools","title":"PortfolioOptimisers.ReturnsResult","text":"ReturnsResult(; nx::Union{Nothing, <:AbstractVector} = nothing,\n                X::Union{Nothing, <:AbstractMatrix} = nothing,\n                nf::Union{Nothing, <:AbstractVector} = nothing,\n                F::Union{Nothing, <:AbstractMatrix} = nothing,\n                ts::Union{Nothing, <:AbstractVector} = nothing,\n                iv::Union{Nothing, <:AbstractMatrix} = nothing,\n                ivpa::Union{Nothing, <:Real, <:AbstractVector{<:Real}} = nothing)\n\nConstruct a ReturnsResult object, validating dimensions and types for asset and factor returns, time series, and instrument variance data.\n\nArguments\n\nnx: Asset names or identifiers.\nX: Asset returns matrix.\nnf: Factor names or identifiers.\nF: Factor returns matrix.\nts: Timestamps.\niv: Implied volatility matrix.\nivpa: Implied volatility risk premium adjustment.\n\nValidation\n\nIf nx or X is provided, both must be non-empty and length(nx) == size(X, 2).\nIf nf or F is provided, both must be non-empty and length(nf) == size(F, 2), and size(X, 1) == size(F, 1).\nIf ts is provided, must be non-empty and length(ts) == size(X, 1).\nIf iv is provided, must be non-empty, positive, and size(iv) == size(X).\nIf ivpa is provided, must be positive and finite; if a vector, length(ivpa) == size(iv, 2).\n\nExamples\n\njulia> ReturnsResult(; nx = [\"A\", \"B\"], X = [0.1 0.2; 0.3 0.4])\nReturnsResult\n    nx | Vector{String}: [\"A\", \"B\"]\n     X | 2×2 Matrix{Float64}\n    nf | nothing\n     F | nothing\n    ts | nothing\n    iv | nothing\n  ivpa | nothing\n\nRelated\n\nReturnsResult\nprices_to_returns\n\n\n\n\n\n","category":"method"},{"location":"002-Tools/#PortfolioOptimisers.prices_to_returns","page":"Tools","title":"PortfolioOptimisers.prices_to_returns","text":"prices_to_returns(X::TimeArray, F::TimeArray = TimeArray(TimeType[], []);\n                  iv::Union{Nothing, <:TimeArray} = nothing,\n                  ivpa::Union{Nothing, <:Real, <:AbstractVector{<:Real}} = nothing,\n                  ret_method::Symbol = :simple, padding::Bool = false,\n                  missing_col_percent::Real = 1.0,\n                  missing_row_percent::Union{Nothing, <:Real} = 1.0,\n                  collapse_args::Tuple = (),\n                  map_func::Union{Nothing, Function} = nothing,\n                  join_method::Symbol = :outer,\n                  impute_method::Union{Nothing, <:Impute.Imputor} = nothing)\n\nConvert price data (and optionally factor data) in TimeArray format to returns, with flexible handling of missing data, imputation, and optional implied volatility information.\n\nReturnsResult a ReturnsResult containing asset and factor returns, time series, and optional implied volatility data, suitable for downstream portfolio optimization.\n\nArguments\n\nX: Asset price data (timestamps × assets).\nF: Optional Factor price data (timestamps × factors).\niv: Optional Implied volatility data.\nivpa: Optional Implied volatility risk premium adjustment.\nret_method: Return calculation method (:simple or :log).\npadding: Whether to pad missing values in returns calculation.\nmissing_col_percent: Maximum allowed fraction of missing values per column (asset/factor).\nmissing_row_percent: Maximum allowed fraction of missing values per row (timestamp).\ncollapse_args: Arguments for collapsing the time series (e.g., to lower frequency).\nmap_func: Optional function to apply to the data before returns calculation.\njoin_method: How to join asset and factor data (:outer, :inner, etc.).\nimpute_method: Optional imputation method for missing data.\n\nReturns\n\nReturnsResult: Struct containing asset/factor returns, names, time series, and optional implied volatility data.\n\nValidation\n\nEnsures consistency of asset/factor names and dimensions.\nHandles missing data according to specified thresholds and imputation method.\nValidates implied volatility and risk premium adjustment if provided.\n\nExamples\n\njulia> using TimeSeries\n\njulia> X = TimeArray(Date(2020, 1, 1):Day(1):Date(2020, 1, 3), [100 101; 102 103; 104 105],\n                     [\"A\", \"B\"])\n3×2 TimeSeries.TimeArray{Int64, 2, Dates.Date, Matrix{Int64}} 2020-01-01 to 2020-01-03\n┌────────────┬─────┬─────┐\n│            │ A   │ B   │\n├────────────┼─────┼─────┤\n│ 2020-01-01 │ 100 │ 101 │\n│ 2020-01-02 │ 102 │ 103 │\n│ 2020-01-03 │ 104 │ 105 │\n└────────────┴─────┴─────┘\n\njulia> rr = prices_to_returns(X)\nReturnsResult\n    nx | Vector{String}: [\"A\", \"B\"]\n     X | 2×2 Matrix{Float64}\n    nf | nothing\n     F | nothing\n    ts | Vector{Dates.Date}: [Dates.Date(\"2020-01-02\"), Dates.Date(\"2020-01-03\")]\n    iv | nothing\n  ivpa | nothing\n\nRelated\n\nReturnsResult\n\n\n\n\n\n","category":"function"},{"location":"002-Tools/#PortfolioOptimisers.brinson_attribution","page":"Tools","title":"PortfolioOptimisers.brinson_attribution","text":"brinson_attribution(X::TimeArray, w::AbstractVector, wb::AbstractVector,\n                    asset_classes::DataFrame, col, date0 = nothing,\n                    date1 = nothing)\n\n\n\n\n\n","category":"function"},{"location":"002-Tools/#PortfolioOptimisers.AbstractReturnsResult","page":"Tools","title":"PortfolioOptimisers.AbstractReturnsResult","text":"AbstractReturnsResult <: AbstractResult\n\nAbstract supertype for all returns result types in PortfolioOptimisers.jl.\n\nAll concrete types representing the result of returns calculations (e.g., asset returns, factor returns) should subtype AbstractReturnsResult. This enables a consistent interface for downstream analysis and optimization routines.\n\nRelated\n\nAbstractResult\nReturnsResult\n\n\n\n\n\n","category":"type"},{"location":"002-Tools/#PortfolioOptimisers.assert_matrix_issquare","page":"Tools","title":"PortfolioOptimisers.assert_matrix_issquare","text":"assert_matrix_issquare(A::AbstractMatrix)\n\nAssert that A is a square matrix.\n\n\n\n\n\n","category":"function"},{"location":"002-Tools/#PortfolioOptimisers.:⊗","page":"Tools","title":"PortfolioOptimisers.:⊗","text":"⊗(A::AbstractArray, B::AbstractArray)\n\nTensor product of two arrays. ReturnsResult a matrix of size (length(A), length(B)) where each element is the product of elements from A and B.\n\nExamples\n\njulia> PortfolioOptimisers.:⊗([1, 2], [3, 4])\n2×2 Matrix{Int64}:\n 3  4\n 6  8\n\n\n\n\n\n","category":"function"},{"location":"002-Tools/#PortfolioOptimisers.:⊙","page":"Tools","title":"PortfolioOptimisers.:⊙","text":"⊙(A, B)\n\nElementwise multiplication.\n\nExamples\n\njulia> PortfolioOptimisers.:⊙([1, 2], [3, 4])\n2-element Vector{Int64}:\n 3\n 8\n\njulia> PortfolioOptimisers.:⊙([1, 2], 2)\n2-element Vector{Int64}:\n 2\n 4\n\njulia> PortfolioOptimisers.:⊙(2, [3, 4])\n2-element Vector{Int64}:\n 6\n 8\n\njulia> PortfolioOptimisers.:⊙(2, 3)\n6\n\n\n\n\n\n","category":"function"},{"location":"002-Tools/#PortfolioOptimisers.:⊘","page":"Tools","title":"PortfolioOptimisers.:⊘","text":"⊘(A, B)\n\nElementwise division.\n\nExamples\n\njulia> PortfolioOptimisers.:⊘([4, 9], [2, 3])\n2-element Vector{Float64}:\n 2.0\n 3.0\n\njulia> PortfolioOptimisers.:⊘([4, 6], 2)\n2-element Vector{Float64}:\n 2.0\n 3.0\n\njulia> PortfolioOptimisers.:⊘(8, [2, 4])\n2-element Vector{Float64}:\n 4.0\n 2.0\n\njulia> PortfolioOptimisers.:⊘(8, 2)\n4.0\n\n\n\n\n\n","category":"function"},{"location":"002-Tools/#PortfolioOptimisers.:⊕","page":"Tools","title":"PortfolioOptimisers.:⊕","text":"⊕(A, B)\n\nElementwise addition.\n\nExamples\n\njulia> PortfolioOptimisers.:⊕([1, 2], [3, 4])\n2-element Vector{Int64}:\n 4\n 6\n\njulia> PortfolioOptimisers.:⊕([1, 2], 2)\n2-element Vector{Int64}:\n 3\n 4\n\njulia> PortfolioOptimisers.:⊕(2, [3, 4])\n2-element Vector{Int64}:\n 5\n 6\n\njulia> PortfolioOptimisers.:⊕(2, 3)\n5\n\n\n\n\n\n","category":"function"},{"location":"002-Tools/#PortfolioOptimisers.:⊖","page":"Tools","title":"PortfolioOptimisers.:⊖","text":"⊖(A, B)\n\nElementwise subtraction.\n\nExamples\n\njulia> PortfolioOptimisers.:⊖([4, 6], [1, 2])\n2-element Vector{Int64}:\n 3\n 4\n\njulia> PortfolioOptimisers.:⊖([4, 6], 2)\n2-element Vector{Int64}:\n 2\n 4\n\njulia> PortfolioOptimisers.:⊖(8, [2, 4])\n2-element Vector{Int64}:\n 6\n 4\n\njulia> PortfolioOptimisers.:⊖(8, 2)\n6\n\n\n\n\n\n","category":"function"},{"location":"002-Tools/#PortfolioOptimisers.traverse_concrete_subtypes","page":"Tools","title":"PortfolioOptimisers.traverse_concrete_subtypes","text":"traverse_concrete_subtypes(t, ctarr::Union{Nothing, <:AbstractVector} = nothing)\n\nRecursively traverse all subtypes of the given abstract type t and collect all concrete struct types into ctarr.\n\nArguments\n\nt: An abstract type whose subtypes will be traversed.\nctarr: Optional An array to collect the concrete types. If not provided, a new empty array is created.\n\nReturns\n\nAn array containing all concrete struct types that are subtypes (direct or indirect) of types.\n\nExamples\n\njulia> abstract type MyAbstract end\n\njulia> struct MyConcrete1 <: MyAbstract end\n\njulia> struct MyConcrete2 <: MyAbstract end\n\njulia> traverse_concrete_subtypes(MyAbstract)\n2-element Vector{Any}:\n MyConcrete1\n MyConcrete2\n\n\n\n\n\n","category":"function"},{"location":"002-Tools/#PortfolioOptimisers.concrete_typed_array","page":"Tools","title":"PortfolioOptimisers.concrete_typed_array","text":"concrete_typed_array(A::AbstractArray)\n\nConvert an AbstractArray A to a concrete typed array, where each element is of the same type as the elements of A.\n\nThis is useful for converting arrays with abstract element types to arrays with concrete element types, which can improve performance in some cases.\n\nArguments\n\nA: The input array.\n\nReturns\n\nA new array with the same shape as A, but with a concrete element type inferred from the elements of A.\n\nExamples\n\njulia> A = Any[1, 2.0, 3];\n\njulia> PortfolioOptimisers.concrete_typed_array(A)\n3-element reshape(::Vector{Union{Float64, Int64}}, 3) with eltype Union{Float64, Int64}:\n 1\n 2.0\n 3\n\n\n\n\n\n","category":"function"},{"location":"002-Tools/#PortfolioOptimisers.dot_scalar","page":"Tools","title":"PortfolioOptimisers.dot_scalar","text":"dot_scalar(a::Real, b::AbstractVector)\ndot_scalar(a::AbstractVector, b::Real)\ndot_scalar(a::AbstractVector, b::AbstractVector)\n\nEfficient scalar and vector dot product utility.\n\nIf one argument is a scalar and the other a vector, returns the scalar times the sum of the vector.\nIf both arguments are vectors, returns their dot product.\n\nArguments\n\na::Real, b::AbstractVector: Multiplies a by the sum of b.\na::AbstractVector, b::Real: Multiplies the sum of a by b.\na::AbstractVector, b::AbstractVector: Computes the dot product of a and b.\n\nReturns\n\nReal: The resulting scalar.\n\nExamples\n\njulia> PortfolioOptimisers.dot_scalar(2.0, [1.0, 2.0, 3.0])\n12.0\n\njulia> PortfolioOptimisers.dot_scalar([1.0, 2.0, 3.0], 2.0)\n12.0\n\njulia> PortfolioOptimisers.dot_scalar([1.0, 2.0, 3.0], [4.0, 5.0, 6.0])\n32.0\n\n\n\n\n\n","category":"function"},{"location":"002-Tools/#PortfolioOptimisers.nothing_scalar_array_view","page":"Tools","title":"PortfolioOptimisers.nothing_scalar_array_view","text":"nothing_scalar_array_view(x, i)\n\nUtility for safely viewing or indexing into possibly nothing, scalar, or array values.\n\nIf x is nothing, returns nothing.\nIf x is a scalar, returns x.\nIf x is a vector, returns view(x, i).\nIf x is a vector of vectors, returns view.(x, Ref(i)).\nIf x is a matrix or higher array, returns view(x, i, i).\n\nArguments\n\nx: Input value, which may be nothing, a scalar, vector, or array.\ni: Index or indices to view.\n\nReturns\n\nThe corresponding view or value, or nothing if x is nothing.\n\nExamples\n\njulia> PortfolioOptimisers.nothing_scalar_array_view(nothing, 1:2)\n\njulia> PortfolioOptimisers.nothing_scalar_array_view(3.0, 1:2)\n3.0\n\njulia> PortfolioOptimisers.nothing_scalar_array_view([1.0, 2.0, 3.0], 2:3)\n2-element view(::Vector{Float64}, 2:3) with eltype Float64:\n 2.0\n 3.0\n\njulia> PortfolioOptimisers.nothing_scalar_array_view([[1, 2], [3, 4]], 1)\n2-element Vector{SubArray{Int64, 0, Vector{Int64}, Tuple{Int64}, true}}:\n fill(1)\n fill(3)\n\n\n\n\n\n","category":"function"},{"location":"002-Tools/#PortfolioOptimisers.nothing_scalar_array_view_odd_order","page":"Tools","title":"PortfolioOptimisers.nothing_scalar_array_view_odd_order","text":"nothing_scalar_array_view_odd_order(x, i, j)\n\nUtility for safely viewing or indexing into possibly nothing or array values with two indices.\n\nIf x is nothing, returns nothing.\nOtherwise, returns view(x, i, j).\n\nArguments\n\nx: Input value, which may be nothing or an array.\ni, j: Indices to view.\n\nReturns\n\nThe corresponding view or nothing.\n\nExamples\n\njulia> PortfolioOptimisers.nothing_scalar_array_view_odd_order(nothing, 1, 2)\n\njulia> PortfolioOptimisers.nothing_scalar_array_view_odd_order([1 2; 3 4], 1, 2)\n0-dimensional view(::Matrix{Int64}, 1, 2) with eltype Int64:\n2\n\n\n\n\n\n","category":"function"},{"location":"002-Tools/#PortfolioOptimisers.nothing_scalar_array_getindex","page":"Tools","title":"PortfolioOptimisers.nothing_scalar_array_getindex","text":"nothing_scalar_array_getindex(x, i)\nnothing_scalar_array_getindex(x, i, j)\n\nUtility for safely indexing into possibly nothing, scalar, vector, or array values.\n\nIf x is nothing, returns nothing.\nIf x is a scalar, returns x.\nIf x is a vector, returns x[i].\nIf x is a matrix, returns x[i, i] or x[i, j].\n\nArguments\n\nx: Input value, which may be nothing, a scalar, vector, or matrix.\ni, j: Indices.\n\nReturns\n\nThe corresponding value or nothing.\n\nExamples\n\njulia> PortfolioOptimisers.nothing_scalar_array_getindex(nothing, 1)\n\njulia> PortfolioOptimisers.nothing_scalar_array_getindex(3.0, 1)\n3.0\n\njulia> PortfolioOptimisers.nothing_scalar_array_getindex([1.0, 2.0, 3.0], 2)\n2.0\n\njulia> PortfolioOptimisers.nothing_scalar_array_getindex([1 2; 3 4], 2)\n4\n\njulia> PortfolioOptimisers.nothing_scalar_array_getindex([1 2; 3 4], 1, 2)\n2\n\n\n\n\n\n","category":"function"},{"location":"002-Tools/#PortfolioOptimisers.nothing_asset_sets_view","page":"Tools","title":"PortfolioOptimisers.nothing_asset_sets_view","text":"nothing_asset_sets_view(::Nothing, ::Any)\n\nNo-op fallback for indexing nothing asset sets.\n\n\n\n\n\n","category":"function"},{"location":"002-Tools/#PortfolioOptimisers.fourth_moment_index_factory","page":"Tools","title":"PortfolioOptimisers.fourth_moment_index_factory","text":"fourth_moment_index_factory(N::Integer, i::AbstractVector)\n\nConstructs an index vector for extracting the fourth moment submatrix corresponding to indices i from a covariance matrix of size N × N.\n\nArguments\n\nN: Size of the full covariance matrix.\ni: Indices of the variables of interest.\n\nReturns\n\nidx::Vector{Int}: Indices for extracting the fourth moment submatrix.\n\nExamples\n\njulia> PortfolioOptimisers.fourth_moment_index_factory(3, [1, 2])\n4-element Vector{Int64}:\n 1\n 2\n 4\n 5\n\n\n\n\n\n","category":"function"},{"location":"007-03-Moments/#Covariance","page":"Covariance","title":"Covariance","text":"","category":"section"},{"location":"007-03-Moments/#PortfolioOptimisers.GeneralWeightedCovariance","page":"Covariance","title":"PortfolioOptimisers.GeneralWeightedCovariance","text":"GeneralWeightedCovariance{T1, T2} <: AbstractCovarianceEstimator\n\nA flexible covariance estimator for PortfolioOptimisers.jl supporting arbitrary covariance estimators and optional observation weights.\n\nGeneralWeightedCovariance allows users to specify both the covariance estimation method and optional observation weights. This enables robust and extensible covariance estimation workflows.\n\nFields\n\nce: Covariance estimator.\nw: Optional weights for each observation. If nothing, the estimator is unweighted.\n\nConstructor\n\nGeneralWeightedCovariance(; ce::StatsBase.CovarianceEstimator = SimpleCovariance(; corrected = true),\n                           w::Union{Nothing, <:AbstractWeights} = nothing)\n\nConstruct a GeneralWeightedCovariance estimator with the specified covariance estimator and optional weights.\n\nRelated\n\nAbstractCovarianceEstimator\nStatsBase.CovarianceEstimator\nStatsBase.AbstractWeights\ncov(ce::GeneralWeightedCovariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\n\n\n\n\n","category":"type"},{"location":"007-03-Moments/#PortfolioOptimisers.GeneralWeightedCovariance-Tuple{}","page":"Covariance","title":"PortfolioOptimisers.GeneralWeightedCovariance","text":"GeneralWeightedCovariance(; ce::StatsBase.CovarianceEstimator = StatsBase.SimpleCovariance(; corrected = true),\n                           w::Union{Nothing, <:AbstractWeights} = nothing)\n\nConstruct a GeneralWeightedCovariance estimator for flexible covariance estimation with optional observation weights.\n\nThis constructor creates a GeneralWeightedCovariance object using the specified covariance estimator and optional weights. If no weights are provided, the estimator defaults to unweighted covariance estimation. If weights are provided, they must not be empty.\n\nArguments\n\nce: Covariance estimator to use.\nw: Optional observation weights. If nothing, the estimator is unweighted. If provided, must be non-empty.\n\nReturns\n\nGeneralWeightedCovariance: A covariance estimator configured with the specified method and optional weights.\n\nValidation\n\nIf w is provided, it must not be empty.\n\nExamples\n\njulia> using StatsBase\n\njulia> gwc = GeneralWeightedCovariance()\nGeneralWeightedCovariance\n  ce | StatsBase.SimpleCovariance: StatsBase.SimpleCovariance(true)\n   w | nothing\n\njulia> w = Weights([0.1, 0.2, 0.7]);\n\njulia> gwc = GeneralWeightedCovariance(; w = w)\nGeneralWeightedCovariance\n  ce | StatsBase.SimpleCovariance: StatsBase.SimpleCovariance(true)\n   w | StatsBase.Weights{Float64, Float64, Vector{Float64}}: [0.1, 0.2, 0.7]\n\nRelated\n\nGeneralWeightedCovariance\nAbstractCovarianceEstimator\nStatsBase.CovarianceEstimator\nStatsBase.AbstractWeights\ncov(ce::GeneralWeightedCovariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"007-03-Moments/#Statistics.cov-Tuple{GeneralWeightedCovariance, AbstractMatrix}","page":"Covariance","title":"Statistics.cov","text":"cov(ce::GeneralWeightedCovariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\nCompute the covariance matrix using a GeneralWeightedCovariance estimator.\n\nThis method dispatches to robust_cov, using the specified covariance estimator and optional observation weights stored in ce. If no weights are provided, the unweighted covariance is computed; otherwise, the weighted covariance is used.\n\nArguments\n\nce: Covariance estimator containing the method and optional weights.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the covariance.\nmean: Optional mean vector to use for centering.\nkwargs...: Additional keyword arguments passed to robust_cov.\n\nReturns\n\nCovariance matrix as computed by the estimator and optional weights.\n\nRelated\n\nrobust_cov\ncor(ce::GeneralWeightedCovariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"007-03-Moments/#Statistics.cor-Tuple{GeneralWeightedCovariance, AbstractMatrix}","page":"Covariance","title":"Statistics.cor","text":"cor(ce::GeneralWeightedCovariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\nCompute the correlation matrix using a GeneralWeightedCovariance estimator.\n\nThis method dispatches to robust_cor, using the specified covariance estimator and optional observation weights stored in ce. If no weights are provided, the unweighted correlation is computed; otherwise, the weighted correlation is used.\n\nArguments\n\nce: Covariance estimator containing the method and optional weights.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the correlation.\nmean: Optional mean vector to use for centering.\nkwargs...: Additional keyword arguments passed to robust_cor.\n\nReturns\n\nCorrelation matrix as computed by the estimator and optional weights.\n\nRelated\n\nrobust_cor\ncov(ce::GeneralWeightedCovariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"007-03-Moments/#PortfolioOptimisers.Covariance","page":"Covariance","title":"PortfolioOptimisers.Covariance","text":"struct Covariance{T1, T2, T3} <: AbstractCovarianceEstimator\n    me::T1\n    ce::T2\n    alg::T3\nend\n\nA flexible container type for configuring and applying joint expected returns and covariance estimation in PortfolioOptimisers.jl.\n\nCovariance encapsulates all components required for estimating the mean vector and covariance matrix of asset returns, including the expected returns estimator, the covariance estimator, and the moment algorithm. This enables modular and extensible workflows for portfolio optimization and risk modeling.\n\nFields\n\nme: Expected returns estimator.\nce: Covariance estimator.\nalg: Moment algorithm.\n\nConstructor\n\nCovariance(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns(),\n            ce::StatsBase.CovarianceEstimator = GeneralWeightedCovariance(),\n            alg::AbstractMomentAlgorithm = Full())\n\nConstruct a Covariance estimator with the specified expected returns estimator, covariance estimator, and moment algorithm.\n\nRelated\n\nAbstractCovarianceEstimator\nGeneralWeightedCovariance\nSimpleExpectedReturns\nFull\nSemi\n\n\n\n\n\n","category":"type"},{"location":"007-03-Moments/#PortfolioOptimisers.Covariance-Tuple{}","page":"Covariance","title":"PortfolioOptimisers.Covariance","text":"Covariance(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns(),\n            ce::StatsBase.CovarianceEstimator = GeneralWeightedCovariance(),\n            alg::AbstractMomentAlgorithm = Full())\n\nConstruct a Covariance estimator for joint mean and covariance estimation.\n\nThis constructor creates a Covariance object using the specified expected returns estimator, covariance estimator, and moment algorithm. Defaults are provided for each component to enable robust and extensible estimation workflows.\n\nArguments\n\nme: Expected returns estimator.\nce: Covariance estimator.\nalg: Moment algorithm.\n\nReturns\n\nCovariance: A configured joint mean and covariance estimator.\n\nExamples\n\njulia> cov_est = Covariance()\nCovariance\n   me | SimpleExpectedReturns\n      |   w | nothing\n   ce | GeneralWeightedCovariance\n      |   ce | StatsBase.SimpleCovariance: StatsBase.SimpleCovariance(true)\n      |    w | nothing\n  alg | Full()\n\nRelated\n\nCovariance\nAbstractCovarianceEstimator\nGeneralWeightedCovariance\nSimpleExpectedReturns\nFull\nSemi\n\n\n\n\n\n","category":"method"},{"location":"007-03-Moments/#Statistics.cov-Tuple{Covariance{<:Any, <:Any, <:Full}, AbstractMatrix}","page":"Covariance","title":"Statistics.cov","text":"cov(ce::Covariance{<:Any, <:Any, <:Full}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\nCompute the full covariance matrix using a Covariance estimator.\n\nArguments\n\nce: Covariance estimator with Full moment algorithm.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the covariance.\nmean: Optional mean vector for centering. If not provided, computed using ce.me.\nkwargs...: Additional keyword arguments passed to the underlying covariance estimator.\n\nReturns\n\nCovariance matrix as computed by the estimator and moment algorithm.\n\nRelated\n\nCovariance\nAbstractCovarianceEstimator\nGeneralWeightedCovariance\nFull\nSemi\ncov(ce::Covariance{<:Any, <:Any, <:Semi}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\ncor(ce::Covariance{<:Any, <:Any, <:Full}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\ncor(ce::Covariance{<:Any, <:Any, <:Semi}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"007-03-Moments/#Statistics.cov-Tuple{Covariance{<:Any, <:Any, <:Semi}, AbstractMatrix}","page":"Covariance","title":"Statistics.cov","text":"cov(ce::Covariance{<:Any, <:Any, <:Semi}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\nCompute the semi covariance matrix using a Covariance estimator.\n\nArguments\n\nce: Covariance estimator with Semi moment algorithm.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the covariance.\nmean: Optional mean vector for centering. If not provided, computed using ce.me.\nkwargs...: Additional keyword arguments passed to the underlying covariance estimator.\n\nReturns\n\nCovariance matrix as computed by the estimator and moment algorithm.\n\nRelated\n\nCovariance\nAbstractCovarianceEstimator\nGeneralWeightedCovariance\nFull\nSemi\ncov(ce::Covariance{<:Any, <:Any, <:Full}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\ncor(ce::Covariance{<:Any, <:Any, <:Full}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\ncor(ce::Covariance{<:Any, <:Any, <:Semi}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"007-03-Moments/#Statistics.cor-Tuple{Covariance{<:Any, <:Any, <:Full}, AbstractMatrix}","page":"Covariance","title":"Statistics.cor","text":"cor(ce::Covariance{<:Any, <:Any, <:Full}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\nCompute the full correlation matrix using a Covariance estimator.\n\nArguments\n\nce: Covariance estimator with Full moment algorithm.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the correlation.\nmean: Optional mean vector for centering. If not provided, computed using ce.me.\nkwargs...: Additional keyword arguments passed to the underlying correlation estimator.\n\nReturns\n\nCorrelation matrix as computed by the estimator and moment algorithm.\n\nRelated\n\nCovariance\nAbstractCovarianceEstimator\nGeneralWeightedCovariance\nFull\nSemi\ncov(ce::Covariance{<:Any, <:Any, <:Full}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\ncov(ce::Covariance{<:Any, <:Any, <:Semi}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\ncor(ce::Covariance{<:Any, <:Any, <:Semi}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"007-03-Moments/#Statistics.cor-Tuple{Covariance{<:Any, <:Any, <:Semi}, AbstractMatrix}","page":"Covariance","title":"Statistics.cor","text":"cov(ce::Covariance{<:Any, <:Any, <:Semi}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\nCompute the semi correlation matrix using a Covariance estimator.\n\nArguments\n\nce: Covariance estimator with Semi moment algorithm.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the correlation.\nmean: Optional mean vector for centering. If not provided, computed using ce.me.\nkwargs...: Additional keyword arguments passed to the underlying correlation estimator.\n\nReturns\n\nCorrelation matrix as computed by the estimator and moment algorithm.\n\nRelated\n\nCovariance\nAbstractCovarianceEstimator\nGeneralWeightedCovariance\nFull\nSemi\ncov(ce::Covariance{<:Any, <:Any, <:Full}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\ncov(ce::Covariance{<:Any, <:Any, <:Semi}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\ncor(ce::Covariance{<:Any, <:Any, <:Full}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"007-16-Moments/#Coskewness","page":"Coskewness","title":"Coskewness","text":"","category":"section"},{"location":"007-16-Moments/#PortfolioOptimisers.CoskewnessEstimator","page":"Coskewness","title":"PortfolioOptimisers.CoskewnessEstimator","text":"abstract type CoskewnessEstimator <: AbstractEstimator end\n\nAbstract supertype for all coskewness estimators in PortfolioOptimisers.jl.\n\nAll concrete types implementing coskewness estimation algorithms should subtype CoskewnessEstimator. This enables a consistent interface for coskewness-based higher moment estimators throughout the package.\n\nRelated\n\nCoskewness\nAbstractEstimator\n\n\n\n\n\n","category":"type"},{"location":"007-16-Moments/#PortfolioOptimisers.Coskewness","page":"Coskewness","title":"PortfolioOptimisers.Coskewness","text":"struct Coskewness{T1, T2, T3} <: CoskewnessEstimator\n    me::T1\n    mp::T2\n    alg::T3\nend\n\nContainer type for coskewness estimators.\n\nCoskewness encapsulates the mean estimator, matrix processing estimator, and moment algorithm for coskewness estimation. This enables modular workflows for higher-moment portfolio analysis.\n\nFields\n\nme: Mean estimator for expected returns.\nmp: Matrix processing estimator for coskewness tensors.\nalg: Moment algorithm (e.g., Full, Semi).\n\nConstructor\n\nCoskewness(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns(),\n            mp::AbstractMatrixProcessingEstimator = NonPositiveDefiniteMatrixProcessing(),\n            alg::AbstractMomentAlgorithm = Full())\n\nConstruct a Coskewness estimator with the specified mean estimator, matrix processing estimator, and moment algorithm.\n\nRelated\n\nCoskewnessEstimator\nAbstractExpectedReturnsEstimator\nAbstractMatrixProcessingEstimator\nAbstractMomentAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"007-16-Moments/#PortfolioOptimisers.Coskewness-Tuple{}","page":"Coskewness","title":"PortfolioOptimisers.Coskewness","text":"Coskewness(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns(),\n            mp::AbstractMatrixProcessingEstimator = NonPositiveDefiniteMatrixProcessing(),\n            alg::AbstractMomentAlgorithm = Full())\n\nConstruct a Coskewness estimator for coskewness computation.\n\nArguments\n\nme: Mean estimator for expected returns.\nmp: Matrix processing estimator.\nalg: Moment algorithm.\n\nReturns\n\nCoskewness: Configured coskewness estimator.\n\nExamples\n\njulia> Coskewness()\nCoskewness\n   me | SimpleExpectedReturns\n      |   w | nothing\n   mp | NonPositiveDefiniteMatrixProcessing\n      |   denoise | nothing\n      |    detone | nothing\n      |       alg | nothing\n  alg | Full()\n\nRelated\n\nCoskewnessEstimator\nAbstractExpectedReturnsEstimator\nAbstractMatrixProcessingEstimator\nAbstractMomentAlgorithm\n\n\n\n\n\n","category":"method"},{"location":"007-16-Moments/#PortfolioOptimisers.__coskewness","page":"Coskewness","title":"PortfolioOptimisers.__coskewness","text":"__coskewness(cskew::AbstractMatrix, X::AbstractMatrix, mp::AbstractMatrixProcessingEstimator)\n\nInternal helper for coskewness matrix processing.\n\n__coskewness processes the coskewness tensor by applying the matrix processing estimator to each block, then projects the result using eigenvalue decomposition and clamps negative values. Used internally for robust coskewness estimation.\n\nArguments\n\ncskew: Coskewness tensor (flattened or block matrix).\nX: Data matrix (observations × assets).\nmp: Matrix processing estimator.\n\nReturns\n\nV::Matrix{<:Real}: Processed coskewness matrix.\n\nRelated\n\nCoskewness\n_coskewness\nmatrix_processing!\ncoskewness\n\n\n\n\n\n","category":"function"},{"location":"007-16-Moments/#PortfolioOptimisers._coskewness","page":"Coskewness","title":"PortfolioOptimisers._coskewness","text":"_coskewness(y::AbstractMatrix, X::AbstractMatrix, mp::AbstractMatrixProcessingEstimator)\n\nInternal helper for coskewness computation.\n\n_coskewness computes the coskewness tensor and applies matrix processing. Used internally by coskewness estimators.\n\nArguments\n\ny: Centered data vector (e.g., X .- mean).\nX: Data matrix (observations × assets).\nmp: Matrix processing estimator.\n\nReturns\n\ncskew::Matrix{<:Real}: Coskewness tensor.\nV::Matrix{<:Real}: Processed coskewness matrix.\n\nRelated\n\nCoskewness\n__coskewness\ncoskewness\n\n\n\n\n\n","category":"function"},{"location":"007-16-Moments/#PortfolioOptimisers.coskewness","page":"Coskewness","title":"PortfolioOptimisers.coskewness","text":"coskewness(ske::Union{Nothing, <:Coskewness}, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\nCompute the full coskewness tensor and processed matrix for a dataset. For Full, it uses all centered data; for Semi, it uses only negative deviations. If the estimator is nothing, returns (nothing, nothing).\n\nArguments\n\nske::Coskewness{<:Any, <:Any, <:Full}: Coskewness estimator with Full moment algorithm.\nske::Coskewness{<:Any, <:Any, <:Semi}: Coskewness estimator with Semi moment algorithm.\nske::Nothing: No-op coskewness computation, returns (nothing, nothing).\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the mean.\nmean: Optional mean vector. If not provided, computed using the estimator's mean estimator.\nkwargs...: Additional keyword arguments passed to the mean estimator.\n\nReturns\n\ncskew::Matrix{<:Real}: Coskewness tensor (observations × assets^2).\nV::Matrix{<:Real}: Processed coskewness matrix (assets × assets).\n\nExamples\n\njulia> using StableRNGs\n\njulia> rng = StableRNG(123456789);\n\njulia> X = randn(rng, 10, 3);\n\njulia> cskew, V = coskewness(Coskewness(), X);\n\njulia> cskew\n3×9 Matrix{Float64}:\n -0.456556   0.104588   0.391789  …   0.391789  -0.283963   0.025956\n -0.136453  -0.191539  -0.139315     -0.139315   0.210037  -0.0952308\n  0.176565  -0.219895   0.24526       0.24526    0.105632  -0.772302\n\njulia> V\n3×3 Matrix{Float64}:\n 0.74159    0.428314   0.0676831\n 0.428314   0.316494   0.0754933\n 0.0676831  0.0754933  0.833249\n\nRelated\n\nCoskewness\n_coskewness\n__coskewness\n\n\n\n\n\n","category":"function"},{"location":"006-MatrixProcessing/#Matrix-Processing","page":"Matrix Processing","title":"Matrix Processing","text":"","category":"section"},{"location":"006-MatrixProcessing/#PortfolioOptimisers.DefaultMatrixProcessing","page":"Matrix Processing","title":"PortfolioOptimisers.DefaultMatrixProcessing","text":"struct DefaultMatrixProcessing{T1, T2, T3, T4} <: AbstractMatrixProcessingEstimator\n    pdm::T1\n    denoise::T2\n    detone::T3\n    alg::T4\nend\n\nA flexible container type for configuring and applying matrix processing routines in PortfolioOptimisers.jl.\n\nDefaultMatrixProcessing encapsulates all steps required for processing covariance or correlation matrices, including positive definiteness enforcement, denoising, detoning, and optional custom matrix processing algorithms. It is the standard estimator type for matrix processing pipelines and supports a variety of estimator and algorithm types.\n\nFields\n\npdm: Positive definite matrix estimator (see Posdef), or nothing to skip.\ndenoise: Denoising estimator (see Denoise), or nothing to skip.\ndetone: Detoning estimator (see Detone), or nothing to skip.\nalg: Optional custom matrix processing algorithm, or nothing to skip.\n\nConstructor\n\nDefaultMatrixProcessing(; pdm = Posdef(), denoise = nothing, detone = nothing, alg = nothing)\n\nKeyword arguments correspond to the fields above. The constructor infers types and sets defaults for robust matrix processing.\n\nRelated\n\nAbstractMatrixProcessingEstimator\nmatrix_processing!\nmatrix_processing\nNonPositiveDefiniteMatrixProcessing\n\n\n\n\n\n","category":"type"},{"location":"006-MatrixProcessing/#PortfolioOptimisers.DefaultMatrixProcessing-Tuple{}","page":"Matrix Processing","title":"PortfolioOptimisers.DefaultMatrixProcessing","text":"DefaultMatrixProcessing(; pdm::Union{Nothing, <:Posdef} = Posdef(),\n                          denoise::Union{Nothing, <:Denoise} = nothing,\n                          detone::Union{Nothing, <:Detone} = nothing,\n                          alg::Union{Nothing, <:AbstractMatrixProcessingAlgorithm} = nothing)\n\nConstruct a DefaultMatrixProcessing object, configuring all steps for matrix processing in PortfolioOptimisers.jl.\n\nArguments\n\npdm: Positive definite matrix estimator.\ndenoise: Denoising estimator.\ndetone: Detoning estimator.\nalg: Optional custom matrix processing algorithm.\n\nReturns\n\nDefaultMatrixProcessing: A configured matrix processing estimator.\n\nExamples\n\njulia> mp = DefaultMatrixProcessing()\nDefaultMatrixProcessing\n      pdm | Posdef\n          |   alg | UnionAll: NearestCorrelationMatrix.Newton\n  denoise | nothing\n   detone | nothing\n      alg | nothing\n\njulia> mp = DefaultMatrixProcessing(; denoise = Denoise(), detone = Detone(; n = 2))\nDefaultMatrixProcessing\n      pdm | Posdef\n          |   alg | UnionAll: NearestCorrelationMatrix.Newton\n  denoise | Denoise\n          |      alg | ShrunkDenoise\n          |          |   alpha | Float64: 0.0\n          |     args | Tuple{}: ()\n          |   kwargs | @NamedTuple{}: NamedTuple()\n          |   kernel | typeof(AverageShiftedHistograms.Kernels.gaussian): AverageShiftedHistograms.Kernels.gaussian\n          |        m | Int64: 10\n          |        n | Int64: 1000\n   detone | Detone\n          |   n | Int64: 2\n      alg | nothing\n\nRelated\n\nDefaultMatrixProcessing\nmatrix_processing!\nmatrix_processing\n\n\n\n\n\n","category":"method"},{"location":"006-MatrixProcessing/#PortfolioOptimisers.NonPositiveDefiniteMatrixProcessing","page":"Matrix Processing","title":"PortfolioOptimisers.NonPositiveDefiniteMatrixProcessing","text":"struct NonPositiveDefiniteMatrixProcessing{T1, T2, T3} <: AbstractMatrixProcessingEstimator\n    denoise::T1\n    detone::T2\n    alg::T3\nend\n\nA container type for matrix processing pipelines that do not enforce positive definiteness in PortfolioOptimisers.jl.\n\nNonPositiveDefiniteMatrixProcessing is intended for workflows where positive definiteness is not required or is handled externally. It supports denoising, detoning, and optional custom matrix processing algorithms, but skips positive definite projection.\n\nFields\n\ndenoise: Denoising estimator (see Denoise), or nothing to skip.\ndetone: Detoning estimator (see Detone), or nothing to skip.\nalg: Optional custom matrix processing algorithm, or nothing to skip.\n\nConstructor\n\nNonPositiveDefiniteMatrixProcessing(; denoise = nothing, detone = nothing, alg = nothing)\n\nKeyword arguments correspond to the fields above. The constructor infers types and sets defaults for robust matrix processing without positive definite enforcement.\n\nRelated\n\nAbstractMatrixProcessingEstimator\nmatrix_processing!\nmatrix_processing\nDefaultMatrixProcessing\n\n\n\n\n\n","category":"type"},{"location":"006-MatrixProcessing/#PortfolioOptimisers.NonPositiveDefiniteMatrixProcessing-Tuple{}","page":"Matrix Processing","title":"PortfolioOptimisers.NonPositiveDefiniteMatrixProcessing","text":"NonPositiveDefiniteMatrixProcessing(; denoise::Union{Nothing, <:Denoise} = nothing,\n                                      detone::Union{Nothing, <:Detone} = nothing,\n                                      alg::Union{Nothing,\n                                                <:AbstractMatrixProcessingAlgorithm} = nothing)\n\nConstruct a NonPositiveDefiniteMatrixProcessing object, configuring matrix processing steps without positive definite enforcement.\n\nArguments\n\ndenoise: Denoising estimator.\ndetone: Detoning estimator.\nalg: Optional custom matrix processing algorithm.\n\nReturns\n\nNonPositiveDefiniteMatrixProcessing: A configured matrix processing estimator.\n\nExamples\n\njulia> mp = NonPositiveDefiniteMatrixProcessing()\nNonPositiveDefiniteMatrixProcessing\n  denoise | nothing\n   detone | nothing\n      alg | nothing\n\njulia> mp = NonPositiveDefiniteMatrixProcessing(; denoise = Denoise(), detone = Detone(; n = 2))\nNonPositiveDefiniteMatrixProcessing\n  denoise | Denoise\n          |      alg | ShrunkDenoise\n          |          |   alpha | Float64: 0.0\n          |     args | Tuple{}: ()\n          |   kwargs | @NamedTuple{}: NamedTuple()\n          |   kernel | typeof(AverageShiftedHistograms.Kernels.gaussian): AverageShiftedHistograms.Kernels.gaussian\n          |        m | Int64: 10\n          |        n | Int64: 1000\n   detone | Detone\n          |   n | Int64: 2\n      alg | nothing\n\nRelated\n\nNonPositiveDefiniteMatrixProcessing\nmatrix_processing!\nmatrix_processing\n\n\n\n\n\n","category":"method"},{"location":"006-MatrixProcessing/#PortfolioOptimisers.matrix_processing!","page":"Matrix Processing","title":"PortfolioOptimisers.matrix_processing!","text":"matrix_processing!(mp::DefaultMatrixProcessing, sigma::AbstractMatrix, X::AbstractMatrix, args...; kwargs...)\nmatrix_processing!(mp::NonPosdefMatrixProcessing, sigma::AbstractMatrix, X::AbstractMatrix, args...; kwargs...)\nmatrix_processing!(::Nothing, args...; kwargs...)\n\nIn-place processing of a covariance or correlation matrix.\n\nIf mp is nothing, this is a no-op and returns nothing.\nIf mp is a DefaultMatrixProcessing object, the specified matrix processing steps are applied to sigma in-place, using the provided data matrix X.\nIf mp is a NonPositiveDefiniteMatrixProcessing object, the specified matrix processing steps without enforcing positive definiteness are applied to sigma in-place, using the provided data matrix X.\n\nThe processing pipeline consists of:\n\nPositive definiteness enforcement via posdef! (if mp.pdm is DefaultMatrixProcessing).\nDenoising via denoise! (if mp.denoise is not nothing).\nDetoning via detone! (if mp.detone is not nothing).\nOptional custom matrix processing algorithm via matrix_processing_algorithm! (if mp.alg is not nothing).\n\nArguments\n\nmp: Matrix processing estimator specifying the pipeline.\nsigma: Covariance or correlation matrix to be processed (modified in-place).\nX: Data matrix (observations × assets) used for denoising and detoning.\nargs...: Additional positional arguments passed to custom algorithms.\nkwargs...: Additional keyword arguments passed to custom algorithms.\n\nReturns\n\nnothing. The input matrix sigma is modified in-place.\n\nExamples\n\njulia> using StableRNGs, Statistics\n\njulia> rng = StableRNG(123456789);\n\njulia> X = rand(rng, 10, 5);\n\njulia> sigma = cov(X)\n5×5 Matrix{Float64}:\n  0.132026     0.0022567   0.0198243    0.00359832  -0.00743829\n  0.0022567    0.0514194  -0.0131242    0.004123     0.0312379\n  0.0198243   -0.0131242   0.0843837   -0.0325342   -0.00609624\n  0.00359832   0.004123   -0.0325342    0.0424332    0.0152574\n -0.00743829   0.0312379  -0.00609624   0.0152574    0.0926441\n\njulia> matrix_processing!(DefaultMatrixProcessing(; denoise = Denoise()), sigma, X)\n\njulia> sigma\n5×5 Matrix{Float64}:\n 0.132026  0.0        0.0        0.0        0.0\n 0.0       0.0514194  0.0        0.0        0.0\n 0.0       0.0        0.0843837  0.0        0.0\n 0.0       0.0        0.0        0.0424332  0.0\n 0.0       0.0        0.0        0.0        0.0926441\n\njulia> sigma = cov(X)\n5×5 Matrix{Float64}:\n  0.132026     0.0022567   0.0198243    0.00359832  -0.00743829\n  0.0022567    0.0514194  -0.0131242    0.004123     0.0312379\n  0.0198243   -0.0131242   0.0843837   -0.0325342   -0.00609624\n  0.00359832   0.004123   -0.0325342    0.0424332    0.0152574\n -0.00743829   0.0312379  -0.00609624   0.0152574    0.0926441\n\njulia> matrix_processing!(DefaultMatrixProcessing(; detone = Detone()), sigma, X)\n\njulia> sigma\n5×5 Matrix{Float64}:\n 0.132026    0.0124802   0.0117303    0.0176194    0.0042142\n 0.0124802   0.0514194   0.0273105   -0.0290864    0.0088165\n 0.0117303   0.0273105   0.0843837   -0.00279296   0.0619156\n 0.0176194  -0.0290864  -0.00279296   0.0424332   -0.0242252\n 0.0042142   0.0088165   0.0619156   -0.0242252    0.0926441\n\nRelated\n\nmatrix_processing\nDefaultMatrixProcessing\nposdef!\ndenoise!\ndetone!\nmatrix_processing_algorithm!\n\n\n\n\n\n","category":"function"},{"location":"006-MatrixProcessing/#PortfolioOptimisers.matrix_processing","page":"Matrix Processing","title":"PortfolioOptimisers.matrix_processing","text":"matrix_processing(mp::DefaultMatrixProcessing, sigma::AbstractMatrix, X::AbstractMatrix, args...; kwargs...)\nmatrix_processing(mp::NonPosdefMatrixProcessing, sigma::AbstractMatrix, X::AbstractMatrix, args...; kwargs...)\nmatrix_processing(::Nothing, args...; kwargs...)\n\nSame as matrix_processing!, but returns a new matrix instead of modifying sigma in-place.\n\nIf mp is nothing, this is a no-op and returns nothing.\n\nExamples\n\njulia> using StableRNGs, Statistics\n\njulia> rng = StableRNG(123456789);\n\njulia> X = rand(rng, 10, 5);\n\njulia> sigma = cov(X)\n5×5 Matrix{Float64}:\n  0.132026     0.0022567   0.0198243    0.00359832  -0.00743829\n  0.0022567    0.0514194  -0.0131242    0.004123     0.0312379\n  0.0198243   -0.0131242   0.0843837   -0.0325342   -0.00609624\n  0.00359832   0.004123   -0.0325342    0.0424332    0.0152574\n -0.00743829   0.0312379  -0.00609624   0.0152574    0.0926441\n\njulia> sigma_ds = matrix_processing(DefaultMatrixProcessing(; denoise = Denoise()), sigma, X)\n5×5 Matrix{Float64}:\n 0.132026  0.0        0.0        0.0        0.0\n 0.0       0.0514194  0.0        0.0        0.0\n 0.0       0.0        0.0843837  0.0        0.0\n 0.0       0.0        0.0        0.0424332  0.0\n 0.0       0.0        0.0        0.0        0.0926441\n\njulia> sigma = cov(X)\n5×5 Matrix{Float64}:\n  0.132026     0.0022567   0.0198243    0.00359832  -0.00743829\n  0.0022567    0.0514194  -0.0131242    0.004123     0.0312379\n  0.0198243   -0.0131242   0.0843837   -0.0325342   -0.00609624\n  0.00359832   0.004123   -0.0325342    0.0424332    0.0152574\n -0.00743829   0.0312379  -0.00609624   0.0152574    0.0926441\n\njulia> sigma_dt = matrix_processing(DefaultMatrixProcessing(; detone = Detone()), sigma, X)\n5×5 Matrix{Float64}:\n 0.132026    0.0124802   0.0117303    0.0176194    0.0042142\n 0.0124802   0.0514194   0.0273105   -0.0290864    0.0088165\n 0.0117303   0.0273105   0.0843837   -0.00279296   0.0619156\n 0.0176194  -0.0290864  -0.00279296   0.0424332   -0.0242252\n 0.0042142   0.0088165   0.0619156   -0.0242252    0.0926441\n\nRelated\n\nmatrix_processing!\nDefaultMatrixProcessing\nposdef!\ndenoise!\ndetone!\nmatrix_processing_algorithm!\n\n\n\n\n\n","category":"function"},{"location":"006-MatrixProcessing/#PortfolioOptimisers.AbstractMatrixProcessingEstimator","page":"Matrix Processing","title":"PortfolioOptimisers.AbstractMatrixProcessingEstimator","text":"AbstractMatrixProcessingEstimator <: AbstractEstimator\n\nAbstract supertype for all matrix processing estimator types in PortfolioOptimisers.jl.\n\nAll concrete types that implement matrix processing routines—such as covariance matrix cleaning, denoising, or detoning—should subtype AbstractMatrixProcessingEstimator. This enables a consistent interface for matrix processing estimators throughout the package.\n\nRelated\n\nAbstractEstimator\nDefaultMatrixProcessing\nNonPositiveDefiniteMatrixProcessing\n\n\n\n\n\n","category":"type"},{"location":"006-MatrixProcessing/#PortfolioOptimisers.AbstractMatrixProcessingAlgorithm","page":"Matrix Processing","title":"PortfolioOptimisers.AbstractMatrixProcessingAlgorithm","text":"AbstractMatrixProcessingAlgorithm <: AbstractAlgorithm\n\nAbstract supertype for all matrix processing algorithm types in PortfolioOptimisers.jl.\n\nAll concrete types that implement a specific matrix processing algorithm (e.g., custom cleaning or transformation routines) should subtype AbstractMatrixProcessingAlgorithm. This enables flexible extension and dispatch of matrix processing routines.\n\nRelated\n\nAbstractAlgorithm\nDefaultMatrixProcessing\nNonPositiveDefiniteMatrixProcessing\n\n\n\n\n\n","category":"type"},{"location":"006-MatrixProcessing/#PortfolioOptimisers.matrix_processing_algorithm!","page":"Matrix Processing","title":"PortfolioOptimisers.matrix_processing_algorithm!","text":"matrix_processing_algorithm!(::Nothing, args...; kwargs...)\n\nNo-op fallback for matrix processing algorithm routines.\n\nThese methods are called internally when no matrix processing algorithm is specified (i.e., when the algorithm argument is nothing). They perform no operation and return nothing, ensuring that the matrix processing pipeline can safely skip optional algorithmic steps.\n\nArguments\n\n::Nothing: Indicates that no algorithm is provided.\nargs...: Additional positional arguments (ignored).\nkwargs...: Additional keyword arguments (ignored).\n\nReturns\n\nnothing.\n\nRelated\n\nmatrix_processing_algorithm\nDefaultMatrixProcessing\nNonPositiveDefiniteMatrixProcessing\n\n\n\n\n\n","category":"function"},{"location":"006-MatrixProcessing/#PortfolioOptimisers.matrix_processing_algorithm","page":"Matrix Processing","title":"PortfolioOptimisers.matrix_processing_algorithm","text":"matrix_processing_algorithm(::Nothing, args...; kwargs...)\n\nSame as matrix_processing_algorithm!, but meant for returning a new matrix instead of modifying it in-place.\n\nRelated\n\nmatrix_processing_algorithm!\nDefaultMatrixProcessing\nNonPositiveDefiniteMatrixProcessing\n\n\n\n\n\n","category":"function"},{"location":"008-1-Distance/#Base-Distance","page":"Base Distance","title":"Base Distance","text":"","category":"section"},{"location":"008-1-Distance/#PortfolioOptimisers.AbstractDistanceEstimator","page":"Base Distance","title":"PortfolioOptimisers.AbstractDistanceEstimator","text":"abstract type AbstractDistanceEstimator <: AbstractEstimator end\n\nAbstract supertype for all distance estimator types in PortfolioOptimisers.jl.\n\nAll concrete types implementing distance-based estimation algorithms should subtype AbstractDistanceEstimator. This enables a consistent interface for distance-based measures (such as correlation distance, absolute distance, or information-theoretic distances) throughout the package.\n\nRelated\n\nAbstractEstimator\nAbstractDistanceAlgorithm\ndistance\ncor_and_dist\n\n\n\n\n\n","category":"type"},{"location":"008-1-Distance/#PortfolioOptimisers.AbstractDistanceAlgorithm","page":"Base Distance","title":"PortfolioOptimisers.AbstractDistanceAlgorithm","text":"abstract type AbstractDistanceAlgorithm <: AbstractAlgorithm end\n\nAbstract supertype for all distance algorithm types in PortfolioOptimisers.jl.\n\nAll concrete types implementing specific distance-based algorithms (such as correlation distance, absolute distance, log distance, or information-theoretic distances) should subtype AbstractDistanceAlgorithm. This enables flexible extension and dispatch of distance routines for use in portfolio optimization and risk analysis.\n\nRelated\n\nAbstractDistanceEstimator\nSimpleDistance\nSimpleAbsoluteDistance\nLogDistance\nCorrelationDistance\nCanonicalDistance\nVariationInfoDistance\ndistance\ncor_and_dist\n\n\n\n\n\n","category":"type"},{"location":"008-1-Distance/#PortfolioOptimisers.SimpleDistance","page":"Base Distance","title":"PortfolioOptimisers.SimpleDistance","text":"struct SimpleDistance <: AbstractDistanceAlgorithm end\n\nSimple distance algorithm for portfolio optimization.\n\nSimpleDistance specifies the use of a basic distance metric (typically Euclidean or squared Euclidean distance) for distance-based estimation in PortfolioOptimisers.jl. It is used as an algorithm type for distance estimators, enabling straightforward computation of pairwise distances between assets or features.\n\nRelated\n\nAbstractDistanceAlgorithm\nAbstractDistanceEstimator\ndistance\ncor_and_dist\n\n\n\n\n\n","category":"type"},{"location":"008-1-Distance/#PortfolioOptimisers.SimpleAbsoluteDistance","page":"Base Distance","title":"PortfolioOptimisers.SimpleAbsoluteDistance","text":"struct SimpleAbsoluteDistance <: AbstractDistanceAlgorithm end\n\nSimple absolute distance algorithm for portfolio optimization.\n\nSimpleAbsoluteDistance specifies the use of the absolute distance metric (L1 norm) for distance-based estimation in PortfolioOptimisers.jl. It is used as an algorithm type for distance estimators, enabling computation of pairwise absolute differences between assets or features.\n\nRelated\n\nAbstractDistanceAlgorithm\nAbstractDistanceEstimator\ndistance\ncor_and_dist\n\n\n\n\n\n","category":"type"},{"location":"008-1-Distance/#PortfolioOptimisers.LogDistance","page":"Base Distance","title":"PortfolioOptimisers.LogDistance","text":"struct LogDistance <: AbstractDistanceAlgorithm end\n\nLog distance algorithm for portfolio optimization.\n\nLogDistance specifies the use of a logarithmic distance metric for distance-based estimation in PortfolioOptimisers.jl. This algorithm is useful for measuring relative differences or ratios between asset returns or features, and can be more robust to scale differences than standard Euclidean or absolute distances.\n\nRelated\n\nAbstractDistanceAlgorithm\nAbstractDistanceEstimator\ndistance\ncor_and_dist\n\n\n\n\n\n","category":"type"},{"location":"008-1-Distance/#PortfolioOptimisers.CorrelationDistance","page":"Base Distance","title":"PortfolioOptimisers.CorrelationDistance","text":"struct CorrelationDistance <: AbstractDistanceAlgorithm end\n\nCorrelation distance algorithm for portfolio optimization.\n\nCorrelationDistance specifies the use of a correlation-based distance metric for distance-based estimation in PortfolioOptimisers.jl. This algorithm measures the dissimilarity between assets or features based on their correlation, typically using the formula distance = 1 - correlation. It is useful for clustering, risk analysis, and constructing distance matrices that reflect the co-movement structure of asset returns.\n\nRelated\n\nAbstractDistanceAlgorithm\nAbstractDistanceEstimator\ndistance\ncor_and_dist\n\n\n\n\n\n","category":"type"},{"location":"008-1-Distance/#PortfolioOptimisers.CanonicalDistance","page":"Base Distance","title":"PortfolioOptimisers.CanonicalDistance","text":"struct CanonicalDistance <: AbstractDistanceAlgorithm end\n\nCanonical distance algorithm for portfolio optimization.\n\nCanonicalDistance specifies the use of a canonical (or Mahalanobis-like) distance metric for distance-based estimation in PortfolioOptimisers.jl. This algorithm measures the dissimilarity between assets or features by accounting for the covariance structure of the data, making it sensitive to correlations and scale differences. It is useful for clustering, risk analysis, and constructing distance matrices that reflect both variance and correlation among asset returns.\n\nRelated\n\nAbstractDistanceAlgorithm\nAbstractDistanceEstimator\ndistance\ncor_and_dist\n\n\n\n\n\n","category":"type"},{"location":"008-1-Distance/#PortfolioOptimisers.VariationInfoDistance","page":"Base Distance","title":"PortfolioOptimisers.VariationInfoDistance","text":"struct VariationInfoDistance{T1, T2} <: AbstractDistanceAlgorithm\n    bins::T1\n    normalise::T2\nend\n\nVariation of Information (VI) distance algorithm for portfolio optimization.\n\nVariationInfoDistance specifies the use of the Variation of Information (VI) metric, an information-theoretic distance based on entropy and mutual information, for distance-based estimation in PortfolioOptimisers.jl. This algorithm is useful for quantifying the dissimilarity between distributions of asset returns or features, and can be applied to both continuous and discrete data via binning.\n\nFields\n\nbins: Binning strategy or number of bins. If an integer, must be strictly positive.\nnormalise: Whether to normalise the VI distance to the range [0, 1].\n\nRelated\n\nAbstractDistanceAlgorithm\ndistance\ncor_and_dist\n\n\n\n\n\n","category":"type"},{"location":"008-1-Distance/#PortfolioOptimisers.VariationInfoDistance-Tuple{}","page":"Base Distance","title":"PortfolioOptimisers.VariationInfoDistance","text":"VariationInfoDistance(; bins::Union{<:AbstractBins, <:Integer} = HacineGharbiRavier(),\n                       normalise::Bool = true)\n\nConstruct a VariationInfoDistance algorithm for information-theoretic distance estimation.\n\nThis constructor creates a VariationInfoDistance object with the specified binning strategy and normalisation option. The VI distance quantifies the dissimilarity between distributions using entropy and mutual information, and can be applied to both continuous and discrete data via binning.\n\nArguments\n\nbins: Binning strategy or number of bins. If an integer, must be strictly positive.\nnormalise: Whether to normalise the VI distance to the range [0, 1].\n\nReturns\n\nVariationInfoDistance: A configured VI distance algorithm.\n\nValidation\n\nIf bins is an integer, it must be strictly positive.\n\nExamples\n\njulia> VariationInfoDistance()\nVariationInfoDistance\n       bins | HacineGharbiRavier()\n  normalise | Bool: true\n\nRelated\n\nVariationInfoDistance\nAbstractDistanceAlgorithm\ndistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"007-08-Moments/#Lower-Tail-Dependence-Covariance","page":"Lower Tail Dependence Covariance","title":"Lower Tail Dependence Covariance","text":"","category":"section"},{"location":"007-08-Moments/#PortfolioOptimisers.LTDCovariance","page":"Lower Tail Dependence Covariance","title":"PortfolioOptimisers.LTDCovariance","text":"struct LTDCovariance{T1, T2, T3} <: AbstractCovarianceEstimator\n    ve::T1\n    alpha::T2\n    threads::T3\nend\n\nLower tail dependence covariance estimator.\n\nLTDCovariance implements a robust covariance estimator based on lower tail dependence, which measures the co-movement of asset returns in the lower quantiles (i.e., during joint drawdowns or adverse events). This estimator is particularly useful for capturing dependence structures relevant to risk management and stress scenarios.\n\nFields\n\nve: Variance estimator used to compute marginal standard deviations.\nalpha: Quantile level for the 5% lower tail.\nthreads: Parallel execution strategy.\n\nConstructor\n\nLTDCovariance(; ve::AbstractVarianceEstimator = SimpleVariance(),\n               alpha::Real = 0.05, threads::FLoops.Transducers.Executor = ThreadedEx())\n\nCreates a LTDCovariance object with the specified variance estimator, quantile level, and parallel execution strategy.\n\nRelated\n\nAbstractVarianceEstimator\nSimpleVariance\nAbstractCovarianceEstimator\nFLoops.Transducers.Executor\n\n\n\n\n\n","category":"type"},{"location":"007-08-Moments/#PortfolioOptimisers.LTDCovariance-Tuple{}","page":"Lower Tail Dependence Covariance","title":"PortfolioOptimisers.LTDCovariance","text":"LTDCovariance(; ve::AbstractVarianceEstimator = SimpleVariance(),\n               alpha::Real = 0.05,\n               threads::FLoops.Transducers.Executor = ThreadedEx())\n\nConstruct a LTDCovariance estimator for robust lower tail dependence covariance or correlation estimation.\n\nThis constructor creates a LTDCovariance object using the specified variance estimator, quantile level, and parallel execution strategy. The estimator computes the covariance matrix by focusing on the joint lower tail events of asset returns, which is particularly relevant for risk-sensitive portfolio construction.\n\nArguments\n\nve: Variance estimator.\nalpha: Quantile level for the lower tail.\nthreads: Parallel execution strategy.\n\nReturns\n\nLTDCovariance: A configured lower tail dependence covariance estimator.\n\nValidation\n\nAsserts that alpha is strictly in (0, 1).\n\nExamples\n\njulia> ce = LTDCovariance()\nLTDCovariance\n       ve | SimpleVariance\n          |          me | SimpleExpectedReturns\n          |             |   w | nothing\n          |           w | nothing\n          |   corrected | Bool: true\n    alpha | Float64: 0.05\n  threads | Transducers.ThreadedEx{@NamedTuple{}}: Transducers.ThreadedEx()\n\nRelated\n\nAbstractVarianceEstimator\nSimpleVariance\nFLoops.Transducers.Executor\n\n\n\n\n\n","category":"method"},{"location":"007-08-Moments/#PortfolioOptimisers.lower_tail_dependence","page":"Lower Tail Dependence Covariance","title":"PortfolioOptimisers.lower_tail_dependence","text":"lower_tail_dependence(X::AbstractMatrix, alpha::Real = 0.05,\n                      threads::FLoops.Transducers.Executor = SequentialEx())\n\nCompute the lower tail dependence matrix for a set of asset returns.\n\nThe lower tail dependence (LTD) between two assets quantifies the probability that both assets experience returns in their respective lower tails (i.e., joint drawdowns or adverse events), given a specified quantile level alpha. This function estimates the LTD matrix for all pairs of assets in the input matrix X, which is particularly useful for risk management and stress testing.\n\nArguments\n\nX: Data matrix of asset returns (observations × assets).\nalpha: Quantile level for the lower tail.\nthreads: Parallel execution strategy.\n\nReturns\n\nrho::Matrix{<:Real}: Symmetric matrix of lower tail dependence coefficients, where rho[i, j] is the estimated LTD between assets i and j.\n\nDetails\n\nFor each pair of assets (i, j), the LTD is estimated as the proportion of observations where both asset i and asset j have returns less than or equal to their respective empirical alpha-quantiles, divided by the number of observations in the lower tail (ceil(Int, T * alpha), where T is the number of observations).\n\nThe resulting matrix is symmetric and all values are clamped to [0, 1].\n\nRelated\n\nLTDCovariance\nFLoops.Transducers.Executor\n\n\n\n\n\n","category":"function"},{"location":"007-08-Moments/#Statistics.cor-Tuple{LTDCovariance, AbstractMatrix}","page":"Lower Tail Dependence Covariance","title":"Statistics.cor","text":"cor(ce::LTDCovariance, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the lower tail dependence correlation matrix using a LTDCovariance estimator.\n\nThis method computes the lower tail dependence (LTD) correlation matrix for the input data matrix X using the quantile level and parallel execution strategy specified in ce. The LTD correlation quantifies the probability that pairs of assets experience joint drawdowns or adverse events, as measured by their co-movement in the lower tail.\n\nArguments\n\nce: Lower tail dependence covariance estimator.\nX: Data matrix of asset returns (observations × assets).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments.\n\nReturns\n\nrho::Matrix{<:Real}: Symmetric matrix of lower tail dependence correlation coefficients.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nRelated\n\nLTDCovariance\nlower_tail_dependence\n\n\n\n\n\n","category":"method"},{"location":"007-08-Moments/#Statistics.cov-Tuple{LTDCovariance, AbstractMatrix}","page":"Lower Tail Dependence Covariance","title":"Statistics.cov","text":"cov(ce::LTDCovariance, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the lower tail dependence covariance matrix using a LTDCovariance estimator.\n\nThis method computes the lower tail dependence (LTD) covariance matrix for the input data matrix X using the quantile level and parallel execution strategy specified in ce. The LTD covariance focuses on the co-movement of asset returns in the lower tail, making it robust to extreme events and particularly relevant for risk-sensitive applications.\n\nArguments\n\nce: Lower tail dependence covariance estimator.\nX: Data matrix of asset returns (observations × assets).\ndims: Dimension along which to compute the covariance.\nkwargs...: Additional keyword arguments passed to the variance estimator.\n\nReturns\n\nsigma::Matrix{<:Real}: Symmetric matrix of lower tail dependence covariances.\n\nValidation\n\nAsserts that dims is either 1 or 2.\n\nRelated\n\nLTDCovariance\nlower_tail_dependence\n\n\n\n\n\n","category":"method"},{"location":"007-15-Moments/#Excess-expected-returns","page":"Excess expected returns","title":"Excess expected returns","text":"","category":"section"},{"location":"007-15-Moments/#PortfolioOptimisers.ExcessExpectedReturns","page":"Excess expected returns","title":"PortfolioOptimisers.ExcessExpectedReturns","text":"struct ExcessExpectedReturns{T1, T2} <: AbstractShrunkExpectedReturnsEstimator\n    me::T1\n    rf::T2\nend\n\nContainer type for excess expected returns estimators.\n\nExcessExpectedReturns encapsulates a mean estimator and a risk-free rate for computing excess expected returns. This enables modular workflows for estimating expected returns above a specified risk-free rate.\n\nFields\n\nme: Mean estimator for expected returns.\nrf: Risk-free rate to subtract from expected returns.\n\nConstructor\n\nExcessExpectedReturns(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns(),\n                      rf::Real = 0.0)\n\nConstruct an ExcessExpectedReturns estimator with the specified mean estimator and risk-free rate.\n\nRelated\n\nAbstractShrunkExpectedReturnsEstimator\nAbstractExpectedReturnsEstimator\n\n\n\n\n\n","category":"type"},{"location":"007-15-Moments/#PortfolioOptimisers.ExcessExpectedReturns-Tuple{}","page":"Excess expected returns","title":"PortfolioOptimisers.ExcessExpectedReturns","text":"ExcessExpectedReturns(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns(),\n                      rf::Real = 0.0)\n\nConstruct an ExcessExpectedReturns estimator for excess expected returns.\n\nArguments\n\nme: Mean estimator for expected returns.\nrf: Risk-free rate to subtract.\n\nReturns\n\nExcessExpectedReturns: Configured excess expected returns estimator.\n\nExamples\n\njulia> ExcessExpectedReturns()\nExcessExpectedReturns\n  me | SimpleExpectedReturns\n     |   w | nothing\n  rf | Float64: 0.0\n\nRelated\n\nExcessExpectedReturns\nAbstractExpectedReturnsEstimator\n\n\n\n\n\n","category":"method"},{"location":"007-15-Moments/#Statistics.mean-Tuple{ExcessExpectedReturns, AbstractMatrix}","page":"Excess expected returns","title":"Statistics.mean","text":"mean(me::ExcessExpectedReturns, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute excess expected returns by subtracting the risk-free rate.\n\nThis method applies the mean estimator to the data and subtracts the risk-free rate from the resulting expected returns.\n\nArguments\n\nme: Excess expected returns estimator.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the mean.\nkwargs...: Additional keyword arguments passed to the mean estimator.\n\nReturns\n\nmu::AbstractArray: Excess expected returns vector.\n\nRelated\n\nExcessExpectedReturns\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#General-Distance","page":"General Distance","title":"General Distance","text":"","category":"section"},{"location":"008-4-Distance/#PortfolioOptimisers.GeneralDistance","page":"General Distance","title":"PortfolioOptimisers.GeneralDistance","text":"struct GeneralDistance{T1, T2} <: AbstractDistanceEstimator\n    power::T1\n    alg::T2\nend\n\nA flexible distance estimator that generalizes distance transformations for portfolio optimization.\n\nGeneralDistance allows you to raise the base correlation or distance matrix to an arbitrary integer power before applying a distance transformation. This enables the construction of custom distance metrics, such as higher-order or nonlinear distances, by combining a power transformation with any supported base distance algorithm (e.g., SimpleDistance, SimpleAbsoluteDistance, LogDistance, etc.).\n\nFields\n\npower: The integer power to which the base correlation or distance matrix is raised.\nalg: The base distance algorithm to use (e.g., SimpleDistance()).\n\nConstructor\n\nGeneralDistance(; power::Integer = 1, alg::AbstractDistanceAlgorithm = SimpleDistance())\n\nRelated\n\ndistance\ncor_and_dist\nSimpleDistance\nSimpleAbsoluteDistance\nLogDistance\nCorrelationDistance\nCanonicalDistance\nVariationInfoDistance\n\n\n\n\n\n","category":"type"},{"location":"008-4-Distance/#PortfolioOptimisers.GeneralDistance-Tuple{}","page":"General Distance","title":"PortfolioOptimisers.GeneralDistance","text":"GeneralDistance(; power::Integer = 1,\n                 alg::AbstractDistanceAlgorithm = SimpleDistance())\n\nConstruct a GeneralDistance estimator with the specified power and base distance algorithm.\n\nThis constructor creates a GeneralDistance object that will raise the base correlation or distance matrix to the given integer power before applying the specified distance transformation.\n\nArguments\n\npower: The integer power to which the base correlation or distance matrix is raised.\nalg: The base distance algorithm to use.\n\nReturns\n\nGeneralDistance: A configured general distance estimator.\n\nValidation\n\nAsserts that power is at least 1.\n\nExamples\n\njulia> GeneralDistance()\nGeneralDistance\n  power | Int64: 1\n    alg | SimpleDistance()\n\nRelated\n\nGeneralDistance\ndistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistance{<:Any, <:SimpleDistance}, CovarianceEstimator, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistance{<:Any, <:SimpleDistance},\n         ce::StatsBase.CovarianceEstimator,\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute a powered simple distance matrix from data using a covariance estimator.\n\nThis method computes the correlation matrix from the data matrix X using the provided covariance estimator ce, raises it to the power specified in de.power, and then applies the simple distance transformation. The result is a matrix of pairwise distances suitable for clustering or portfolio construction.\n\nArguments\n\nde: General distance estimator with a power and SimpleDistance algorithm.\nce: Covariance estimator to use for correlation computation.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation estimator.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise distances.\n\nDetails\n\nThe correlation matrix is raised to the specified integer power.\nThe distance is computed as sqrt(clamp!((1 - rho) * scale, 0, 1)), where scale is 0.5 if the power is odd, otherwise 1.0.\n\nRelated\n\nGeneralDistance\nSimpleDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistance{<:Any, <:SimpleDistance}, AbstractMatrix, Vararg{Any}}","page":"General Distance","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistance{<:Any, <:SimpleDistance},\n         rho::AbstractMatrix, args...; kwargs...)\n\nCompute a powered simple distance matrix from a correlation or covariance matrix.\n\nThis method takes a correlation or covariance matrix rho, raises it to the power specified in de.power, and applies the simple distance transformation. If rho is a covariance matrix, it is first converted to a correlation matrix.\n\nArguments\n\nde: General distance estimator with a power and SimpleDistance algorithm.\nrho: Correlation or covariance matrix.\nargs...: Ignored.\nkwargs...: Ignored.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise distances.\n\nDetails\n\nIf the diagonal of rho is not all ones, it is assumed to be a covariance matrix and is converted to a correlation matrix.\nThe distance is computed as sqrt(clamp!((1 - rho^power) * scale, 0, 1)), where scale is 0.5 if the power is odd, otherwise 1.0.\n\nRelated\n\nGeneralDistance\nSimpleDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{GeneralDistance{<:Any, <:SimpleDistance}, CovarianceEstimator, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(de::GeneralDistance{<:Any, <:SimpleDistance},\n             ce::StatsBase.CovarianceEstimator,\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the powered correlation matrix and the corresponding simple distance matrix from data.\n\nThis method computes the correlation matrix from the data matrix X using the provided covariance estimator ce, raises it to the power specified in de.power, and returns both the powered correlation matrix and the corresponding simple distance matrix.\n\nArguments\n\nde: General distance estimator with a power and SimpleDistance algorithm.\nce: Covariance estimator to use for correlation computation.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation estimator.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of powered correlation matrix and distance matrix.\n\nDetails\n\nThe distance is computed as sqrt(clamp!((1 - rho) * scale, 0, 1)), where scale is 0.5 if the power is odd, otherwise 1.0.\n\nRelated\n\nGeneralDistance\nSimpleDistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistance{<:Any, <:SimpleAbsoluteDistance}, CovarianceEstimator, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistance{<:Any, <:SimpleAbsoluteDistance},\n         ce::StatsBase.CovarianceEstimator,\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute a powered simple absolute distance matrix from data using a covariance estimator.\n\nThis method computes the correlation matrix from the data matrix X using the provided covariance estimator ce, takes the absolute value, raises it to the power specified in de.power, and then applies the simple absolute distance transformation. The result is a matrix of pairwise distances suitable for clustering or portfolio construction.\n\nArguments\n\nde: General distance estimator with a power and SimpleAbsoluteDistance algorithm.\nce: Covariance estimator to use for correlation computation.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation estimator.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise distances.\n\nDetails\n\nThe correlation matrix is computed, then the absolute value is taken and raised to the specified integer power.\nThe distance is computed as sqrt(clamp!(1 - |rho|^power, 0, 1)).\n\nRelated\n\nGeneralDistance\nSimpleAbsoluteDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistance{<:Any, <:SimpleAbsoluteDistance}, AbstractMatrix, Vararg{Any}}","page":"General Distance","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistance{<:Any, <:SimpleAbsoluteDistance},\n         rho::AbstractMatrix, args...; kwargs...)\n\nCompute a powered simple absolute distance matrix from a correlation or covariance matrix.\n\nThis method takes a correlation or covariance matrix rho, takes the absolute value, raises it to the power specified in de.power, and applies the simple absolute distance transformation. If rho is a covariance matrix, it is first converted to a correlation matrix.\n\nArguments\n\nde: General distance estimator with a power and SimpleAbsoluteDistance algorithm.\nrho: Correlation or covariance matrix.\nargs...: Ignored.\nkwargs...: Ignored.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise distances.\n\nDetails\n\nIf the diagonal of rho is not all ones, it is assumed to be a covariance matrix and is converted to a correlation matrix.\nThe distance is computed as sqrt(clamp!(1 - |rho|^power, 0, 1)).\n\nRelated\n\nGeneralDistance\nSimpleAbsoluteDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{GeneralDistance{<:Any, <:SimpleAbsoluteDistance}, CovarianceEstimator, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(de::GeneralDistance{<:Any, <:SimpleAbsoluteDistance},\n             ce::StatsBase.CovarianceEstimator,\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the powered absolute correlation matrix and the corresponding simple absolute distance matrix from data.\n\nThis method computes the correlation matrix from the data matrix X using the provided covariance estimator ce, takes the absolute value, raises it to the power specified in de.power, and returns both the powered absolute correlation matrix and the corresponding simple absolute distance matrix.\n\nArguments\n\nde: General distance estimator with a power and SimpleAbsoluteDistance algorithm.\nce: Covariance estimator to use for correlation computation.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation estimator.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of powered absolute correlation matrix and distance matrix.\n\nDetails\n\nThe distance is computed as sqrt(clamp!(1 - |rho|^power, 0, 1)).\n\nRelated\n\nGeneralDistance\nSimpleAbsoluteDistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistance{<:Any, <:LogDistance}, CovarianceEstimator, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistance{<:Any, <:LogDistance},\n         ce::StatsBase.CovarianceEstimator,\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute a powered log-distance matrix from data using a covariance estimator.\n\nThis method computes the correlation matrix from the data matrix X using the provided covariance estimator ce, raises the absolute value to the power specified in de.power, and then applies the negative logarithm transformation. The result is a matrix of pairwise log-distances.\n\nArguments\n\nde: General distance estimator with a power and LogDistance algorithm.\nce: Covariance estimator to use for correlation computation.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation estimator.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise log-distances.\n\nDetails\n\nThe correlation matrix is computed, absolute value is taken, raised to the specified power, and the negative logarithm is applied: -log(|rho|^power).\n\nRelated\n\nGeneralDistance\nLogDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistance{<:Any, <:LogDistance}, Union{LTDCovariance, PortfolioOptimisersCovariance{<:LTDCovariance}}, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistance{<:Any, <:LogDistance},\n         ce::Union{<:LTDCovariance, <:PortfolioOptimisersCovariance{<:LTDCovariance, <:Any}},\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute a powered log-distance matrix from data using an LTD covariance estimator.\n\nThis method computes the correlation matrix from the data matrix X using the provided LTD covariance estimator ce, raises it to the power specified in de.power, and then applies the negative logarithm transformation. The result is a matrix of pairwise log-distances.\n\nArguments\n\nde: General distance estimator with a power and LogDistance algorithm.\nce: LTD covariance estimator.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation estimator.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise log-distances.\n\nDetails\n\nThe correlation matrix is computed, raised to the specified power, and the negative logarithm is applied: -log(rho^power).\n\nRelated\n\nGeneralDistance\nLogDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistance{<:Any, <:LogDistance}, AbstractMatrix, Vararg{Any}}","page":"General Distance","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistance{<:Any, <:LogDistance},\n         rho::AbstractMatrix, args...; kwargs...)\n\nCompute a powered log-distance matrix from a correlation or covariance matrix.\n\nThis method takes a correlation or covariance matrix rho, converts to a correlation matrix if needed, takes the absolute value, raises it to the power specified in de.power, and applies the negative logarithm transformation.\n\nArguments\n\nde: General distance estimator with a power and LogDistance algorithm.\nrho: Correlation or covariance matrix.\nargs...: Ignored.\nkwargs...: Ignored.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise log-distances.\n\nDetails\n\nIf the diagonal of rho is not all ones, it is assumed to be a covariance matrix and is converted to a correlation matrix.\nThe distance is computed as -log(|rho|^power).\n\nRelated\n\nGeneralDistance\nLogDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{GeneralDistance{<:Any, <:LogDistance}, CovarianceEstimator, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(de::GeneralDistance{<:Any, <:LogDistance},\n             ce::StatsBase.CovarianceEstimator,\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the powered absolute correlation matrix and the corresponding log-distance matrix from data.\n\nThis method computes the correlation matrix from the data matrix X using the provided covariance estimator ce, takes the absolute value, raises it to the power specified in de.power, and returns both the powered absolute correlation matrix and the corresponding log-distance matrix.\n\nArguments\n\nde: General distance estimator with a power and LogDistance algorithm.\nce: Covariance estimator to use for correlation computation.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation estimator.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of powered absolute correlation matrix and log-distance matrix.\n\nDetails\n\nThe distance is computed as -log(rho) where rho = |cor(X)|^power.\n\nRelated\n\nGeneralDistance\nLogDistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{GeneralDistance{<:Any, <:LogDistance}, Union{LTDCovariance, PortfolioOptimisersCovariance{<:LTDCovariance}}, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(de::GeneralDistance{<:Any, <:LogDistance},\n             ce::Union{<:LTDCovariance, <:PortfolioOptimisersCovariance{<:LTDCovariance, <:Any}},\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the powered correlation matrix and the corresponding log-distance matrix from data using an LTD covariance estimator.\n\nThis method computes the correlation matrix from the data matrix X using the provided LTD covariance estimator ce, raises it to the power specified in de.power, and returns both the powered correlation matrix and the corresponding log-distance matrix.\n\nArguments\n\nde: General distance estimator with a power and LogDistance algorithm.\nce: LTD covariance estimator.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation estimator.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of powered correlation matrix and log-distance matrix.\n\nDetails\n\nThe distance is computed as -log(rho) where rho = cor(X)^power.\n\nRelated\n\nGeneralDistance\nLogDistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistance{<:Any, <:VariationInfoDistance}, Any, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistance{<:Any, <:VariationInfoDistance},\n         ::Any, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute a powered variation of information (VI) distance matrix from a data matrix.\n\nThis method computes the VI distance matrix for the input data matrix X using the configuration in the VariationInfoDistance algorithm, then raises the result to the power specified in de.power. The VI distance is a measure of dissimilarity between random variables based on their mutual information, estimated via histogram binning.\n\nArguments\n\nde: General distance estimator with a power and VariationInfoDistance algorithm.\n::Any: Placeholder for compatibility; ignored.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance. If 2, the data is transposed.\nkwargs...: Additional keyword arguments (ignored).\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of powered pairwise variation of information distances.\n\nDetails\n\nThe number of bins and normalisation are taken from the VariationInfoDistance algorithm fields.\nIf dims == 2, the data matrix is transposed before computation.\nThe resulting VI distance matrix is raised to the specified power.\n\nRelated\n\nGeneralDistance\nVariationInfoDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{GeneralDistance{<:Any, <:VariationInfoDistance}, CovarianceEstimator, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(de::GeneralDistance{<:Any, <:VariationInfoDistance},\n             ce::StatsBase.CovarianceEstimator, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the powered correlation matrix and the powered variation of information (VI) distance matrix from data.\n\nThis method computes the correlation matrix from the data matrix X using the provided covariance estimator ce, raises it to the power specified in de.power, and returns both the powered correlation matrix and the corresponding powered VI distance matrix. The VI distance is computed using the configuration in the VariationInfoDistance algorithm and is also raised to the specified power.\n\nArguments\n\nde: General distance estimator with a power and VariationInfoDistance algorithm.\nce: Covariance estimator (used to compute the correlation matrix).\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the correlation. If 2, the data is transposed.\nkwargs...: Additional keyword arguments passed to the correlation computation.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of powered correlation matrix and powered VI distance matrix.\n\nDetails\n\nThe number of bins and normalisation are taken from the VariationInfoDistance algorithm fields.\nIf dims == 2, the data matrix is transposed before computation.\nBoth the correlation matrix and the VI distance matrix are raised to the specified power.\n\nRelated\n\nGeneralDistance\nVariationInfoDistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistance{<:Any, <:CorrelationDistance}, CovarianceEstimator, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistance{<:Any, <:CorrelationDistance},\n         ce::StatsBase.CovarianceEstimator,\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute a powered correlation distance matrix from data using a covariance estimator.\n\nThis method computes the correlation matrix from the data matrix X using the provided covariance estimator ce, raises it to the power specified in de.power, and then applies the correlation distance transformation. The result is a matrix of pairwise correlation distances.\n\nArguments\n\nde: General distance estimator with a power and CorrelationDistance algorithm.\nce: Covariance estimator to use for correlation computation.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation estimator.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise correlation distances.\n\nDetails\n\nThe correlation matrix is raised to the specified integer power.\nThe distance is computed as sqrt(clamp!(1 - rho, 0, 1)).\n\nRelated\n\nGeneralDistance\nCorrelationDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistance{<:Any, <:CorrelationDistance}, AbstractMatrix, Vararg{Any}}","page":"General Distance","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistance{<:Any, <:CorrelationDistance},\n         rho::AbstractMatrix, args...; kwargs...)\n\nCompute a powered correlation distance matrix from a correlation or covariance matrix.\n\nThis method takes a correlation or covariance matrix rho, raises it to the power specified in de.power, and applies the correlation distance transformation. If rho is a covariance matrix, it is first converted to a correlation matrix.\n\nArguments\n\nde: General distance estimator with a power and CorrelationDistance algorithm.\nrho: Correlation or covariance matrix.\nargs...: Ignored.\nkwargs...: Ignored.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise correlation distances.\n\nDetails\n\nIf the diagonal of rho is not all ones, it is assumed to be a covariance matrix and is converted to a correlation matrix.\nThe distance is computed as sqrt(clamp!(1 - rho^power, 0, 1)).\n\nRelated\n\nGeneralDistance\nCorrelationDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{GeneralDistance{<:Any, <:CorrelationDistance}, CovarianceEstimator, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(de::GeneralDistance{<:Any, <:CorrelationDistance},\n             ce::StatsBase.CovarianceEstimator,\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the powered correlation matrix and the corresponding correlation distance matrix from data.\n\nThis method computes the correlation matrix from the data matrix X using the provided covariance estimator ce, raises it to the power specified in de.power, and returns both the powered correlation matrix and the corresponding correlation distance matrix.\n\nArguments\n\nde: General distance estimator with a power and CorrelationDistance algorithm.\nce: Covariance estimator to use for correlation computation.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the correlation.\nkwargs...: Additional keyword arguments passed to the correlation estimator.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of powered correlation matrix and correlation distance matrix.\n\nDetails\n\nThe distance is computed as sqrt(clamp!(1 - rho, 0, 1)).\n\nRelated\n\nGeneralDistance\nCorrelationDistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistance{<:Any, <:CanonicalDistance}, MutualInfoCovariance, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistance{<:Any, <:CanonicalDistance}, ce::MutualInfoCovariance,\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the canonical distance matrix using a mutual information covariance estimator and data matrix.\n\nThis method dispatches to the VariationInfoDistance algorithm, using the number of bins and normalisation from the provided MutualInfoCovariance estimator.\n\nArguments\n\nde: General distance estimator with a power and CanonicalDistance algorithm.\nce: Mutual information covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\ndist::Matri{<Real}: Matrix of pairwise canonical distances.\n\nRelated\n\nGeneralDistance\nVariationInfoDistance\nMutualInfoCovariance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistance{<:Any, <:CanonicalDistance}, PortfolioOptimisersCovariance{<:MutualInfoCovariance}, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistance{<:Any, <:CanonicalDistance},\n         ce::PortfolioOptimisersCovariance{<:MutualInfoCovariance, <:Any},\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the canonical distance matrix using a wrapped mutual information covariance estimator and data matrix.\n\nThis method dispatches to the VariationInfoDistance algorithm, using the number of bins and normalisation from the wrapped MutualInfoCovariance estimator.\n\nArguments\n\nde: General distance estimator with a power and CanonicalDistance algorithm.\nce: Wrapped mutual information covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise canonical distances.\n\nRelated\n\nGeneralDistance\nVariationInfoDistance\nMutualInfoCovariance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistance{<:Any, <:CanonicalDistance}, Union{LTDCovariance, PortfolioOptimisersCovariance{<:LTDCovariance}}, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistance{<:Any, <:CanonicalDistance},\n         ce::Union{<:LTDCovariance,\n                   <:PortfolioOptimisersCovariance{<:LTDCovariance, <:Any}},\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the canonical distance matrix using a lower tail dependence covariance estimator and data matrix.\n\nThis method dispatches to the LogDistance algorithm.\n\nArguments\n\nde: General distance estimator with a power and CanonicalDistance algorithm.\nce: LTD covariance estimator or a wrapped LTD estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise canonical distances.\n\nRelated\n\nGeneralDistance\nLogDistance\nLTDCovariance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistance{<:Any, <:CanonicalDistance}, Union{DistanceCovariance, PortfolioOptimisersCovariance{<:DistanceCovariance}}, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistance{<:Any, <:CanonicalDistance},\n         ce::Union{<:DistanceCovariance,\n                   <:PortfolioOptimisersCovariance{<:DistanceCovariance, <:Any}},\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the canonical distance matrix using a distance covariance estimator and data matrix.\n\nThis method dispatches to the CorrelationDistance algorithm.\n\nArguments\n\nde: General distance estimator with a power and CanonicalDistance algorithm.\nce: Distance covariance estimator or a wrapped distance covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise canonical distances.\n\nRelated\n\nGeneralDistance\nCorrelationDistance\nDistanceCovariance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistance{<:Any, <:CanonicalDistance}, CovarianceEstimator, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistance{<:Any, <:CanonicalDistance},\n         ce::StatsBase.CovarianceEstimator, X::AbstractMatrix; dims::Int = 1,\n         kwargs...)\n\nCompute the canonical distance matrix using a generic covariance estimator and data matrix.\n\nThis method dispatches to the SimpleDistance algorithm.\n\nArguments\n\nde: General distance estimator with a power and CanonicalDistance algorithm.\nce: Covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise canonical distances.\n\nRelated\n\nGeneralDistance\nSimpleDistance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.distance-Tuple{GeneralDistance{<:Any, <:CanonicalDistance}, AbstractMatrix, Vararg{Any}}","page":"General Distance","title":"PortfolioOptimisers.distance","text":"distance(de::GeneralDistance{<:Any, <:CanonicalDistance}, rho::AbstractMatrix,\n         args...; kwargs...)\n\nCompute the canonical distance matrix from a correlation or covariance matrix.\n\nThis method dispatches to the SimpleDistance algorithm.\n\nArguments\n\nde: General distance estimator with a power and CanonicalDistance algorithm.\nrho: Correlation or covariance matrix.\nargs...: Additional arguments (ignored).\nkwargs...: Additional keyword arguments.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise canonical distances.\n\nRelated\n\nGeneralDistance\nSimpleDistance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{GeneralDistance{<:Any, <:CanonicalDistance}, MutualInfoCovariance, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(de::GeneralDistance{<:Any, <:CanonicalDistance},\n             ce::MutualInfoCovariance, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the correlation matrix and the canonical distance matrix using a mutual information covariance estimator and data matrix.\n\nThis method dispatches to the VariationInfoDistance algorithm, using the number of bins and normalisation from the provided MutualInfoCovariance estimator.\n\nArguments\n\nde: General distance estimator with a power and CanonicalDistance algorithm.\nce: Mutual information covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of correlation matrix and canonical distance matrix.\n\nRelated\n\nGeneralDistance\nVariationInfoDistance\nMutualInfoCovariance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{GeneralDistance{<:Any, <:CanonicalDistance}, PortfolioOptimisersCovariance{<:MutualInfoCovariance}, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(de::GeneralDistance{<:Any, <:CanonicalDistance},\n             ce::PortfolioOptimisersCovariance{<:MutualInfoCovariance, <:Any},\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the correlation matrix and the canonical distance matrix using a wrapped mutual information covariance estimator and data matrix.\n\nThis method dispatches to the VariationInfoDistance algorithm, using the number of bins and normalisation from the wrapped MutualInfoCovariance estimator.\n\nArguments\n\nde: General distance estimator with a power and CanonicalDistance algorithm.\nce: Wrapped mutual information covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of correlation matrix and canonical distance matrix.\n\nRelated\n\nGeneralDistance\nVariationInfoDistance\nMutualInfoCovariance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{GeneralDistance{<:Any, <:CanonicalDistance}, Union{LTDCovariance, PortfolioOptimisersCovariance{<:LTDCovariance}}, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(de::GeneralDistance{<:Any, <:CanonicalDistance},\n             ce::Union{<:LTDCovariance,\n                       <:PortfolioOptimisersCovariance{<:LTDCovariance, <:Any}},\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the correlation matrix and the canonical distance matrix using a lower tail dependence covariance estimator and data matrix.\n\nThis method dispatches to the LogDistance algorithm.\n\nArguments\n\nde: General distance estimator with a power and CanonicalDistance algorithm.\nce: LTD covariance estimator or a wrapped LTD estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of correlation matrix and canonical distance matrix.\n\nRelated\n\nGeneralDistance\nLogDistance\nLTDCovariance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{GeneralDistance{<:Any, <:CanonicalDistance}, Union{DistanceCovariance, PortfolioOptimisersCovariance{<:DistanceCovariance}}, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(de::GeneralDistance{<:Any, <:CanonicalDistance},\n             ce::Union{<:DistanceCovariance,\n                       <:PortfolioOptimisersCovariance{<:DistanceCovariance, <:Any}},\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the correlation matrix and the canonical distance matrix using a distance covariance estimator and data matrix.\n\nThis method dispatches to the CorrelationDistance algorithm.\n\nArguments\n\nde: General distance estimator with a power and CanonicalDistance algorithm.\nce: Distance covariance estimator or a wrapped distance covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of correlation matrix and canonical distance matrix.\n\nRelated\n\nGeneralDistance\nCorrelationDistance\nDistanceCovariance\n\n\n\n\n\n","category":"method"},{"location":"008-4-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{GeneralDistance{<:Any, <:CanonicalDistance}, CovarianceEstimator, AbstractMatrix}","page":"General Distance","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(de::GeneralDistance{<:Any, <:CanonicalDistance},\n             ce::StatsBase.CovarianceEstimator, X::AbstractMatrix; dims::Int = 1,\n             kwargs...)\n\nCompute both the correlation matrix and the canonical distance matrix using a generic covariance estimator and data matrix.\n\nThis method dispatches to the SimpleDistance algorithm.\n\nArguments\n\nde: General distance estimator with a power and CanonicalDistance algorithm.\nce: Covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the distance.\nkwargs...: Additional keyword arguments.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of correlation matrix and canonical distance matrix.\n\nRelated\n\nGeneralDistance\nSimpleDistance\n\n\n\n\n\n","category":"method"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"The source files for all examples can be found in /examples.","category":"page"},{"location":"examples/1-Getting-Started/#Example-1:-Simple-MeanRisk-optimisation","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"","category":"section"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"Here we show a simple example of how to use PortfolioOptimisers. We will perform the classic Markowitz optimisation.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"using PortfolioOptimisers","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"PrettyTables is used to format the example output.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"using PrettyTables\n\n# Format for pretty tables.\ntsfmt = (v, i, j) -> begin\n    if j == 1\n        return Date(v)\n    else\n        return v\n    end\nend;\nresfmt = (v, i, j) -> begin\n    if j == 1\n        return v\n    else\n        return isa(v, Number) ? \"$(round(v*100, digits=3)) %\" : v\n    end\nend;\nmipresfmt = (v, i, j) -> begin\n    if j ∈ (1, 2, 3)\n        return v\n    else\n        return isa(v, Number) ? \"$(round(v*100, digits=3)) %\" : v\n    end\nend;\nnothing #hide","category":"page"},{"location":"examples/1-Getting-Started/#1.-Load-the-data","page":"Example 1: Simple MeanRisk optimisation","title":"1. Load the data","text":"","category":"section"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"Import the S&P500 data from a compressed .csv file. We will only use the last 253 observations.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"using CSV, TimeSeries, DataFrames\n\nX = TimeArray(CSV.File(joinpath(@__DIR__, \"SP500.csv.gz\")); timestamp = :Date)[(end - 252):end]\npretty_table(X[(end - 5):end]; formatters = tsfmt)","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"First we must compute the returns from the prices. The ReturnsResult struct stores the asset names in nx, asset returns in X, and timestamps in ts. The other fields are used in other applications which we will not be showcasing here.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"rd = prices_to_returns(X)","category":"page"},{"location":"examples/1-Getting-Started/#2.-MeanRisk-optimisation","page":"Example 1: Simple MeanRisk optimisation","title":"2. MeanRisk optimisation","text":"","category":"section"},{"location":"examples/1-Getting-Started/#2.1-Creating-a-solver-instance","page":"Example 1: Simple MeanRisk optimisation","title":"2.1 Creating a solver instance","text":"","category":"section"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"All optimisations require some prior statistics to be computed. This can either be done before the optimisation function, or within it. For certain optimisations, precomputing the prior is more efficient, but it makes no difference here so we'll do it within the optimisation.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"The MeanRisk estimator defines a mean-risk optimisation problem. It is a JuMPOptimisationEstimator, which means it requires a JuMP-compatible optimiser, which in this case will be Clarabel.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"using Clarabel","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"We have to define a Solver object, which contains the optimiser we wish to use, an optional name for logging purposes, optional solver settings, and optional kwargs for JuMP.assert_is_solved_and_feasible.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"Given the vast range of optimisation options and types, it is often useful to try different solver and settings combinations. To this aim, it is also possible to provide a vector of Solver objects, which is iterated over until one succeeds or all fail. The classic Markowitz optimisation is rather simple, so we will use a single solver instance.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"slv = Solver(; name = :clarabel1, solver = Clarabel.Optimizer,\n             settings = Dict(\"verbose\" => false),\n             check_sol = (; allow_local = true, allow_almost = true))","category":"page"},{"location":"examples/1-Getting-Started/#2.2-Defining-the-optimisation-estimator","page":"Example 1: Simple MeanRisk optimisation","title":"2.2 Defining the optimisation estimator","text":"","category":"section"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"PortfolioOptimisers is designed to heavily leverage composition. The first hint of this design ethos in the examples comes in the form of JuMPOptimiser, which is the structure defining the optimiser parameters used in all JuMPOptimisationEstimators.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"Lets create a MeanRisk estimator. As you can see from the output, JuMPOptimiser and MeanRisk contain myriad properties that we will not showcase in this example.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"mr = MeanRisk(; opt = JuMPOptimiser(; slv = slv))","category":"page"},{"location":"examples/1-Getting-Started/#2.3-Performing-the-optimisation","page":"Example 1: Simple MeanRisk optimisation","title":"2.3 Performing the optimisation","text":"","category":"section"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"The optimise! function is used to perform all optimisations in PortfolioOptimisers. Each method returns an AbstractResult object containing the optimisation results, which include a return code, a solution object, and relevant statistics (precomputed or otherwise) used in the optimisation.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"The field retcode informs us that our optimisation was successful because it contains an OptimisationSuccess return code.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"res = optimise!(mr, rd)","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"Lets view the solution results as a pretty table. For convenience, we have ensured all AbstractResult have a property called w, which directly accesses sol.w. The optimisations don't shuffle the asset order, so we can simply view the asset names and weights side by side.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"pretty_table(DataFrame(:assets => rd.nx, :weights => res.w); formatters = resfmt)","category":"page"},{"location":"examples/1-Getting-Started/#3.-Finite-allocation","page":"Example 1: Simple MeanRisk optimisation","title":"3. Finite allocation","text":"","category":"section"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"We have the optimal solution, but most people don't have access to effectively unlimited funds. Given the optimised weights, current prices and a finite cash amount, it is possible to perform a finite allocation. We will use a discrete allocation method which uses mixed-integer programming to find the best allocation. We have another finite allocation method which uses a greedy algorithm that can deal with fractional shares, but we will reserve it for a later example.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"For the discrete allocation, we need a solver capable of handling mixed-integer programming problems, we will use HiGHS.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"using HiGHS\n\nmip_slv = Solver(; name = :highs1, solver = HiGHS.Optimizer,\n                 settings = Dict(\"log_to_console\" => false),\n                 check_sol = (; allow_local = true, allow_almost = true))\nda = DiscreteAllocation(; slv = mip_slv)","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"Luckily, we have the optimal weights, the latest prices are the last entry of our original time array X, and lets say we have 4206.9 USD to invest.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"The function can optionally take extra positional arguments to account for a variety of fees, but we will not use them here.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"mip_res = optimise!(da, res.w, vec(values(X[end])), 4206.9)","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"The result of this optimisation contains different pieces of information to the previous one. The reason various fields are prefixed by l_or s_ is because the discrete allocation method splits the assets into long and short positions, which are recombined in the final result.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"Lets see the results in another pretty table.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"pretty_table(DataFrame(:assets => rd.nx, :shares => mip_res.shares, :cost => mip_res.cost,\n                       :opt_weights => res.w, :mip_weights => mip_res.w);\n             formatters = mipresfmt)","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"We can see that the mip weights do not exactly match the optimal ones, but that is because we only have finite resources. Note that the sum of the costs minus the initial cash is equal to the cash property of the result. This changes when we introduce fees, which will be shown in a future example.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"println(\"used cash ≈ available cash: $(isapprox(mip_res.cash, 4206.9 - sum(mip_res.cost)))\")","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"We can also see that the cost of each asset is equal to the number of shares times its price.","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"println(\"cost of shares ≈ cost of portfolio: $(all(isapprox.(mip_res.shares .* vec(values(X[end])), mip_res.cost)))\")","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"","category":"page"},{"location":"examples/1-Getting-Started/","page":"Example 1: Simple MeanRisk optimisation","title":"Example 1: Simple MeanRisk optimisation","text":"This page was generated using Literate.jl.","category":"page"},{"location":"008-3-Distance/#Distances-of-Distances","page":"Distances of Distances","title":"Distances of Distances","text":"","category":"section"},{"location":"008-3-Distance/#PortfolioOptimisers.DistanceDistance","page":"Distances of Distances","title":"PortfolioOptimisers.DistanceDistance","text":"struct DistanceDistance{T1, T2, T3, T4} <: AbstractDistanceEstimator\n    dist::T1\n    args::T2\n    kwargs::T3\n    alg::T4\nend\n\nA distance-of-distances estimator for portfolio optimization.\n\nDistanceDistance wraps a distance metric from Distances.jl and a base distance algorithm, allowing you to compute a \"distance of distances\" matrix. This is useful for meta-clustering or higher-order distance-based analyses.\n\nFields\n\ndist: The metric to use for the second-level distance from Distances.jl.\nargs: Positional arguments to pass to the metric.\nkwargs: Keyword arguments to pass to the metric.\nalg::AbstractDistanceAlgorithm: The base distance algorithm to use.\n\nConstructor\n\nDistanceDistance(; dist::Distances.Metric = Distances.Euclidean(),\n                   args::Tuple = (), kwargs::NamedTuple = (;),\n                   alg::AbstractDistanceAlgorithm = SimpleDistance())\n\nRelated\n\nDistance\ndistance\nDistances.jl\n\n\n\n\n\n","category":"type"},{"location":"008-3-Distance/#PortfolioOptimisers.DistanceDistance-Tuple{}","page":"Distances of Distances","title":"PortfolioOptimisers.DistanceDistance","text":"DistanceDistance(; dist::Distances.Metric = Distances.Euclidean(),\n                  args::Tuple = (), kwargs::NamedTuple = (;),\n                  alg::AbstractDistanceAlgorithm = SimpleDistance())\n\nConstruct a DistanceDistance estimator with the specified metric and base distance algorithm.\n\nArguments\n\ndist: The metric to use for the second-level distance from Distances.jl.\nargs: Positional arguments to pass to the metric.\nkwargs: Keyword arguments to pass to the metric.\nalg: The base distance algorithm to use.\n\nReturns\n\nDistanceDistance: A configured distance-of-distances estimator.\n\nExamples\n\njulia> DistanceDistance()\nDistanceDistance\n    dist | Distances.Euclidean: Distances.Euclidean(0.0)\n    args | Tuple{}: ()\n  kwargs | @NamedTuple{}: NamedTuple()\n     alg | SimpleDistance()\n\nRelated\n\nDistanceDistance\nDistance\ndistance\nDistances.jl\n\n\n\n\n\n","category":"method"},{"location":"008-3-Distance/#PortfolioOptimisers.distance-Tuple{DistanceDistance, CovarianceEstimator, AbstractMatrix}","page":"Distances of Distances","title":"PortfolioOptimisers.distance","text":"distance(de::DistanceDistance, ce::StatsBase.CovarianceEstimator,\n         X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the distance-of-distances matrix from a covariance estimator and data matrix.\n\nThis method first computes a base distance matrix using the specified base distance algorithm, then applies the provided metric to compute a second-level distance matrix.\n\nArguments\n\nde: Distance-of-distances estimator.\nce: Covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the base distance.\nkwargs...: Additional keyword arguments passed to the base distance computation.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise distances of distances.\n\nRelated\n\nDistanceDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-3-Distance/#PortfolioOptimisers.distance-Tuple{DistanceDistance, AbstractMatrix, Vararg{Any}}","page":"Distances of Distances","title":"PortfolioOptimisers.distance","text":"distance(de::DistanceDistance, rho::AbstractMatrix, args...; kwargs...)\n\nCompute the distance-of-distances matrix from a correlation or covariance matrix.\n\nThis method first computes a base distance matrix using the specified base distance algorithm, then applies the provided metric to compute a second-level distance matrix.\n\nArguments\n\nde: Distance-of-distances estimator.\nrho: Correlation or covariance matrix.\nargs...: Additional arguments (ignored).\nkwargs...: Additional keyword arguments passed to the base distance computation.\n\nReturns\n\ndist::Matrix{<:Real}: Matrix of pairwise distances of distances.\n\nRelated\n\nDistanceDistance\ndistance\n\n\n\n\n\n","category":"method"},{"location":"008-3-Distance/#PortfolioOptimisers.cor_and_dist-Tuple{DistanceDistance, CovarianceEstimator, AbstractMatrix}","page":"Distances of Distances","title":"PortfolioOptimisers.cor_and_dist","text":"cor_and_dist(de::DistanceDistance, ce::StatsBase.CovarianceEstimator,\n             X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute both the correlation matrix and the distance-of-distances matrix from a covariance estimator and data matrix.\n\nThis method first computes the correlation and base distance matrices, then applies the provided metric to the base distance matrix.\n\nArguments\n\nde: Distance-of-distances estimator.\nce: Covariance estimator.\nX: Data matrix (observations × features).\ndims: Dimension along which to compute the base distance.\nkwargs...: Additional keyword arguments passed to the base distance computation.\n\nReturns\n\n(rho::Matrix{<:Real}, dist::Matrix{<:Real}): Tuple of correlation matrix and distance-of-distances matrix.\n\nRelated\n\nDistanceDistance\ncor_and_dist\n\n\n\n\n\n","category":"method"},{"location":"005-Detone/#Detone","page":"Detone","title":"Detone","text":"","category":"section"},{"location":"005-Detone/#PortfolioOptimisers.Detone","page":"Detone","title":"PortfolioOptimisers.Detone","text":"struct Detone{T1} <: AbstractDetoneEstimator\n    n::T1\nend\n\nA concrete detoning estimator for removing the top n principal components (market modes) from a covariance or correlation matrix.\n\nFields\n\nn: Number of leading principal components to remove.\n\nConstructor\n\nDetone(; n = 1)\n\nRelated\n\nDetone\ndetone!\ndetone\n\n\n\n\n\n","category":"type"},{"location":"005-Detone/#PortfolioOptimisers.Detone-Tuple{}","page":"Detone","title":"PortfolioOptimisers.Detone","text":"Detone(; n::Integer = 1)\n\nConstruct a Detone estimator for removing the top n principal components (market modes) from a covariance or correlation matrix.\n\nArguments\n\nn: Number of leading principal components to remove. Must satisfy n ≥ 0.\n\nReturns\n\nDetone: A detoning estimator.\n\nExamples\n\njulia> dt = Detone(; n = 2)\nDetone\n  n | Int64: 2\n\nRelated\n\ndetone!\ndetone\n\n\n\n\n\n","category":"method"},{"location":"005-Detone/#PortfolioOptimisers.detone!","page":"Detone","title":"PortfolioOptimisers.detone!","text":"detone!(dt::Detone, X::AbstractMatrix, pdm::Union{Nothing, <:Posdef} = Posdef())\ndetone!(::Nothing, args...)\n\nIn-place removal of the top n principal components (market modes) from a covariance or correlation matrix.\n\nIf dt is nothing, this is a no-op and returns nothing.\nIf dt is a Detone object, the top n principal components are removed from X in-place. Optionally, a Posdef can be provided to ensure the output is positive definite.\n\nArguments\n\ndt: The detoning estimator specifying the number of components to remove.\nX: The covariance or correlation matrix to be detoned (modified in-place).\npdm: Optional Positive definite matrix estimator. If provided, ensures the output is positive definite.\n\nReturns\n\nnothing. The input matrix X is modified in-place.\n\nValidation\n\nIf X is a covariance matrix, it is internally converted to a correlation matrix for detoning and then rescaled.\nThe number of components removed is validated to be within the matrix size.\nIf pdm is provided, the result is projected to the nearest positive definite matrix.\n\nExamples\n\njulia> using StableRNGs\n\njulia> rng = StableRNG(123456789);\n\njulia> X = rand(rng, 10, 5);\n\njulia> X = X' * X\n5×5 Matrix{Float64}:\n 3.29494  2.0765   1.73334  2.01524  1.77493\n 2.0765   2.46967  1.39953  1.97242  2.07886\n 1.73334  1.39953  1.90712  1.17071  1.30459\n 2.01524  1.97242  1.17071  2.24818  1.87091\n 1.77493  2.07886  1.30459  1.87091  2.44414\n\njulia> detone!(Detone(), X)\n\njulia> X\n5×5 Matrix{Float64}:\n  3.29494    -1.14673     0.0868439  -0.502106   -1.71581\n -1.14673     2.46967    -0.876289   -0.0864304   0.274663\n  0.0868439  -0.876289    1.90712    -1.18851    -0.750345\n -0.502106   -0.0864304  -1.18851     2.24818    -0.0774753\n -1.71581     0.274663   -0.750345   -0.0774753   2.44414\n\nRelated\n\ndetone\nDetone\n\n\n\n\n\n","category":"function"},{"location":"005-Detone/#PortfolioOptimisers.detone","page":"Detone","title":"PortfolioOptimisers.detone","text":"detone(dt::Detone, X::AbstractMatrix, pdm::Union{Nothing, <:Posdef} = Posdef())\ndetone(::Nothing, args...)\n\nSame as detone!, but returns a new matrix instead of modifying X in-place.\n\nIf dt is nothing, this is a no-op and returns nothing.\n\nExamples\n\njulia> using StableRNGs\n\njulia> rng = StableRNG(123456789);\n\njulia> X = rand(rng, 10, 5);\n\njulia> X = X' * X\n5×5 Matrix{Float64}:\n 3.29494  2.0765   1.73334  2.01524  1.77493\n 2.0765   2.46967  1.39953  1.97242  2.07886\n 1.73334  1.39953  1.90712  1.17071  1.30459\n 2.01524  1.97242  1.17071  2.24818  1.87091\n 1.77493  2.07886  1.30459  1.87091  2.44414\n\njulia> Xd = detone(Detone(), X)\n5×5 Matrix{Float64}:\n  3.29494    -1.14673     0.0868439  -0.502106   -1.71581\n -1.14673     2.46967    -0.876289   -0.0864304   0.274663\n  0.0868439  -0.876289    1.90712    -1.18851    -0.750345\n -0.502106   -0.0864304  -1.18851     2.24818    -0.0774753\n -1.71581     0.274663   -0.750345   -0.0774753   2.44414\n\nRelated\n\ndetone!\nDetone\n\n\n\n\n\n","category":"function"},{"location":"005-Detone/#PortfolioOptimisers.AbstractDetoneEstimator","page":"Detone","title":"PortfolioOptimisers.AbstractDetoneEstimator","text":"abstract type AbstractDetoneEstimator <: AbstractEstimator end\n\nAbstract supertype for all detoning estimators in PortfolioOptimisers.jl.\n\nAll concrete types representing detoning estimators (such as Detone) should subtype AbstractDetoneEstimator. This enables a consistent interface for detoning routines and downstream analysis.\n\nRelated\n\nDetone\ndetone!\ndetone\n\n\n\n\n\n","category":"type"},{"location":"007-04-Moments/#Variance-and-Standard-Deviation","page":"Variance and Standard Deviation","title":"Variance and Standard Deviation","text":"","category":"section"},{"location":"007-04-Moments/#PortfolioOptimisers.SimpleVariance","page":"Variance and Standard Deviation","title":"PortfolioOptimisers.SimpleVariance","text":"SimpleVariance{T1 <: Union{Nothing, <:AbstractExpectedReturnsEstimator},\n               T2 <: Union{Nothing, <:AbstractWeights}, T3 <: Bool}\n\nA flexible variance estimator for PortfolioOptimisers.jl supporting optional expected returns estimators, observation weights, and bias correction.\n\nSimpleVariance enables users to specify an expected returns estimator (for mean-centering), optional observation weights, and whether to apply bias correction (Bessel's correction). This type is suitable for both unweighted and weighted variance estimation workflows.\n\nFields\n\nme: Optional expected returns estimator. If nothing, the mean is not estimated.\nw: Optional observation weights. If nothing, the estimator is unweighted.\ncorrected: Whether to apply Bessel's correction (unbiased variance).\n\nConstructor\n\nSimpleVariance(; me::Union{Nothing, <:AbstractExpectedReturnsEstimator} = SimpleExpectedReturns(),\n                w::Union{Nothing, <:AbstractWeights} = nothing,\n                corrected::Bool = true)\n\nConstruct a SimpleVariance estimator with the specified expected returns estimator, optional weights, and bias correction flag.\n\nRelated\n\nAbstractVarianceEstimator\nAbstractExpectedReturnsEstimator\nSimpleExpectedReturns\nStatsBase.AbstractWeights\nstd(ve::SimpleVariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nstd(ve::SimpleVariance, X::AbstractVector; dims::Int = 1, mean = nothing, kwargs...)\nvar(ve::SimpleVariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nvar(ve::SimpleVariance, X::AbstractVector; mean = nothing)\n\n\n\n\n\n","category":"type"},{"location":"007-04-Moments/#PortfolioOptimisers.SimpleVariance-Tuple{}","page":"Variance and Standard Deviation","title":"PortfolioOptimisers.SimpleVariance","text":"SimpleVariance(; me::Union{Nothing, <:AbstractExpectedReturnsEstimator} = SimpleExpectedReturns(),\n                w::Union{Nothing, <:AbstractWeights} = nothing,\n                corrected::Bool = true)\n\nConstruct a SimpleVariance estimator for flexible variance estimation with optional mean-centering, observation weights, and bias correction.\n\nThis constructor creates a SimpleVariance object using the specified expected returns estimator for mean-centering, optional observation weights, and a flag for Bessel's correction (bias correction). If no weights are provided, the estimator defaults to unweighted variance estimation. If weights are provided, they must not be empty.\n\nArguments\n\nme: Expected returns estimator. Necessary when estimating the variance or standard deviation along the dimension of a matrix. Not used when computed on a vector.\nw: Optional observation weights. If nothing, the estimator is unweighted.\ncorrected: Whether to apply Bessel's correction.\n\nReturns\n\nSimpleVariance: A variance estimator configured with the specified mean estimator, weights, and bias correction flag.\n\nValidation\n\nIf w is provided, it must not be empty.\n\nExamples\n\njulia> using StatsBase\n\njulia> sv = SimpleVariance()\nSimpleVariance\n         me | SimpleExpectedReturns\n            |   w | nothing\n          w | nothing\n  corrected | Bool: true\n\njulia> w = Weights([0.2, 0.3, 0.5]);\n\njulia> svw = SimpleVariance(; w = w, corrected = false)\nSimpleVariance\n         me | SimpleExpectedReturns\n            |   w | nothing\n          w | StatsBase.Weights{Float64, Float64, Vector{Float64}}: [0.2, 0.3, 0.5]\n  corrected | Bool: false\n\nRelated\n\nSimpleVariance\nAbstractVarianceEstimator\nAbstractExpectedReturnsEstimator\nSimpleExpectedReturns\nStatsBase.AbstractWeights\nstd(ve::SimpleVariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nstd(ve::SimpleVariance, X::AbstractVector; dims::Int = 1, mean = nothing, kwargs...)\nvar(ve::SimpleVariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nvar(ve::SimpleVariance, X::AbstractVector; mean = nothing)\n\n\n\n\n\n","category":"method"},{"location":"007-04-Moments/#Statistics.std-Tuple{SimpleVariance, AbstractMatrix}","page":"Variance and Standard Deviation","title":"Statistics.std","text":"std(ve::SimpleVariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\nCompute the standard deviation using a SimpleVariance estimator for an array.\n\nThis method computes the standard deviation of the input array X using the configuration specified in ve, including optional mean-centering (via ve.me), observation weights (ve.w), and bias correction (ve.corrected). If a mean is not provided, it is estimated using the expected returns estimator in ve.me.\n\nArguments\n\nve: Variance estimator specifying the mean estimator, weights, and bias correction.\nX: Data array (vector or matrix) for which to compute the standard deviation.\ndims: Dimension along which to compute the standard deviation (for matrices).\nmean: Optional mean value or vector for centering. If not provided, estimated using ve.me.\nkwargs...: Additional keyword arguments passed to the mean estimator.\n\nReturns\n\nStandard deviation of X, computed according to the estimator configuration.\n\nExamples\n\njulia> sv = SimpleVariance()\nSimpleVariance\n         me | SimpleExpectedReturns\n            |   w | nothing\n          w | nothing\n  corrected | Bool: true\n\njulia> Xmat = [1.0 2.0; 3.0 4.0];\n\njulia> std(sv, Xmat; dims = 1)\n1×2 Matrix{Float64}:\n 1.41421  1.41421\n\nRelated\n\nSimpleVariance\nStatistics.std\nstd(ve::SimpleVariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nstd(ve::SimpleVariance, X::AbstractVector; dims::Int = 1, mean = nothing, kwargs...)\nvar(ve::SimpleVariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nvar(ve::SimpleVariance, X::AbstractVector; mean = nothing)\n\n\n\n\n\n","category":"method"},{"location":"007-04-Moments/#Statistics.std-Tuple{SimpleVariance, AbstractVector}","page":"Variance and Standard Deviation","title":"Statistics.std","text":"std(ve::SimpleVariance, X::AbstractVector; mean = nothing)\n\nCompute the standard deviation using a SimpleVariance estimator for a vector.\n\nThis method computes the standard deviation of the input vector X using the configuration specified in ve, including optional observation weights (ve.w) and bias correction (ve.corrected). If a mean is provided, it is used for centering; otherwise, the default mean is used.\n\nArguments\n\nve: Variance estimator specifying weights and bias correction.\nX: Data vector for which to compute the standard deviation.\nmean: Optional Mean value for centering. If not provided, the default mean is used.\n\nReturns\n\nStandard deviation of X, computed according to the estimator configuration.\n\nExamples\n\njulia> using StatsBase\n\njulia> sv = SimpleVariance()\nSimpleVariance\n         me | SimpleExpectedReturns\n            |   w | nothing\n          w | nothing\n  corrected | Bool: true\n\njulia> X = [1.0, 2.0, 3.0];\n\njulia> std(sv, X)\n1.0\n\njulia> w = Weights([0.2, 0.3, 0.5]);\n\njulia> svw = SimpleVariance(; w = w, corrected = false)\nSimpleVariance\n         me | SimpleExpectedReturns\n            |   w | nothing\n          w | StatsBase.Weights{Float64, Float64, Vector{Float64}}: [0.2, 0.3, 0.5]\n  corrected | Bool: false\n\njulia> std(svw, X)\n0.7810249675906654\n\nRelated\n\nSimpleVariance\nStatistics.std\nstd(ve::SimpleVariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nvar(ve::SimpleVariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nvar(ve::SimpleVariance, X::AbstractVector; mean = nothing)\n\n\n\n\n\n","category":"method"},{"location":"007-04-Moments/#Statistics.var-Tuple{SimpleVariance, AbstractMatrix}","page":"Variance and Standard Deviation","title":"Statistics.var","text":"var(ve::SimpleVariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\nCompute the variance using a SimpleVariance estimator for an array.\n\nThis method computes the variance of the input array X using the configuration specified in ve, including optional mean-centering (via ve.me), observation weights (ve.w), and bias correction (ve.corrected). If a mean is not provided, it is estimated using the expected returns estimator in ve.me.\n\nArguments\n\nve: Variance estimator specifying the mean estimator, weights, and bias correction.\nX: Data array (vector or matrix) for which to compute the variance.\ndims: Dimension along which to compute the variance (for matrices).\nmean: Optional mean value or vector for centering. If not provided, estimated using ve.me.\nkwargs...: Additional keyword arguments passed to the mean estimator.\n\nReturns\n\nVariance of X, computed according to the estimator configuration.\n\nExamples\n\njulia> sv = SimpleVariance()\nSimpleVariance\n         me | SimpleExpectedReturns\n            |   w | nothing\n          w | nothing\n  corrected | Bool: true\n\njulia> Xmat = [1.0 2.0; 3.0 4.0];\n\njulia> var(sv, Xmat; dims = 1)\n1×2 Matrix{Float64}:\n 2.0  2.0\n\nRelated\n\nSimpleVariance\nStatistics.var\nstd(ve::SimpleVariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nstd(ve::SimpleVariance, X::AbstractVector; dims::Int = 1, mean = nothing, kwargs...)\nvar(ve::SimpleVariance, X::AbstractVector; mean = nothing)\n\n\n\n\n\n","category":"method"},{"location":"007-04-Moments/#Statistics.var-Tuple{SimpleVariance, AbstractVector}","page":"Variance and Standard Deviation","title":"Statistics.var","text":"var(ve::SimpleVariance, X::AbstractVector; mean = nothing)\n\nCompute the variance using a SimpleVariance estimator for a vector.\n\nThis method computes the variance of the input vector X using the configuration specified in ve, including optional observation weights (ve.w) and bias correction (ve.corrected). If a mean is provided, it is used for centering; otherwise, the default mean is used.\n\nArguments\n\nve: Variance estimator specifying weights and bias correction.\nX: Data vector for which to compute the variance.\nmean: Optional mean value for centering. If not provided, the default mean is used.\n\nReturns\n\nVariance of X, computed according to the estimator configuration.\n\nExamples\n\njulia> using StatsBase\n\njulia> sv = SimpleVariance()\nSimpleVariance\n         me | SimpleExpectedReturns\n            |   w | nothing\n          w | nothing\n  corrected | Bool: true\n\njulia> X = [1.0, 2.0, 3.0];\n\njulia> var(sv, X)\n1.0\n\njulia> w = Weights([0.2, 0.3, 0.5]);\n\njulia> svw = SimpleVariance(; w = w, corrected = false)\nSimpleVariance\n         me | SimpleExpectedReturns\n            |   w | nothing\n          w | StatsBase.Weights{Float64, Float64, Vector{Float64}}: [0.2, 0.3, 0.5]\n  corrected | Bool: false\n\njulia> var(svw, X)\n0.61\n\nRelated\n\nSimpleVariance\nStatistics.var\nstd(ve::SimpleVariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\nstd(ve::SimpleVariance, X::AbstractVector; dims::Int = 1, mean = nothing, kwargs...)\nvar(ve::SimpleVariance, X::AbstractMatrix; dims::Int = 1, mean = nothing, kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"092-reference/#reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"092-reference/","page":"Reference","title":"Reference","text":"G. P. Massara, T. Di Matteo and T. Aste. Network Filtering for Big Data: Triangulated Maximally Filtered Graph. Journal of Complex Networks 5, 161–178 (2016), arXiv:https://academic.oup.com/comnet/article-pdf/5/2/161/13794756/cnw015.pdf.\n\n\n\n","category":"page"},{"location":"092-reference/#Contributors","page":"Reference","title":"Contributors","text":"","category":"section"},{"location":"092-reference/","page":"Reference","title":"Reference","text":"<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->","category":"page"},{"location":"092-reference/#Contents","page":"Reference","title":"Contents","text":"","category":"section"},{"location":"092-reference/","page":"Reference","title":"Reference","text":"Pages = [\"95-reference.md\"]","category":"page"},{"location":"092-reference/#Index","page":"Reference","title":"Index","text":"","category":"section"},{"location":"092-reference/","page":"Reference","title":"Reference","text":"","category":"page"},{"location":"011-2-Clustering/#Clustering","page":"Clustering","title":"Clustering","text":"","category":"section"},{"location":"011-2-Clustering/#PortfolioOptimisers.AbstractClusteringEstimator","page":"Clustering","title":"PortfolioOptimisers.AbstractClusteringEstimator","text":"AbstractClusteringEstimator <: AbstractPhylogenyEstimator\n\nAbstract supertype for all clustering estimator types in PortfolioOptimisers.jl.\n\nAll concrete types implementing clustering-based estimation algorithms should subtype AbstractClusteringEstimator. This enables a consistent interface for clustering estimators throughout the package.\n\nRelated\n\nAbstractClusteringAlgorithm\nAbstractClusteringResult\n\n\n\n\n\n","category":"type"},{"location":"011-2-Clustering/#PortfolioOptimisers.AbstractClusteringAlgorithm","page":"Clustering","title":"PortfolioOptimisers.AbstractClusteringAlgorithm","text":"AbstractClusteringAlgorithm <: AbstractPhylogenyAlgorithm\n\nAbstract supertype for all clustering algorithm types in PortfolioOptimisers.jl.\n\nAll concrete types implementing specific clustering algorithms should subtype AbstractClusteringAlgorithm. This enables flexible extension and dispatch of clustering routines.\n\nRelated\n\nAbstractClusteringEstimator\nAbstractClusteringResult\n\n\n\n\n\n","category":"type"},{"location":"011-2-Clustering/#PortfolioOptimisers.AbstractOptimalNumberClustersEstimator","page":"Clustering","title":"PortfolioOptimisers.AbstractOptimalNumberClustersEstimator","text":"AbstractOptimalNumberClustersEstimator <: AbstractEstimator\n\nAbstract supertype for all optimal number of clusters estimator types in PortfolioOptimisers.jl.\n\nAll concrete types implementing algorithms to estimate the optimal number of clusters should subtype AbstractOptimalNumberClustersEstimator. This enables a consistent interface for cluster number estimation.\n\nRelated\n\nAbstractOptimalNumberClustersAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"011-2-Clustering/#PortfolioOptimisers.AbstractOptimalNumberClustersAlgorithm","page":"Clustering","title":"PortfolioOptimisers.AbstractOptimalNumberClustersAlgorithm","text":"AbstractOptimalNumberClustersAlgorithm <: AbstractAlgorithm\n\nAbstract supertype for all optimal number of clusters algorithm types in PortfolioOptimisers.jl.\n\nAll concrete types implementing specific algorithms for determining the optimal number of clusters should subtype AbstractOptimalNumberClustersAlgorithm. This enables flexible extension and dispatch of cluster number selection routines.\n\nRelated\n\nAbstractOptimalNumberClustersEstimator\n\n\n\n\n\n","category":"type"},{"location":"011-2-Clustering/#PortfolioOptimisers.AbstractClusteringResult","page":"Clustering","title":"PortfolioOptimisers.AbstractClusteringResult","text":"AbstractClusteringResult <: AbstractPhylogenyResult\n\nAbstract supertype for all clustering result types in PortfolioOptimisers.jl.\n\nAll concrete types representing the result of a clustering estimation should subtype AbstractClusteringResult. This enables a consistent interface for clustering results throughout the package.\n\nRelated\n\nAbstractClusteringEstimator\nAbstractClusteringAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"011-2-Clustering/#PortfolioOptimisers.HierarchicalClustering","page":"Clustering","title":"PortfolioOptimisers.HierarchicalClustering","text":"HierarchicalClustering{T1, T2, T3, T4} <: AbstractClusteringResult\n\nResult type for hierarchical clustering in PortfolioOptimisers.jl.\n\nHierarchicalClustering stores the output of a hierarchical clustering algorithm, including the clustering object, similarity and distance matrices, and the number of clusters.\n\nFields\n\nclustering: The hierarchical clustering object (e.g., Clustering.Hclust).\nS: Similarity matrix used for clustering.\nD: Distance matrix used for clustering.\nk: Number of clusters.\n\nConstructor\n\nHierarchicalClustering(; clustering::Clustering.Hclust, S::AbstractMatrix,\n                        D::AbstractMatrix, k::Integer)\n\nRelated\n\nAbstractClusteringResult\nClusteringEstimator\n\n\n\n\n\n","category":"type"},{"location":"011-2-Clustering/#PortfolioOptimisers.HierarchicalClustering-Tuple{}","page":"Clustering","title":"PortfolioOptimisers.HierarchicalClustering","text":"HierarchicalClustering(; clustering::Clustering.Hclust, S::AbstractMatrix,\n                        D::AbstractMatrix, k::Integer)\n\nConstruct a HierarchicalClustering result for hierarchical clustering.\n\nCreates a HierarchicalClustering object from the given clustering result, similarity and distance matrices, and number of clusters. Validates that the matrices are non-empty, of matching size, and that k ≥ 1.\n\nArguments\n\nclustering: The hierarchical clustering object.\nS: Similarity matrix.\nD: Distance matrix.\nk: Number of clusters.\n\nReturns\n\nHierarchicalClustering: A result object encapsulating the clustering output.\n\nValidation\n\nThrows an error if S or D are empty, if their sizes do not match, or if k < 1.\n\nRelated\n\nAbstractClusteringResult\n\n\n\n\n\n","category":"method"},{"location":"011-2-Clustering/#PortfolioOptimisers.clusterise-Tuple{PortfolioOptimisers.AbstractClusteringResult, Vararg{Any}}","page":"Clustering","title":"PortfolioOptimisers.clusterise","text":"clusterise(cle::AbstractClusteringResult, args...; kwargs...)\n\nReturn the clustering result as-is.\n\nThis function provides a generic interface for extracting or processing clustering results. By default, it simply returns the provided clustering result object unchanged. This allows for consistent downstream handling of clustering results in PortfolioOptimisers.jl workflows.\n\nArguments\n\ncle::AbstractClusteringResult: The clustering result object.\nargs...; kwargs...: Additional arguments (ignored by default).\n\nReturns\n\nThe input cle object.\n\nRelated\n\nAbstractClusteringResult\n\n\n\n\n\n","category":"method"},{"location":"011-2-Clustering/#PortfolioOptimisers.SecondOrderDifference","page":"Clustering","title":"PortfolioOptimisers.SecondOrderDifference","text":"SecondOrderDifference <: AbstractOptimalNumberClustersAlgorithm\n\nAlgorithm type for estimating the optimal number of clusters using the second-order difference method.\n\nThe SecondOrderDifference algorithm selects the optimal number of clusters by maximizing the second-order difference of a clustering evaluation metric (such as within-cluster sum of squares or silhouette score) across different cluster counts. This approach helps identify the \"elbow\" point in the metric curve.\n\nRelated\n\nAbstractOptimalNumberClustersAlgorithm\nOptimalNumberClusters\n\n\n\n\n\n","category":"type"},{"location":"011-2-Clustering/#PortfolioOptimisers.PredefinedNumberClusters","page":"Clustering","title":"PortfolioOptimisers.PredefinedNumberClusters","text":"PredefinedNumberClusters{T1} <: AbstractOptimalNumberClustersAlgorithm\n\nAlgorithm type for specifying a fixed, user-defined number of clusters.\n\nPredefinedNumberClusters allows the user to set the number of clusters directly, bypassing any automatic selection algorithm. This is useful when the desired number of clusters is known in advance or dictated by external requirements.\n\nFields\n\nk: The fixed number of clusters.\n\nConstructor\n\nPredefinedNumberClusters(; k::Integer = 1)\n\nRelated\n\nAbstractOptimalNumberClustersAlgorithm\nOptimalNumberClusters\n\n\n\n\n\n","category":"type"},{"location":"011-2-Clustering/#PortfolioOptimisers.PredefinedNumberClusters-Tuple{}","page":"Clustering","title":"PortfolioOptimisers.PredefinedNumberClusters","text":"PredefinedNumberClusters(; k::Integer = 1)\n\nConstruct a PredefinedNumberClusters algorithm with a fixed number of clusters.\n\nArguments\n\nk`: The number of clusters (must be ≥ 1).\n\nReturns\n\nPredefinedNumberClusters: An algorithm object specifying the fixed number of clusters.\n\nValidation\n\nThrows an error if k < 1.\n\nExamples\n\njulia> PredefinedNumberClusters(; k = 3)\nPredefinedNumberClusters\n  k | Int64: 3\n\nRelated\n\nPredefinedNumberClusters\n\n\n\n\n\n","category":"method"},{"location":"011-2-Clustering/#PortfolioOptimisers.StandardisedSilhouetteScore","page":"Clustering","title":"PortfolioOptimisers.StandardisedSilhouetteScore","text":"StandardisedSilhouetteScore{T1} <: AbstractOptimalNumberClustersAlgorithm\n\nAlgorithm type for estimating the optimal number of clusters using the standardised silhouette score.\n\nStandardisedSilhouetteScore selects the optimal number of clusters by maximizing the silhouette score, which measures how well each object lies within its cluster compared to other clusters. The score can be computed using different distance metrics.\n\nFields\n\nmetric: The distance metric used for silhouette calculation (e.g., from Distances.jl), or nothing for the default.\n\nConstructor\n\nPredefinedNumberClusters(; k::Integer = 1)\n\nRelated\n\nAbstractOptimalNumberClustersAlgorithm\nOptimalNumberClusters\n\n\n\n\n\n","category":"type"},{"location":"011-2-Clustering/#PortfolioOptimisers.StandardisedSilhouetteScore-Tuple{}","page":"Clustering","title":"PortfolioOptimisers.StandardisedSilhouetteScore","text":"StandardisedSilhouetteScore(; metric::Union{Nothing, <:Distances.SemiMetric} = nothing)\n\nConstruct a StandardisedSilhouetteScore algorithm for optimal cluster number selection.\n\nArguments\n\nmetric: The distance metric to use for silhouette calculation (optional). If nothing, the default metric is used.\n\nReturns\n\nStandardisedSilhouetteScore: An algorithm object for silhouette-based cluster selection.\n\nExamples\n\njulia> StandardisedSilhouetteScore()\nStandardisedSilhouetteScore\n  metric | nothing\n\nRelated\n\nStandardisedSilhouetteScore\n\n\n\n\n\n","category":"method"},{"location":"011-2-Clustering/#PortfolioOptimisers.OptimalNumberClusters","page":"Clustering","title":"PortfolioOptimisers.OptimalNumberClusters","text":"OptimalNumberClusters{T1, T2} <: AbstractOptimalNumberClustersEstimator\n\nEstimator type for selecting the optimal number of clusters in PortfolioOptimisers.jl.\n\nOptimalNumberClusters encapsulates the configuration for determining the optimal number of clusters, including the maximum allowed clusters and the algorithm used for selection.\n\nFields\n\nmax_k: Maximum number of clusters to consider (can be nothing for no limit).\nalg: Algorithm for selecting the optimal number of clusters (e.g., SecondOrderDifference, StandardisedSilhouetteScore, PredefinedNumberClusters).\n\nConstructor\n\nOptimalNumberClusters(; max_k::Union{Nothing, <:Integer} = nothing,\n                      alg::AbstractOptimalNumberClustersAlgorithm = SecondOrderDifference())\n\nRelated\n\nAbstractOptimalNumberClustersEstimator\nAbstractOptimalNumberClustersAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"011-2-Clustering/#PortfolioOptimisers.OptimalNumberClusters-Tuple{}","page":"Clustering","title":"PortfolioOptimisers.OptimalNumberClusters","text":"OptimalNumberClusters(; max_k::Union{Nothing, <:Integer} = nothing,\n                      alg::AbstractOptimalNumberClustersAlgorithm = SecondOrderDifference())\n\nConstruct an OptimalNumberClusters estimator for optimal cluster number selection.\n\nArguments\n\nmax_k: Maximum number of clusters to consider. If nothing, defaults to ceil(Int, sqrt(N)), where N is the number of assets.\nalg: Algorithm for selecting the optimal number of clusters.\n\nReturns\n\nOptimalNumberClusters: An estimator object for optimal cluster number selection.\n\nValidation\n\nThrows an error if max_k is provided and less than 1.\n\nExamples\n\njulia> OptimalNumberClusters(; max_k = 10)\nOptimalNumberClusters\n  max_k | Int64: 10\n    alg | SecondOrderDifference()\n\nRelated\n\nOptimalNumberClusters\n\n\n\n\n\n","category":"method"},{"location":"011-2-Clustering/#PortfolioOptimisers.HClustAlgorithm","page":"Clustering","title":"PortfolioOptimisers.HClustAlgorithm","text":"HClustAlgorithm{T1} <: AbstractClusteringAlgorithm\n\nAlgorithm type for hierarchical clustering in PortfolioOptimisers.jl.\n\nHClustAlgorithm specifies the linkage method used for hierarchical clustering, such as :ward, :single, :complete, or :average.\n\nFields\n\nlinkage: Linkage method for hierarchical clustering from Clustering.jl.\n\nConstructor\n\nHClustAlgorithm(; linkage::Symbol = :ward)\n\nRelated\n\nAbstractClusteringAlgorithm\nClusteringEstimator\n\n\n\n\n\n","category":"type"},{"location":"011-2-Clustering/#PortfolioOptimisers.HClustAlgorithm-Tuple{}","page":"Clustering","title":"PortfolioOptimisers.HClustAlgorithm","text":"HClustAlgorithm(; linkage::Symbol = :ward)\n\nConstruct an HClustAlgorithm for hierarchical clustering.\n\nArguments\n\nlinkage: Linkage method to use for hierarchical clustering from Clustering.jl.\n\nReturns\n\nHClustAlgorithm: An algorithm object for hierarchical clustering.\n\nExamples\n\njulia> HClustAlgorithm(; linkage = :average)\nHClustAlgorithm\n  linkage | Symbol: :average\n\nRelated\n\nHClustAlgorithm\n\n\n\n\n\n","category":"method"},{"location":"011-2-Clustering/#PortfolioOptimisers.ClusteringEstimator","page":"Clustering","title":"PortfolioOptimisers.ClusteringEstimator","text":"ClusteringEstimator{T1, T2, T3, T4} <: AbstractClusteringEstimator\n\nEstimator type for clustering in PortfolioOptimisers.jl.\n\nClusteringEstimator encapsulates all configuration required for clustering, including the covariance estimator, distance estimator, clustering algorithm, and optimal number of clusters estimator.\n\nFields\n\nce: Covariance estimator.\nde: Distance estimator.\nalg: Clustering algorithm.\nonc: Optimal number of clusters estimator.\n\nConstructor\n\nClusteringEstimator(; ce::StatsBase.CovarianceEstimator = PortfolioOptimisersCovariance(),\n                     de::AbstractDistanceEstimator = Distance(alg = CanonicalDistance()),\n                     alg::AbstractClusteringAlgorithm = HClustAlgorithm(),\n                     onc::AbstractOptimalNumberClustersEstimator = OptimalNumberClusters())\n\nRelated\n\nAbstractClusteringEstimator\nAbstractClusteringAlgorithm\nAbstractOptimalNumberClustersEstimator\n\n\n\n\n\n","category":"type"},{"location":"011-2-Clustering/#PortfolioOptimisers.ClusteringEstimator-Tuple{}","page":"Clustering","title":"PortfolioOptimisers.ClusteringEstimator","text":"ClusteringEstimator(; ce::StatsBase.CovarianceEstimator = PortfolioOptimisersCovariance(),\n                     de::AbstractDistanceEstimator = Distance(alg = CanonicalDistance()),\n                     alg::AbstractClusteringAlgorithm = HClustAlgorithm(),\n                     onc::AbstractOptimalNumberClustersEstimator = OptimalNumberClusters())\n\nConstruct a ClusteringEstimator for clustering.\n\nCreates a clustering estimator using the specified covariance estimator, distance estimator, clustering algorithm, and optimal number of clusters estimator.\n\nArguments\n\nce: Covariance estimator.\nde: Distance estimator.\nalg: Clustering algorithm.\nonc: Optimal number of clusters estimator.\n\nReturns\n\nClusteringEstimator: An estimator object for clustering.\n\nExamples\n\njulia> ClusteringEstimator()\nClusteringEstimator\n   ce | PortfolioOptimisersCovariance\n      |   ce | Covariance\n      |      |    me | SimpleExpectedReturns\n      |      |       |   w | nothing\n      |      |    ce | GeneralWeightedCovariance\n      |      |       |   ce | StatsBase.SimpleCovariance: StatsBase.SimpleCovariance(true)\n      |      |       |    w | nothing\n      |      |   alg | Full()\n      |   mp | DefaultMatrixProcessing\n      |      |       pdm | Posdef\n      |      |           |   alg | UnionAll: NearestCorrelationMatrix.Newton\n      |      |   denoise | nothing\n      |      |    detone | nothing\n      |      |       alg | nothing\n   de | Distance\n      |   alg | CanonicalDistance()\n  alg | HClustAlgorithm\n      |   linkage | Symbol: :ward\n  onc | OptimalNumberClusters\n      |   max_k | nothing\n      |     alg | SecondOrderDifference()\n\nRelated\n\nClusteringEstimator\n\n\n\n\n\n","category":"method"},{"location":"007-01-Moments/#Base-Moments","page":"Base Moments","title":"Base Moments","text":"","category":"section"},{"location":"007-01-Moments/#PortfolioOptimisers.Full","page":"Base Moments","title":"PortfolioOptimisers.Full","text":"Full <: AbstractMomentAlgorithm\n\nFull is used to indicate that all available data points are included in the moment estimation process.\n\nRelated\n\nAbstractMomentAlgorithm\nSemi\n\n\n\n\n\n","category":"type"},{"location":"007-01-Moments/#PortfolioOptimisers.Semi","page":"Base Moments","title":"PortfolioOptimisers.Semi","text":"Semi <: AbstractMomentAlgorithm\n\nSemi is used for semi-moment estimators, where only observations below the mean (i.e., negative deviations) are considered.\n\nRelated\n\nAbstractMomentAlgorithm\nFull\n\n\n\n\n\n","category":"type"},{"location":"007-01-Moments/#PortfolioOptimisers.AbstractExpectedReturnsEstimator","page":"Base Moments","title":"PortfolioOptimisers.AbstractExpectedReturnsEstimator","text":"AbstractExpectedReturnsEstimator <: AbstractEstimator\n\nAbstract supertype for all expected returns estimator types in PortfolioOptimisers.jl.\n\nAll concrete types that implement expected returns estimation (e.g., sample mean, Bayesian estimators) should subtype AbstractExpectedReturnsEstimator. This enables a consistent interface for expected returns estimation routines throughout the package.\n\nRelated\n\nAbstractEstimator\nAbstractExpectedReturnsAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"007-01-Moments/#PortfolioOptimisers.AbstractExpectedReturnsAlgorithm","page":"Base Moments","title":"PortfolioOptimisers.AbstractExpectedReturnsAlgorithm","text":"AbstractExpectedReturnsAlgorithm <: AbstractAlgorithm\n\nAbstract supertype for all expected returns algorithm types in PortfolioOptimisers.jl.\n\nAll concrete types that implement a specific algorithm for expected returns estimation (e.g., shrinkage, robust mean) should subtype AbstractExpectedReturnsAlgorithm. This allows for flexible extension and dispatch of expected returns estimation routines.\n\nRelated\n\nAbstractAlgorithm\nAbstractExpectedReturnsEstimator\n\n\n\n\n\n","category":"type"},{"location":"007-01-Moments/#PortfolioOptimisers.AbstractCovarianceEstimator","page":"Base Moments","title":"PortfolioOptimisers.AbstractCovarianceEstimator","text":"AbstractCovarianceEstimator <: StatsBase.CovarianceEstimator\n\nAbstract supertype for all covariance estimator types in PortfolioOptimisers.jl.\n\nAll concrete types that implement covariance estimation (e.g., sample covariance, shrinkage estimators) should subtype AbstractCovarianceEstimator. This enables a consistent interface for covariance estimation routines throughout the package.\n\nRelated\n\nStatsBase.CovarianceEstimator\nAbstractMomentAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"007-01-Moments/#PortfolioOptimisers.AbstractMomentAlgorithm","page":"Base Moments","title":"PortfolioOptimisers.AbstractMomentAlgorithm","text":"AbstractMomentAlgorithm <: AbstractAlgorithm\n\nAbstract supertype for all moment algorithm types in PortfolioOptimisers.jl.\n\nAll concrete types that implement a specific algorithm for moment estimation (e.g., full, semi) should subtype AbstractMomentAlgorithm. This allows for flexible extension and dispatch of moment estimation routines.\n\nRelated\n\nAbstractAlgorithm\nAbstractCovarianceEstimator\n\n\n\n\n\n","category":"type"},{"location":"007-01-Moments/#PortfolioOptimisers.AbstractVarianceEstimator","page":"Base Moments","title":"PortfolioOptimisers.AbstractVarianceEstimator","text":"AbstractVarianceEstimator <: AbstractCovarianceEstimator\n\nAbstract supertype for all variance estimator types in PortfolioOptimisers.jl.\n\nAll concrete types that implement variance estimation (e.g., sample variance, robust variance estimators) should subtype AbstractVarianceEstimator. This enables a consistent interface for variance estimation routines and allows for flexible extension and dispatch within the package.\n\nRelated\n\nAbstractCovarianceEstimator\n\n\n\n\n\n","category":"type"},{"location":"007-01-Moments/#PortfolioOptimisers.robust_cov","page":"Base Moments","title":"PortfolioOptimisers.robust_cov","text":"robust_cov(ce::StatsBase.CovarianceEstimator, X::AbstractMatrix, [w::AbstractWeights]; dims::Int = 1, mean = nothing, kwargs...)\n\nCompute the covariance matrix robustly using the specified covariance estimator ce, data matrix X, and optional weights vector w.\n\nThis function attempts to compute the weighted covariance matrix using the provided estimator and keyword arguments. If an error occurs (e.g., due to unsupported keyword arguments), it retries with a reduced set of arguments for compatibility. This ensures robust weighted covariance estimation across different estimator types and StatsBase versions.\n\nArguments\n\nce: Covariance estimator to use.\nX: Data matrix.\nw: Optional weights for each observation.\ndims: Dimension along which to compute the covariance.\nmean: Optional mean array to use for centering.\nkwargs...: Additional keyword arguments passed to cov.\n\nReturns\n\nCovariance matrix as computed by the estimator and optional weights.\n\nRelated\n\nrobust_cor\nStatistics.cov\n\n\n\n\n\n","category":"function"},{"location":"007-01-Moments/#PortfolioOptimisers.robust_cor","page":"Base Moments","title":"PortfolioOptimisers.robust_cor","text":"robust_cor(ce::StatsBase.CovarianceEstimator, X::AbstractMatrix, [w::AbstractWeights]; dims::Int = 1, mean = nothing, kwargs...)\n\nCompute the correlation matrix robustly using the specified covariance estimator ce, data matrix X, and optional weights vector w.\n\nThis function attempts to compute the weighted correlation matrix using the provided estimator and keyword arguments. If an error occurs, it falls back to computing the weighted covariance matrix and then converts it to a correlation matrix. This ensures robust weighted correlation estimation across different estimator types and StatsBase versions.\n\nArguments\n\nce: Covariance estimator to use.\nX: Data matrix.\nw: Optional weights for each observation.\ndims: Dimension along which to compute the correlation.\nmean: Optional mean array to use for centering.\nkwargs...: Additional keyword arguments passed to cor.\n\nReturns\n\nCorrelation matrix as computed by the estimator and optional weights.\n\nRelated\n\nrobust_cov\nStatistics.cor\n\n\n\n\n\n","category":"function"},{"location":"007-13-Moments/#Shrunk-Expected-Returns","page":"Shrunk Expected Returns","title":"Shrunk Expected Returns","text":"","category":"section"},{"location":"007-13-Moments/#PortfolioOptimisers.AbstractShrunkExpectedReturnsEstimator","page":"Shrunk Expected Returns","title":"PortfolioOptimisers.AbstractShrunkExpectedReturnsEstimator","text":"abstract type AbstractShrunkExpectedReturnsEstimator <: AbstractExpectedReturnsEstimator end\n\nAbstract supertype for all shrunk expected returns estimators in PortfolioOptimisers.jl.\n\nAll concrete types implementing shrinkage-based expected returns estimation algorithms should subtype AbstractShrunkExpectedReturnsEstimator. This enables a consistent interface for shrinkage estimators throughout the package.\n\nRelated\n\nShrunkExpectedReturns\nAbstractExpectedReturnsEstimator\n\n\n\n\n\n","category":"type"},{"location":"007-13-Moments/#PortfolioOptimisers.AbstractShrunkExpectedReturnsAlgorithm","page":"Shrunk Expected Returns","title":"PortfolioOptimisers.AbstractShrunkExpectedReturnsAlgorithm","text":"abstract type AbstractShrunkExpectedReturnsAlgorithm <: AbstractExpectedReturnsAlgorithm end\n\nAbstract supertype for all shrinkage algorithms for expected returns estimation.\n\nAll concrete types implementing specific shrinkage algorithms (e.g., James-Stein, Bayes-Stein) should subtype AbstractShrunkExpectedReturnsAlgorithm. This enables flexible extension and dispatch of shrinkage routines.\n\nRelated\n\nJamesStein\nBayesStein\nBodnarOkhrinParolya\nAbstractExpectedReturnsAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"007-13-Moments/#PortfolioOptimisers.AbstractShrunkExpectedReturnsTarget","page":"Shrunk Expected Returns","title":"PortfolioOptimisers.AbstractShrunkExpectedReturnsTarget","text":"abstract type AbstractShrunkExpectedReturnsTarget <: AbstractExpectedReturnsAlgorithm end\n\nAbstract supertype for all shrinkage targets used in expected returns estimation.\n\nConcrete types implementing specific shrinkage targets (e.g., grand mean, volatility-weighted mean) should subtype AbstractShrunkExpectedReturnsTarget. This enables modular selection of shrinkage targets in shrinkage algorithms.\n\nRelated\n\nGrandMean\nVolatilityWeighted\nMeanSquareError\n\n\n\n\n\n","category":"type"},{"location":"007-13-Moments/#PortfolioOptimisers.GrandMean","page":"Shrunk Expected Returns","title":"PortfolioOptimisers.GrandMean","text":"struct GrandMean <: AbstractShrunkExpectedReturnsTarget end\n\nShrinkage target representing the grand mean of expected returns.\n\nGrandMean computes the shrinkage target as the mean of all asset expected returns, resulting in a vector where each element is the same grand mean value. This is commonly used in shrinkage estimators to reduce estimation error by pulling individual expected returns toward the overall average.\n\nRelated\n\nAbstractShrunkExpectedReturnsTarget\nShrunkExpectedReturns\n\n\n\n\n\n","category":"type"},{"location":"007-13-Moments/#PortfolioOptimisers.VolatilityWeighted","page":"Shrunk Expected Returns","title":"PortfolioOptimisers.VolatilityWeighted","text":"struct VolatilityWeighted <: AbstractShrunkExpectedReturnsTarget end\n\nShrinkage target representing the volatility-weighted mean of expected returns.\n\nVolatilityWeighted computes the shrinkage target as a weighted mean of expected returns, where weights are inversely proportional to asset volatility (from the inverse covariance matrix). This approach accounts for differences in asset risk when estimating the shrinkage target.\n\nRelated\n\nAbstractShrunkExpectedReturnsTarget\nShrunkExpectedReturns\n\n\n\n\n\n","category":"type"},{"location":"007-13-Moments/#PortfolioOptimisers.MeanSquareError","page":"Shrunk Expected Returns","title":"PortfolioOptimisers.MeanSquareError","text":"struct MeanSquareError <: AbstractShrunkExpectedReturnsTarget end\n\nShrinkage target representing the mean squared error of expected returns.\n\nMeanSquareError computes the shrinkage target as the trace of the covariance matrix divided by the number of observations, resulting in a vector where each element is the same value. This target is useful for certain shrinkage estimators that minimize mean squared error.\n\nRelated\n\nAbstractShrunkExpectedReturnsTarget\nShrunkExpectedReturns\n\n\n\n\n\n","category":"type"},{"location":"007-13-Moments/#PortfolioOptimisers.JamesStein","page":"Shrunk Expected Returns","title":"PortfolioOptimisers.JamesStein","text":"struct JamesStein{T1} <: AbstractShrunkExpectedReturnsAlgorithm\n    target::T1\nend\n\nShrinkage algorithm implementing the James-Stein estimator for expected returns.\n\nJamesStein applies shrinkage to asset expected returns by pulling them toward a specified target (e.g., grand mean, volatility-weighted mean). The estimator reduces estimation error, especially in high-dimensional settings.\n\nFields\n\ntarget: The shrinkage target type.\n\nConstructor\n\nJamesStein(; target::AbstractShrunkExpectedReturnsTarget = GrandMean())\n\nConstruct a JamesStein shrinkage algorithm with the specified target.\n\nRelated\n\nAbstractShrunkExpectedReturnsAlgorithm\nAbstractShrunkExpectedReturnsTarget\nBayesStein\nBodnarOkhrinParolya\n\n\n\n\n\n","category":"type"},{"location":"007-13-Moments/#PortfolioOptimisers.JamesStein-Tuple{}","page":"Shrunk Expected Returns","title":"PortfolioOptimisers.JamesStein","text":"JamesStein(; target::AbstractShrunkExpectedReturnsTarget = GrandMean())\n\nConstruct a JamesStein shrinkage algorithm for expected returns estimation.\n\nArguments\n\ntarget: The shrinkage target.\n\nReturns\n\nJamesStein: Configured James-Stein shrinkage algorithm.\n\nExamples\n\njulia> JamesStein()\nJamesStein\n  target | GrandMean()\n\nRelated\n\nAbstractShrunkExpectedReturnsTarget\nJamesStein\nBayesStein\nBodnarOkhrinParolya\n\n\n\n\n\n","category":"method"},{"location":"007-13-Moments/#PortfolioOptimisers.BayesStein","page":"Shrunk Expected Returns","title":"PortfolioOptimisers.BayesStein","text":"struct BayesStein{T1} <: AbstractShrunkExpectedReturnsAlgorithm\n    target::T1\nend\n\nShrinkage algorithm implementing the Bayes-Stein estimator for expected returns.\n\nBayesStein applies shrinkage to asset expected returns by pulling them toward a specified target (e.g., grand mean, volatility-weighted mean) using Bayesian principles. This estimator is useful for reducing estimation error, especially when sample sizes are small.\n\nFields\n\ntarget: The shrinkage target type.\n\nConstructor\n\nBayesStein(; target::AbstractShrunkExpectedReturnsTarget = GrandMean())\n\nConstruct a BayesStein shrinkage algorithm with the specified target.\n\nRelated\n\nAbstractShrunkExpectedReturnsAlgorithm\nAbstractShrunkExpectedReturnsTarget\nJamesStein\nBodnarOkhrinParolya\n\n\n\n\n\n","category":"type"},{"location":"007-13-Moments/#PortfolioOptimisers.BayesStein-Tuple{}","page":"Shrunk Expected Returns","title":"PortfolioOptimisers.BayesStein","text":"BayesStein(; target::AbstractShrunkExpectedReturnsTarget = GrandMean())\n\nConstruct a BayesStein shrinkage algorithm for expected returns estimation.\n\nArguments\n\ntarget: The shrinkage target.\n\nReturns\n\nBayesStein: Configured Bayes-Stein shrinkage algorithm.\n\nExamples\n\njulia> BayesStein()\nBayesStein\n  target | GrandMean()\n\nRelated\n\nAbstractShrunkExpectedReturnsTarget\nJamesStein\nBayesStein\nBodnarOkhrinParolya\n\n\n\n\n\n","category":"method"},{"location":"007-13-Moments/#PortfolioOptimisers.BodnarOkhrinParolya","page":"Shrunk Expected Returns","title":"PortfolioOptimisers.BodnarOkhrinParolya","text":"struct BodnarOkhrinParolya{T1} <: AbstractShrunkExpectedReturnsAlgorithm\n    target::T1\nend\n\nShrinkage algorithm implementing the Bodnar-Okhrin-Parolya estimator for expected returns.\n\nBodnarOkhrinParolya applies shrinkage to asset expected returns by pulling them toward a specified target (e.g., grand mean, volatility-weighted mean) using the Bodnar-Okhrin-Parolya approach. This estimator is designed for robust estimation in high-dimensional settings.\n\nFields\n\ntarget: The shrinkage target type.\n\nConstructor\n\nBodnarOkhrinParolya(; target::AbstractShrunkExpectedReturnsTarget = GrandMean())\n\nConstruct a BodnarOkhrinParolya shrinkage algorithm with the specified target.\n\nRelated\n\nAbstractShrunkExpectedReturnsAlgorithm\nAbstractShrunkExpectedReturnsTarget\nJamesStein\nBayesStein\n\n\n\n\n\n","category":"type"},{"location":"007-13-Moments/#PortfolioOptimisers.BodnarOkhrinParolya-Tuple{}","page":"Shrunk Expected Returns","title":"PortfolioOptimisers.BodnarOkhrinParolya","text":"BodnarOkhrinParolya(; target::AbstractShrunkExpectedReturnsTarget = GrandMean())\n\nConstruct a BodnarOkhrinParolya shrinkage algorithm for expected returns estimation.\n\nArguments\n\ntarget: The shrinkage target.\n\nReturns\n\nBodnarOkhrinParolya: Configured Bodnar-Okhrin-Parolya shrinkage algorithm.\n\nExamples\n\njulia> BodnarOkhrinParolya()\nBodnarOkhrinParolya\n  target | GrandMean()\n\nRelated\n\nAbstractShrunkExpectedReturnsTarget\nJamesStein\nBayesStein\nBodnarOkhrinParolya\n\n\n\n\n\n","category":"method"},{"location":"007-13-Moments/#PortfolioOptimisers.ShrunkExpectedReturns","page":"Shrunk Expected Returns","title":"PortfolioOptimisers.ShrunkExpectedReturns","text":"struct ShrunkExpectedReturns{T1, T2, T3} <: AbstractShrunkExpectedReturnsEstimator\n    me::T1\n    ce::T2\n    alg::T3\nend\n\nContainer type for shrinkage-based expected returns estimators.\n\nShrunkExpectedReturns encapsulates all components required for shrinkage estimation of expected returns, including the mean estimator, covariance estimator, and shrinkage algorithm. This enables modular and extensible workflows for robust expected returns estimation using shrinkage techniques.\n\nFields\n\nme: Mean estimator for expected returns.\nce: Covariance estimator.\nalg: Shrinkage algorithm (e.g., James-Stein, Bayes-Stein).\n\nConstructor\n\nShrunkExpectedReturns(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns(),\n                       ce::StatsBase.CovarianceEstimator = PortfolioOptimisersCovariance(),\n                       alg::AbstractShrunkExpectedReturnsAlgorithm = JamesStein())\n\nConstruct a ShrunkExpectedReturns estimator with the specified mean estimator, covariance estimator, and shrinkage algorithm.\n\nRelated\n\nAbstractShrunkExpectedReturnsEstimator\nAbstractExpectedReturnsEstimator\nStatsBase.CovarianceEstimator\nAbstractShrunkExpectedReturnsAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"007-13-Moments/#PortfolioOptimisers.ShrunkExpectedReturns-Tuple{}","page":"Shrunk Expected Returns","title":"PortfolioOptimisers.ShrunkExpectedReturns","text":"ShrunkExpectedReturns(; me::AbstractExpectedReturnsEstimator = SimpleExpectedReturns(),\n                       ce::StatsBase.CovarianceEstimator = PortfolioOptimisersCovariance(),\n                       alg::AbstractShrunkExpectedReturnsAlgorithm = JamesStein())\n\nConstruct a ShrunkExpectedReturns estimator for shrinkage-based expected returns estimation.\n\nArguments\n\nme: Mean estimator for expected returns.\nce: Covariance estimator.\nalg: Shrinkage algorithm.\n\nReturns\n\nShrunkExpectedReturns: Configured shrinkage-based expected returns estimator.\n\nExamples\n\njulia> ShrunkExpectedReturns()\nShrunkExpectedReturns\n   me | SimpleExpectedReturns\n      |   w | nothing\n   ce | PortfolioOptimisersCovariance\n      |   ce | Covariance\n      |      |    me | SimpleExpectedReturns\n      |      |       |   w | nothing\n      |      |    ce | GeneralWeightedCovariance\n      |      |       |   ce | StatsBase.SimpleCovariance: StatsBase.SimpleCovariance(true)\n      |      |       |    w | nothing\n      |      |   alg | Full()\n      |   mp | DefaultMatrixProcessing\n      |      |       pdm | Posdef\n      |      |           |   alg | UnionAll: NearestCorrelationMatrix.Newton\n      |      |   denoise | nothing\n      |      |    detone | nothing\n      |      |       alg | nothing\n  alg | JamesStein\n      |   target | GrandMean()\n\nRelated\n\nAbstractExpectedReturnsEstimator\nStatsBase.CovarianceEstimator\nAbstractShrunkExpectedReturnsAlgorithm\nShrunkExpectedReturns\n\n\n\n\n\n","category":"method"},{"location":"007-13-Moments/#PortfolioOptimisers.target_mean","page":"Shrunk Expected Returns","title":"PortfolioOptimisers.target_mean","text":"target_mean(::AbstractShrunkExpectedReturnsTarget, mu::AbstractArray, sigma::AbstractMatrix; kwargs...)\n\nCompute the shrinkage target vector for expected returns estimation.\n\ntarget_mean calculates the target vector toward which expected returns are shrunk, based on the specified shrinkage target type. This function is used internally by shrinkage estimators such as James-Stein, Bayes-Stein, and Bodnar-Okhrin-Parolya.\n\nArguments\n\ntarget::GrandMean: ReturnsResult a vector filled with the mean of mu.\ntarget::VolatilityWeighted: ReturnsResult a vector filled with the volatility-weighted mean of mu, using the inverse covariance matrix.\ntarget::MeanSquareError: ReturnsResult a vector filled with the trace of sigma divided by T.\nmu: 1D array of expected returns.\nsigma: Covariance matrix of asset returns.\nkwargs...: Additional keyword arguments, such as T (number of observations) or isigma (inverse covariance matrix).\n\nReturns\n\nb::AbstractArray: Target vector for shrinkage estimation.\n\nRelated\n\nGrandMean\nVolatilityWeighted\nMeanSquareError\nShrunkExpectedReturns\n\n\n\n\n\n","category":"function"},{"location":"007-13-Moments/#Statistics.mean-Tuple{ShrunkExpectedReturns{<:Any, <:Any, <:JamesStein}, AbstractMatrix}","page":"Shrunk Expected Returns","title":"Statistics.mean","text":"mean(me::ShrunkExpectedReturns, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute shrunk expected returns using the specified estimator.\n\nThis method applies a shrinkage algorithm to the sample expected returns, pulling them toward a specified target to reduce estimation error, especially in high-dimensional settings.\n\nArguments\n\nme::ShrunkExpectedReturns{<:Any, <:Any, <:JamesStein}: Use the James-Stein algorithm.\nme::ShrunkExpectedReturns{<:Any, <:Any, <:BayesStein}: Use the Bayes-Stein algorithm.\nme::ShrunkExpectedReturns{<:Any, <:Any, <:BodnarOkhrinParolya}: Use the Bodnar-Okhrin-Parolya algorithm.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute the mean.\nkwargs...: Additional keyword arguments passed to the mean and covariance estimators.\n\nReturns\n\nmu::AbstractArray: Shrunk expected returns vector.\n\nDetails\n\nComputes the sample mean and covariance.\nComputes the shrinkage target using target_mean.\nComputes the shrinkage intensity alpha with:\nJamesStein: the centered mean and eigenvalues of the covariance matrix.\nBayesStein: a Bayesian formula involving the centered mean and inverse covariance.\nBodnarOkhrinParolya: a Bayesian formula involving the target mean, mean and inverse covariance.\nReturnsResult the shrunk mean vector.\n\nRelated\n\nJamesStein\nBayesStein\nBodnarOkhrinParolya\nShrunkExpectedReturns\ntarget_mean\n\n\n\n\n\n","category":"method"},{"location":"090-contributing/#contributing","page":"Contributing guidelines","title":"Contributing guidelines","text":"","category":"section"},{"location":"090-contributing/","page":"Contributing guidelines","title":"Contributing guidelines","text":"First of all, thanks for the interest!","category":"page"},{"location":"090-contributing/","page":"Contributing guidelines","title":"Contributing guidelines","text":"We welcome all kinds of contribution, including, but not limited to code, documentation, examples, configuration, issue creating, etc.","category":"page"},{"location":"090-contributing/","page":"Contributing guidelines","title":"Contributing guidelines","text":"Be polite and respectful, and follow the code of conduct.","category":"page"},{"location":"090-contributing/#Bug-reports-and-discussions","page":"Contributing guidelines","title":"Bug reports and discussions","text":"","category":"section"},{"location":"090-contributing/","page":"Contributing guidelines","title":"Contributing guidelines","text":"If you think you found a bug, feel free to open an issue. Focused suggestions and requests can also be opened as issues. Before opening a pull request, start an issue or a discussion on the topic, please.","category":"page"},{"location":"090-contributing/#Working-on-an-issue","page":"Contributing guidelines","title":"Working on an issue","text":"","category":"section"},{"location":"090-contributing/","page":"Contributing guidelines","title":"Contributing guidelines","text":"If you found an issue that interests you, comment on that issue what your plans are. If the solution to the issue is clear, you can immediately create a pull request (see below). Otherwise, say what your proposed solution is and wait for a discussion around it.","category":"page"},{"location":"090-contributing/","page":"Contributing guidelines","title":"Contributing guidelines","text":"tip: Tip\nFeel free to ping us after a few days if there are no responses.","category":"page"},{"location":"090-contributing/","page":"Contributing guidelines","title":"Contributing guidelines","text":"If your solution involves code (or something that requires running the package locally), check the developer documentation. Otherwise, you can use the GitHub interface directly to create your pull request.","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"The source files for all examples can be found in /examples.","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/#Example-2:-MeanRisk-objectives","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"","category":"section"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"In this example we will show the different objective functions available in MeanRisk, and compare them to a benchmark.","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"using PortfolioOptimisers, PrettyTables\n# Format for pretty tables.\ntsfmt = (v, i, j) -> begin\n    if j == 1\n        return Date(v)\n    else\n        return v\n    end\nend;\nresfmt = (v, i, j) -> begin\n    if j == 1\n        return v\n    else\n        return isa(v, Number) ? \"$(round(v*100, digits=3)) %\" : v\n    end\nend;\nnothing #hide","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/#1.-ReturnsResult-data","page":"Example 2: MeanRisk objectives","title":"1. ReturnsResult data","text":"","category":"section"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"We will use the same data as the previous example.","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"using CSV, TimeSeries, DataFrames\n\nX = TimeArray(CSV.File(joinpath(@__DIR__, \"SP500.csv.gz\")); timestamp = :Date)[(end - 252):end]\npretty_table(X[(end - 5):end]; formatters = tsfmt)\n\n# Compute the returns\nrd = prices_to_returns(X)","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/#2.-MeanRisk-objectives","page":"Example 2: MeanRisk objectives","title":"2. MeanRisk objectives","text":"","category":"section"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"Here we will show the different objective functions available in MeanRisk. We will also use the semi-standard deviation risk measure.","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"using Clarabel\nslv = Solver(; name = :clarabel1, solver = Clarabel.Optimizer,\n             settings = Dict(\"verbose\" => false),\n             check_sol = (; allow_local = true, allow_almost = true))","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"Here we encounter another consequence of the design philosophy of PortfolioOptimisers. An entire class of risk measures can be categorised and consistently implemented as LowOrderMoment risk measures with different internal algorithms. This corresponds to the semi-standard deviation.","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"r = LowOrderMoment(;\n                   alg = LowOrderDeviation(;\n                                           alg = SecondLowerMoment(; alg = SqrtRiskExpr())))","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"Since we will perform various optimisations on the same data, there's no need to redo work. Lets precompute the prior statistics using the EmpiricalPrior to avoid recomputing them every time we call the optimisation.","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"pr = prior(EmpiricalPrior(), rd)","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"We can provide the prior result to JuMPOptimiser.","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"opt = JuMPOptimiser(; pe = pr, slv = slv)","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"Here we define the estimators for different objective functions.","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"# Minimum risk\nmr1 = MeanRisk(; r = r, obj = MinimumRisk(), opt = opt)\n# Maximum utility with risk aversion parameter 2\nmr2 = MeanRisk(; r = r, obj = MaximumUtility(), opt = opt)\n# Risk-free rate of 4.2/100/252\nrf = 4.2 / 100 / 252\nmr3 = MeanRisk(; r = r, obj = MaximumRatio(; rf = rf), opt = opt)\n# Maximum return\nmr4 = MeanRisk(; r = r, obj = MaximumReturn(), opt = opt)","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"Lets perform the optimisations, but since we've precomputed the prior statistics, we do not need to provide the returns data. We will also produce a benchmark using the InverseVolatility estimator.","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"res1 = optimise!(mr1)\nres2 = optimise!(mr2)\nres3 = optimise!(mr3)\nres4 = optimise!(mr4)\nres0 = optimise!(InverseVolatility(; pe = pr))","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"Lets view the results as pretty tables.","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"pretty_table(DataFrame(; :assets => rd.nx, :benchmark => res0.w, :MinimumRisk => res1.w,\n                       :MaximumUtility => res2.w, :MaximumRatio => res3.w,\n                       :MaximumReturn => res4.w); formatters = resfmt)","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"In order to confirm that the objective functions do what they say on the tin, we can compute the risk, return and risk return ration. There are individual functions for each expected_risk, expected_return, expected_ratio, but we also have expected_risk_ret_ratio that returns all three at once (risk, return, risk-return ratio) which is what we will use here.","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"Due to the fact that we provide different expected portfolio return measures, any function that computes the expected portfolio return also needs to know which return type to compute. We will be consistent with the returns we used in the optimisation.","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"rk1, rt1, rr1 = expected_risk_ret_ratio(r, res1.ret, res1.w, res1.pr; rf = rf);\nrk2, rt2, rr2 = expected_risk_ret_ratio(r, res2.ret, res2.w, res2.pr; rf = rf);\nrk3, rt3, rr3 = expected_risk_ret_ratio(r, res3.ret, res3.w, res3.pr; rf = rf);\nrk4, rt4, rr4 = expected_risk_ret_ratio(r, res4.ret, res4.w, res4.pr; rf = rf);\nrk0, rt0, rr0 = expected_risk_ret_ratio(r, ArithmeticReturn(), res0.w, res0.pr; rf = rf);\nnothing #hide","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"Lets make sure the results are what we expect.","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"pretty_table(DataFrame(;\n                       :obj => [:MinimumRisk, :MaximumUtility, :MaximumRatio,\n                                :MaximumReturn, :Benchmark],\n                       :rk => [rk1, rk2, rk3, rk4, rk0], :rt => [rt1, rt2, rt3, rt4, rt0],\n                       :rr => [rr1, rr2, rr3, rr4, rr0]); formatters = resfmt)","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"We can seee that indeed, the minimum risk produces the portfolio with minimum risk, the maximum ratio produces the portfolio with the maximum risk-return ratio, and the maximum return portfolio produces the portfolio with the maximum return.","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"","category":"page"},{"location":"examples/2-Mean-Risk-Objectives/","page":"Example 2: MeanRisk objectives","title":"Example 2: MeanRisk objectives","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"The source files for all examples can be found in /examples.","category":"page"},{"location":"examples/3-Efficient-Frontier/#Example-3:-Efficient-frontier","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"","category":"section"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"In this example we will show how to compute efficient frontiers using the MeanRisk and NearOptimalCentering estimators.","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"using PortfolioOptimisers, PrettyTables\n# Format for pretty tables.\ntsfmt = (v, i, j) -> begin\n    if j == 1\n        return Date(v)\n    else\n        return v\n    end\nend;\nresfmt = (v, i, j) -> begin\n    if j == 1\n        return v\n    else\n        return isa(v, Number) ? \"$(round(v*100, digits=3)) %\" : v\n    end\nend;\nnothing #hide","category":"page"},{"location":"examples/3-Efficient-Frontier/#1.-ReturnsResult-data","page":"Example 3: Efficient frontier","title":"1. ReturnsResult data","text":"","category":"section"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"We will use the same data as the previous example.","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"using CSV, TimeSeries, DataFrames\n\nX = TimeArray(CSV.File(joinpath(@__DIR__, \"SP500.csv.gz\")); timestamp = :Date)[(end - 252):end]\npretty_table(X[(end - 5):end]; formatters = tsfmt)\n\n# Compute the returns\nrd = prices_to_returns(X)","category":"page"},{"location":"examples/3-Efficient-Frontier/#2.-Efficient-frontier","page":"Example 3: Efficient frontier","title":"2. Efficient frontier","text":"","category":"section"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"We have two mutually exclusive ways to compute the efficient frontier. We can do so from the perspective of minimising the risk with a return lower bound, or maximising the return with a risk upper bound. It is possible to provide explicit bounds, or a Frontier object which automatically computes the bounds based on the problem and constraints. All four combinations have their use cases. In this example we will only show the use of Frontier as a lower bound on the portfolio return.","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"Since we will be performing various optimistions, we will provide a vector of solver settings because we don't know if a single set of settings will work in all cases.","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"using Clarabel\nslv = [Solver(; name = :clarabel1, solver = Clarabel.Optimizer,\n              settings = Dict(\"verbose\" => false),\n              check_sol = (; allow_local = true, allow_almost = true)),\n       Solver(; name = :clarabel2, solver = Clarabel.Optimizer,\n              settings = Dict(\"verbose\" => false, \"max_step_fraction\" => 0.75),\n              check_sol = (; allow_local = true, allow_almost = true))]","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"This time we will use the ConditionalValueatRisk measure and we will once again precompute prior.","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"r = ConditionalValueatRisk()\npr = prior(EmpiricalPrior(), rd)","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"Lets create the efficient frontier by setting returns lower bounds and minimising the risk. We will compute a 30-point frontier.","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"opt = JuMPOptimiser(; pe = pr, slv = slv, ret = ArithmeticReturn(; lb = Frontier(; N = 30)))","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"We can now use opt to create the MeanRisk estimator. In order to get the entire frontier, we need to minimise the risk (which is the default value).","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"mr = MeanRisk(; opt = opt, r = r)\nres1 = optimise!(mr)","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"Note that retcode and sol are now vectors. This is because there is one per point in the frontier. Since we didn't get any warnings that any optimisations failed we can proceed without checking the return codes. Regardless, lets check that all optimisations succeeded.","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"all(x -> isa(x, OptimisationSuccess), res1.retcode)","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"We can view how the weights evolve along the frontier.","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"pretty_table(DataFrame([rd.nx hcat(res1.w...)], Symbol.([:assets; 1:30]));\n             formatters = resfmt)","category":"page"},{"location":"examples/3-Efficient-Frontier/#3.-Visualising-the-efficient-frontier","page":"Example 3: Efficient frontier","title":"3. Visualising the efficient frontier","text":"","category":"section"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"Perhaps it is time to introduce some visualisations, which are implemented as a package extesion. For this we need to import the Plots and GraphRecipes packages.","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"using StatsPlots, GraphRecipes\n\nplot_stacked_area_composition(res1.w, rd.nx)","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"The efficient frontier is just a special case of a pareto front, we have a function that can plot pareto fronts and surfaces. We have to provide the weights and the prior. There are optional keyword parameters for the risk measure for the X-axis, Y-axis, Z-axis, and colourbar. Here we will use the Conditional Value at Risk as the X-axis, the arithmetic return, and the risk-return ratio as the colourbar.","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"# Risk-free rate of 4.2/100/252\nplot_measures(res1.w, res1.pr; x = r, y = ReturnRiskMeasure(; rt = res1.ret),\n              c = RatioRiskMeasure(; rt = res1.ret, rk = r, rf = 4.2 / 100 / 252),\n              title = \"Efficient Frontier\", xlabel = \"CVaR\", ylabel = \"Arithmetic Return\",\n              colorbar_title = \"\\nRisk/Return Ratio\", right_margin = 6Plots.mm)","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"The plot_measures function can plot all sorts of pareto fronts. We can even use the ratio of two risk measures as the colourbar.","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"plot_measures(res1.w, res1.pr; x = r, y = ConditionalDrawdownatRisk(),\n              c = RiskRatioRiskMeasure(; r1 = ConditionalDrawdownatRisk(), r2 = r),\n              title = \"Pareto Front\", xlabel = \"CVaR\", ylabel = \"CDaR\",\n              colorbar_title = \"\\nCDaR/CVaR Ratio\", right_margin = 6Plots.mm)","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"","category":"page"},{"location":"examples/3-Efficient-Frontier/","page":"Example 3: Efficient frontier","title":"Example 3: Efficient frontier","text":"This page was generated using Literate.jl.","category":"page"},{"location":"001-Base/#Base","page":"Base","title":"Base","text":"","category":"section"},{"location":"001-Base/#PortfolioOptimisers.AbstractEstimator","page":"Base","title":"PortfolioOptimisers.AbstractEstimator","text":"AbstractEstimator\n\nAbstract supertype for all estimator types in PortfolioOptimisers.jl.\n\nAll custom estimators (e.g., for moments, risk, or priors) should subtype AbstractEstimator. This enables a consistent interface for estimation routines throughout the package.\n\nRelated\n\nAbstractAlgorithm\nAbstractResult\n\n\n\n\n\n","category":"type"},{"location":"001-Base/#PortfolioOptimisers.AbstractAlgorithm","page":"Base","title":"PortfolioOptimisers.AbstractAlgorithm","text":"AbstractAlgorithm\n\nAbstract supertype for all algorithm types in PortfolioOptimisers.jl.\n\nAll algorithms (e.g., solvers, metaheuristics) should subtype AbstractAlgorithm. This allows for flexible extension and dispatch of routines.\n\nRelated\n\nAbstractEstimator\nAbstractResult\n\n\n\n\n\n","category":"type"},{"location":"001-Base/#PortfolioOptimisers.AbstractResult","page":"Base","title":"PortfolioOptimisers.AbstractResult","text":"AbstractResult\n\nAbstract supertype for all result types returned by optimizers in PortfolioOptimisers.jl.\n\nAll result objects (e.g., optimization outputs, solution summaries) should subtype AbstractResult. This ensures a unified interface for accessing results across different estimators and algorithms.\n\nRelated\n\nAbstractEstimator\nAbstractAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"007-10-Moments/#Histogram","page":"Histogram","title":"Histogram","text":"","category":"section"},{"location":"007-10-Moments/#PortfolioOptimisers.AbstractBins","page":"Histogram","title":"PortfolioOptimisers.AbstractBins","text":"Abstract supertype for all histogram binning algorithms.\n\nAbstractBins is the abstract type for all binning algorithm types used in histogram-based calculations within PortfolioOptimisers.jl, such as mutual information and variation of information analysis. Concrete subtypes implement specific binning strategies (e.g., Knuth, Freedman-Diaconis, Scott, Hacine-Gharbi-Ravier) and provide a consistent interface for bin selection.\n\nRelated\n\nAstroPyBins\nKnuth\nFreedmanDiaconis\nScott\nHacineGharbiRavier\n\n\n\n\n\n","category":"type"},{"location":"007-10-Moments/#PortfolioOptimisers.AstroPyBins","page":"Histogram","title":"PortfolioOptimisers.AstroPyBins","text":"abstract type AstroPyBins <: AbstractBins end\n\nAbstract supertype for all histogram binning algorithms implemented using AstroPy's bin width selection methods.\n\nAstroPyBins is the abstract type for all binning algorithm types that rely on bin width selection functions from the AstroPy Python library, such as Knuth, Freedman-Diaconis, and Scott. Concrete subtypes implement specific binning strategies and provide a consistent interface for bin selection in histogram-based calculations within PortfolioOptimisers.jl.\n\nRelated\n\nKnuth\nFreedmanDiaconis\nScott\nAbstractBins\n\n\n\n\n\n","category":"type"},{"location":"007-10-Moments/#PortfolioOptimisers.Knuth","page":"Histogram","title":"PortfolioOptimisers.Knuth","text":"Knuth <: AstroPyBins\n\nHistogram binning algorithm using Knuth's rule.\n\nKnuth implements Knuth's rule for selecting the optimal number of bins in a histogram, as provided by the AstroPy library. This method aims to maximize the posterior probability of the histogram given the data, resulting in an adaptive binning strategy that balances bias and variance.\n\nRelated\n\nAstroPyBins\nFreedmanDiaconis\nScott\nHacineGharbiRavier\nget_bin_width_func\n\n\n\n\n\n","category":"type"},{"location":"007-10-Moments/#PortfolioOptimisers.FreedmanDiaconis","page":"Histogram","title":"PortfolioOptimisers.FreedmanDiaconis","text":"FreedmanDiaconis <: AstroPyBins\n\nHistogram binning algorithm using the Freedman-Diaconis rule.\n\nFreedmanDiaconis implements the Freedman-Diaconis rule for selecting the number of bins in a histogram, as provided by the AstroPy library. This method determines bin width based on the interquartile range (IQR) and the number of data points, making it robust to outliers and suitable for skewed distributions.\n\nRelated\n\nAstroPyBins\nKnuth\nScott\nHacineGharbiRavier\nget_bin_width_func\n\n\n\n\n\n","category":"type"},{"location":"007-10-Moments/#PortfolioOptimisers.Scott","page":"Histogram","title":"PortfolioOptimisers.Scott","text":"Scott <: AstroPyBins\n\nHistogram binning algorithm using Scott's rule.\n\nScott implements Scott's rule for selecting the number of bins in a histogram, as provided by the AstroPy library. This method chooses bin width based on the standard deviation of the data and the number of observations, providing a good default for normally distributed data.\n\nRelated\n\nAstroPyBins\nKnuth\nFreedmanDiaconis\nHacineGharbiRavier\nget_bin_width_func\n\n\n\n\n\n","category":"type"},{"location":"007-10-Moments/#PortfolioOptimisers.HacineGharbiRavier","page":"Histogram","title":"PortfolioOptimisers.HacineGharbiRavier","text":"HacineGharbiRavier <: AbstractBins\n\nHistogram binning algorithm using the Hacine-Gharbi–Ravier rule.\n\nHacineGharbiRavier implements the Hacine-Gharbi–Ravier rule for selecting the number of bins in a histogram. This method adapts the bin count based on the correlation structure and sample size, and is particularly useful for information-theoretic measures such as mutual information and variation of information.\n\nRelated\n\nAbstractBins\nAstroPyBins\nKnuth\nFreedmanDiaconis\nScott\nget_bin_width_func\n\n\n\n\n\n","category":"type"},{"location":"007-10-Moments/#PortfolioOptimisers.get_bin_width_func","page":"Histogram","title":"PortfolioOptimisers.get_bin_width_func","text":"get_bin_width_func(bins::Union{<:AbstractBins, <:Integer})\n\nReturn the bin width selection function associated with a histogram binning algorithm.\n\nThis utility dispatches on the binning algorithm type and returns the corresponding bin width function from the AstroPy Python library for Knuth, FreedmanDiaconis, and Scott. For HacineGharbiRavier and integer bin counts, it returns nothing, as these strategies do not use a bin width function.\n\nArguments\n\nbins::Knuth: Use Knuth's rule (astropy.stats.knuth_bin_width).\nbins::FreedmanDiaconis: Use the Freedman-Diaconis rule (astropy.stats.freedman_bin_width).\nbins::Scott: Use Scott's rule (astropy.stats.scott_bin_width).\nbins::Union{<:HacineGharbiRavier, <:Integer}: No bin width function (returns nothing).\n\nReturns\n\nbin_width_func: The corresponding bin width function (callable), or nothing if not applicable.\n\nExamples\n\njulia> PortfolioOptimisers.get_bin_width_func(Knuth())\nPython: <function knuth_bin_width at 0x7da1178e0fe0>\n\njulia> PortfolioOptimisers.get_bin_width_func(FreedmanDiaconis())\nPython: <function freedman_bin_width at 0x7da1178e0fe0>\n\njulia> PortfolioOptimisers.get_bin_width_func(Scott())\nPython: <function scott_bin_width at 0x7da1178e0fe0>\n\njulia> PortfolioOptimisers.get_bin_width_func(HacineGharbiRavier())\n\njulia> PortfolioOptimisers.get_bin_width_func(10)\n\n\nRelated\n\nKnuth\nFreedmanDiaconis\nScott\nHacineGharbiRavier\n\n\n\n\n\n","category":"function"},{"location":"007-10-Moments/#PortfolioOptimisers.calc_num_bins","page":"Histogram","title":"PortfolioOptimisers.calc_num_bins","text":"calc_num_bins(bins::Union{<:AbstractBins, <:Integer},\n              xj::AbstractVector, xi::AbstractVector, j::Integer, i::Integer,\n              bin_width_func, T::Integer)\n\nCompute the number of histogram bins for a pair of variables using a specified binning algorithm.\n\nThis function determines the number of bins to use for histogram-based calculations (such as mutual information or variation of information) between two variables, based on the selected binning strategy. It dispatches on the binning algorithm type and uses the appropriate method for each:\n\nFor AstroPyBins, it computes the bin width using the provided bin_width_func and calculates the number of bins as the range divided by the bin width, rounding to the nearest integer. For off-diagonal pairs, it uses the maximum of the two variables' bin counts.\nFor HacineGharbiRavier, it uses the Hacine-Gharbi–Ravier rule, which adapts the bin count based on the correlation and sample size.\nFor an integer, it returns the specified number of bins directly.\n\nArguments\n\nbins: Binning algorithm/number.\nxj: Data vector for variable j.\nxi: Data vector for variable i.\nj: Index of variable j.\ni: Index of variable i.\nbin_width_func: Bin width selection function (from get_bin_width_func), or nothing.\nT: Number of observations (used by some algorithms).\n\nReturns\n\nnbins::Int: The computed number of bins for the variable pair.\n\nRelated\n\nget_bin_width_func\nKnuth\nFreedmanDiaconis\nScott\nHacineGharbiRavier\n\n\n\n\n\n","category":"function"},{"location":"007-10-Moments/#PortfolioOptimisers.calc_hist_data","page":"Histogram","title":"PortfolioOptimisers.calc_hist_data","text":"calc_hist_data(xj::AbstractVector, xi::AbstractVector, bins::Integer)\n\nCompute histogram-based marginal and joint distributions for two variables.\n\nThis function computes the normalised histograms (probability mass functions) for two variables xj and xi using the specified number of bins, as well as their joint histogram. It returns the marginal entropies and the joint histogram, which are used in mutual information and variation of information calculations.\n\nArguments\n\nxj: Data vector for variable j.\nxi: Data vector for variable i.\nbins: Number of bins to use for the histograms.\n\nReturns\n\nex::Real: Entropy of xj.\ney::Real: Entropy of xi.\nhxy::Matrix{<:Real}: Joint histogram (counts, not normalised to probability).\n\nDetails\n\nThe histograms are computed using StatsBase.fit(Histogram, ...) over the range of each variable, with bin edges expanded slightly using eps to ensure all data is included.\nThe marginal histograms are normalised to sum to 1 before entropy calculation.\nThe joint histogram is not normalised, as it is used directly in mutual information calculations.\n\nRelated\n\nvariation_info\nmutual_info\n\n\n\n\n\n","category":"function"},{"location":"007-10-Moments/#PortfolioOptimisers.intrinsic_mutual_info","page":"Histogram","title":"PortfolioOptimisers.intrinsic_mutual_info","text":"intrinsic_mutual_info(X::AbstractMatrix)\n\nCompute the intrinsic mutual information from a joint histogram.\n\nThis function calculates the mutual information between two variables given their joint histogram matrix X. It is used as a core step in information-theoretic measures such as mutual information and variation of information.\n\nArguments\n\nX: Joint histogram matrix (typically from calc_hist_data).\n\nReturns\n\nmi::Real: The intrinsic mutual information between the two variables.\n\nDetails\n\nThe function computes marginal distributions by summing over rows and columns.\nOnly nonzero entries in the joint histogram are considered.\nThe mutual information is computed as the sum over all nonzero joint probabilities of p(x, y) * log(p(x, y) / (p(x) * p(y))), with careful handling of log and normalisation.\n\nRelated\n\ncalc_hist_data\nvariation_info\nmutual_info\n\n\n\n\n\n","category":"function"},{"location":"007-10-Moments/#PortfolioOptimisers.variation_info","page":"Histogram","title":"PortfolioOptimisers.variation_info","text":"variation_info(X::AbstractMatrix,\n               bins::Union{<:AbstractBins, <:Integer} = HacineGharbiRavier(),\n               normalise::Bool = true)\n\nCompute the variation of information (VI) matrix for a set of variables.\n\nThis function calculates the pairwise variation of information between all columns of the data matrix X, using histogram-based entropy and mutual information estimates. VI quantifies the amount of information lost and gained when moving from one variable to another, and is a true metric on the space of discrete distributions.\n\nArguments\n\nX: Data matrix (observations × variables).\nbins: Binning algorithm or fixed number of bins.\nnormalise: Whether to normalise the VI by the joint entropy.\n\nReturns\n\nvar_mtx::Matrix{<:Real}: Symmetric matrix of pairwise variation of information values.\n\nDetails\n\nFor each pair of variables, the function computes marginal entropies and the joint histogram using calc_hist_data.\nThe mutual information is computed using intrinsic_mutual_info.\nVI is calculated as H(X) + H(Y) - 2 * I(X, Y). If normalise is true, it is divided by the joint entropy.\nThe result is clamped to [0, typemax(eltype(X))] and is symmetric.\n\nRelated\n\nmutual_info\ncalc_hist_data\nintrinsic_mutual_info\n\n\n\n\n\n","category":"function"},{"location":"007-10-Moments/#PortfolioOptimisers.mutual_info","page":"Histogram","title":"PortfolioOptimisers.mutual_info","text":"mutual_info(X::AbstractMatrix,\n            bins::Union{<:AbstractBins, <:Integer} = HacineGharbiRavier(),\n            normalise::Bool = true)\n\nCompute the mutual information (MI) matrix for a set of variables.\n\nThis function calculates the pairwise mutual information between all columns of the data matrix X, using histogram-based entropy and mutual information estimates. MI quantifies the amount of shared information between pairs of variables, and is widely used in information-theoretic analysis of dependencies.\n\nArguments\n\nX: Data matrix (observations × variables).\nbins: Binning algorithm or fixed number of bins.\nnormalise: Whether to normalise the MI by the minimum marginal entropy.\n\nReturns\n\nmut_mtx::Matrix{<:Real}: Symmetric matrix of pairwise mutual information values.\n\nDetails\n\nFor each pair of variables, the function computes marginal entropies and the joint histogram using calc_hist_data.\nThe mutual information is computed using intrinsic_mutual_info.\nIf normalise is true, the MI is divided by the minimum of the two marginal entropies.\nThe result is clamped to [0, typemax(eltype(X))] and is symmetric.\n\nRelated\n\nvariation_info\ncalc_hist_data\nintrinsic_mutual_info\n\n\n\n\n\n","category":"function"},{"location":"004-Denoise/#Denoise","page":"Denoise","title":"Denoise","text":"","category":"section"},{"location":"004-Denoise/#PortfolioOptimisers.SpectralDenoise","page":"Denoise","title":"PortfolioOptimisers.SpectralDenoise","text":"SpectralDenoise <: AbstractDenoiseAlgorithm\n\nA denoising algorithm that sets the smallest num_factors eigenvalues of a covariance or correlation matrix to zero, effectively removing the principal components relating to random noise according to random matrix theory-based approaches.\n\nExamples\n\njulia> alg = SpectralDenoise()\nSpectralDenoise()\n\nRelated\n\nAbstractDenoiseAlgorithm\ndenoise!\nDenoise\n\n\n\n\n\n","category":"type"},{"location":"004-Denoise/#PortfolioOptimisers.FixedDenoise","page":"Denoise","title":"PortfolioOptimisers.FixedDenoise","text":"FixedDenoise <: AbstractDenoiseAlgorithm\n\nA denoising algorithm that replaces the smallest num_factors eigenvalues of a covariance or correlation matrix with their average, effectively averaging the principal components relating to random noise according to random matrix theory-based approaches.\n\nExamples\n\njulia> alg = FixedDenoise()\nFixedDenoise()\n\nRelated\n\nAbstractDenoiseAlgorithm\ndenoise!\nDenoise\n\n\n\n\n\n","category":"type"},{"location":"004-Denoise/#PortfolioOptimisers.ShrunkDenoise","page":"Denoise","title":"PortfolioOptimisers.ShrunkDenoise","text":"struct ShrunkDenoise{T1} <: AbstractDenoiseAlgorithm\n    alpha::T1\nend\n\nA denoising algorithm that shrinks the smallest num_factors eigenvalues of a covariance or correlation matrix towards their diagonal, controlled by the shrinkage parameter alpha. This approach interpolates between no shrinkage (alpha = 0) and full shrinkage (alpha = 1), providing a flexible way to regularize noisy eigenvalues.\n\nFields\n\nalpha: The shrinkage parameter controlling the degree of shrinkage applied to the smallest eigenvalues. Must be in the range [0, 1], where 0 means no shrinkage and 1 means full shrinkage.\n\nConstructor\n\nShrunkDenoise(; alpha::Real = 0.0)\n\nCreates a new ShrunkDenoise with the specified shrinkage parameter alpha.\n\nRelated\n\nAbstractDenoiseAlgorithm\ndenoise!\nDenoise\n\n\n\n\n\n","category":"type"},{"location":"004-Denoise/#PortfolioOptimisers.ShrunkDenoise-Tuple{}","page":"Denoise","title":"PortfolioOptimisers.ShrunkDenoise","text":"ShrunkDenoise(; alpha::Real = 0.0)\n\nConstructor for ShrunkDenoise.\n\nArguments\n\nalpha: The shrinkage parameter controlling the degree of shrinkage applied to the smallest eigenvalues. Must be in the range [0, 1], where 0 means no shrinkage and 1 means full shrinkage.\n\nValidation\n\nThrows an error if alpha is not in [0, 1].\n\nExamples\n\njulia> alg = ShrunkDenoise(; alpha = 0.5)\nShrunkDenoise\n  alpha | Float64: 0.5\n\n\n\n\n\n","category":"method"},{"location":"004-Denoise/#PortfolioOptimisers.Denoise","page":"Denoise","title":"PortfolioOptimisers.Denoise","text":"struct Denoise{T1, T2, T3, T4, T5, T6} <: AbstractDenoiseEstimator\n    alg::T1\n    args::T2\n    kwargs::T3\n    kernel::T4\n    m::T5\n    n::T6\nend\n\nA flexible container type for configuring and applying denoising algorithms to covariance or correlation matrices in PortfolioOptimisers.jl.\n\nDenoise encapsulates all parameters required for matrix denoising, including the kernel and its arguments for spectral density estimation, the denoising algorithm, and matrix dimensions. It is the standard estimator type for denoising routines and supports a variety of algorithms (SpectralDenoise, FixedDenoise, ShrunkDenoise).\n\nFields\n\nalg: Denoising algorithm (SpectralDenoise, FixedDenoise, ShrunkDenoise).\nargs: Positional arguments for the univariate Optim.optimize.\nkwargs: Keyword arguments for the univariate Optim.optimize.\nkernel: Kernel function for AverageShiftedHistograms.ash.\nm: Number of adjacent histograms to smooth over in AverageShiftedHistograms.ash.\nn: Number of points in the range of eigenvalues used in the average shifted histogram density estimation.\n\nConstructor\n\nDenoise(; alg::AbstractDenoiseAlgorithm = ShrunkDenoise(),\n         m::Integer = 10,\n         n::Integer = 1000,\n         kernel::Any = AverageShiftedHistograms.Kernels.gaussian,\n         args::Tuple = (),\n         kwargs::NamedTuple = (;))\n\nKeyword arguments correspond to the fields above. The constructor infers types and sets defaults for robust denoising.\n\nRelated\n\nAbstractDenoiseEstimator\nSpectralDenoise\nFixedDenoise\nShrunkDenoise\ndenoise!\ndenoise\n\n\n\n\n\n","category":"type"},{"location":"004-Denoise/#PortfolioOptimisers.Denoise-Tuple{}","page":"Denoise","title":"PortfolioOptimisers.Denoise","text":"Denoise(; alg::AbstractDenoiseAlgorithm = ShrunkDenoise(),\n          args::Tuple = (),\n          kwargs::NamedTuple = (;),\n          kernel = AverageShiftedHistograms.Kernels.gaussian,\n          m::Integer = 10,\n          n::Integer = 1000)\n\nConstruct a Denoise object, configuring all parameters for matrix denoising in PortfolioOptimisers.jl.\n\nArguments\n\nalg: Denoising algorithm to use (e.g., SpectralDenoise, FixedDenoise, ShrunkDenoise).\nargs: Positional arguments for the univariate Optim.optimize.\nkwargs: Keyword arguments for the univariate Optim.optimize.\nkernel: Kernel function for AverageShiftedHistograms.ash.\nm: Number of adjacent histograms to smooth over in AverageShiftedHistograms.ash.\nn: Number of points in the range of eigenvalues used in the average shifted histogram density estimation.\n\nExamples\n\njulia> de = Denoise(;)\nDenoise\n     alg | ShrunkDenoise\n         |   alpha | Float64: 0.0\n    args | Tuple{}: ()\n  kwargs | @NamedTuple{}: NamedTuple()\n  kernel | typeof(AverageShiftedHistograms.Kernels.gaussian): AverageShiftedHistograms.Kernels.gaussian\n       m | Int64: 10\n       n | Int64: 1000\n\njulia> de = Denoise(; alg = SpectralDenoise(), m = 20, n = 500)\nDenoise\n     alg | SpectralDenoise()\n    args | Tuple{}: ()\n  kwargs | @NamedTuple{}: NamedTuple()\n  kernel | typeof(AverageShiftedHistograms.Kernels.gaussian): AverageShiftedHistograms.Kernels.gaussian\n       m | Int64: 20\n       n | Int64: 500\n\nRelated\n\nDenoise\nAbstractDenoiseEstimator\nSpectralDenoise\nFixedDenoise\nShrunkDenoise\ndenoise!\ndenoise\n\n\n\n\n\n","category":"method"},{"location":"004-Denoise/#PortfolioOptimisers.denoise!","page":"Denoise","title":"PortfolioOptimisers.denoise!","text":"denoise!(de::Denoise, X::AbstractMatrix, q::Real, pdm::Union{Nothing, <:Posdef} = Posdef())\ndenoise!(::Nothing, args...)\n\nIn-place denoising of a covariance or correlation matrix using a Denoise estimator.\n\nIf de is nothing, this is a no-op and returns nothing.\nIf de is a Denoise object, the specified denoising algorithm is applied to X in-place. Optionally, a Posdef can be provided to ensure the output is positive definite.\n\nArguments\n\nde: The denoising estimator specifying the algorithm and kernel parameters.\nX: The covariance or correlation matrix to be denoised (modified in-place).\nq: The effective sample ratio (e.g., n_obs / n_assets), used for spectral thresholding.\npdm: Optional Positive definite matrix estimator. If provided, ensures the output is positive definite.\n\nReturns\n\nnothing. The input matrix X is modified in-place.\n\nValidation\n\nIf X is a covariance matrix, it is internally converted to a correlation matrix for denoising and then rescaled.\nThe number of factors is determined automatically from the spectrum and kernel parameters.\nIf pdm is provided, the result is projected to the nearest positive definite matrix.\n\nExamples\n\njulia> using StableRNGs\n\njulia> rng = StableRNG(123456789);\n\njulia> X = rand(rng, 10, 5);\n\njulia> X = X' * X\n5×5 Matrix{Float64}:\n 3.29494  2.0765   1.73334  2.01524  1.77493\n 2.0765   2.46967  1.39953  1.97242  2.07886\n 1.73334  1.39953  1.90712  1.17071  1.30459\n 2.01524  1.97242  1.17071  2.24818  1.87091\n 1.77493  2.07886  1.30459  1.87091  2.44414\n\njulia> denoise!(Denoise(), X, 10 / 5)\n\njulia> X\n5×5 Matrix{Float64}:\n 3.29494  2.28883  1.70633  2.12343  2.17377\n 2.28883  2.46967  1.59575  1.98583  2.0329\n 1.70633  1.59575  1.90712  1.48044  1.51553\n 2.12343  1.98583  1.48044  2.24818  1.886\n 2.17377  2.0329   1.51553  1.886    2.44414\n\nRelated\n\ndenoise\nDenoise\nSpectralDenoise\nFixedDenoise\nShrunkDenoise\nposdef!\n\n\n\n\n\n","category":"function"},{"location":"004-Denoise/#PortfolioOptimisers.denoise","page":"Denoise","title":"PortfolioOptimisers.denoise","text":"denoise(de::Denoise, X::AbstractMatrix, q::Real, pdm::Union{Nothing, <:Posdef} = Posdef())\ndenoise(::Nothing, args...)\n\nSame as denoise!, but returns a new matrix instead of modifying X in-place.\n\nIf de is nothing, this is a no-op and returns nothing.\n\nExamples\n\njulia> using StableRNGs\n\njulia> rng = StableRNG(123456789);\n\njulia> X = rand(rng, 10, 5);\n\njulia> X = X' * X\n5×5 Matrix{Float64}:\n 3.29494  2.0765   1.73334  2.01524  1.77493\n 2.0765   2.46967  1.39953  1.97242  2.07886\n 1.73334  1.39953  1.90712  1.17071  1.30459\n 2.01524  1.97242  1.17071  2.24818  1.87091\n 1.77493  2.07886  1.30459  1.87091  2.44414\n\njulia> Xd = denoise(Denoise(), X, 10 / 5)\n5×5 Matrix{Float64}:\n 3.29494  2.28883  1.70633  2.12343  2.17377\n 2.28883  2.46967  1.59575  1.98583  2.0329\n 1.70633  1.59575  1.90712  1.48044  1.51553\n 2.12343  1.98583  1.48044  2.24818  1.886\n 2.17377  2.0329   1.51553  1.886    2.44414\n\nRelated\n\ndenoise!\nDenoise\nSpectralDenoise\nFixedDenoise\nShrunkDenoise\nposdef\n\n\n\n\n\n","category":"function"},{"location":"004-Denoise/#PortfolioOptimisers.AbstractDenoiseEstimator","page":"Denoise","title":"PortfolioOptimisers.AbstractDenoiseEstimator","text":"AbstractDenoiseEstimator <: AbstractEstimator\n\nAbstract supertype for all denoising estimator types in PortfolioOptimisers.jl.\n\nAll concrete types that implement denoising of covariance or correlation matrices (e.g., via spectral, fixed, or shrinkage methods) should subtype AbstractDenoiseEstimator. This enables a consistent interface for denoising routines throughout the package.\n\nRelated\n\nAbstractEstimator\nDenoise\ndenoise!\ndenoise\n\n\n\n\n\n","category":"type"},{"location":"004-Denoise/#PortfolioOptimisers.AbstractDenoiseAlgorithm","page":"Denoise","title":"PortfolioOptimisers.AbstractDenoiseAlgorithm","text":"AbstractDenoiseAlgorithm <: AbstractAlgorithm\n\nAbstract supertype for all denoising algorithm types in PortfolioOptimisers.jl.\n\nAll concrete types that implement a specific denoising algorithm (e.g., spectral, fixed, shrinkage) should subtype AbstractDenoiseAlgorithm. This enables flexible extension and dispatch of denoising routines.\n\nRelated\n\nAbstractAlgorithm\nSpectralDenoise\nFixedDenoise\nShrunkDenoise\n\n\n\n\n\n","category":"type"},{"location":"004-Denoise/#PortfolioOptimisers._denoise!","page":"Denoise","title":"PortfolioOptimisers._denoise!","text":"_denoise!(alg::SpectralDenoise, X::AbstractMatrix, vals::AbstractVector, vecs::AbstractMatrix, num_factors::Integer)\n_denoise!(alg::FixedDenoise, X::AbstractMatrix, vals::AbstractVector, vecs::AbstractMatrix, num_factors::Integer)\n_denoise!(alg::ShrunkDenoise, X::AbstractMatrix, vals::AbstractVector, vecs::AbstractMatrix, num_factors::Integer)\n\nIn-place denoising of a covariance or correlation matrix using a specific denoising algorithm.\n\nThese methods are called internally by denoise! and denoise when a Denoise estimator is used, and should not typically be called directly.\n\nArguments\n\nalg::SpectralDenoise: Sets the smallest num_factors eigenvalues to zero.\nalg::FixedDenoise: Replaces the smallest num_factors eigenvalues with their average.\nalg::ShrunkDenoise: Shrinks the smallest num_factors eigenvalues towards the diagonal, controlled by alg.alpha.\nX: The matrix to be denoised (modified in-place).\nvals: Eigenvalues of X, sorted in ascending order.\nvecs: Corresponding eigenvectors of X.\nnum_factors: Number of eigenvalues to treat as noise.\n\nReturns\n\nnothing. The input matrix X is modified in-place.\n\nRelated\n\ndenoise!\nDenoise\nSpectralDenoise\nFixedDenoise\nShrunkDenoise\n\n\n\n\n\n","category":"function"},{"location":"004-Denoise/#PortfolioOptimisers.errPDF","page":"Denoise","title":"PortfolioOptimisers.errPDF","text":"errPDF(x::Real, vals::AbstractVector, q::Real;\n       kernel::Any = AverageShiftedHistograms.Kernels.gaussian, m::Integer = 10,\n       n::Integer = 1000)\n\nCompute the sum of squared errors (SSE) between the theoretical Marčenko–Pastur (MP) eigenvalue density and the empirical eigenvalue density estimated from observed eigenvalues.\n\nThis function is used internally to fit the MP distribution to the observed spectrum, as part of the denoising procedure.\n\nArguments\n\nx: Scale parameter for the MP distribution [0, 1].\nvals: Observed eigenvalues.\nq: Effective sample ratio (e.g., n_obs / n_assets).\nkernel: Kernel function for AverageShiftedHistograms.ash.\nm: Number of adjacent histograms to smooth over.\nn: Number of points in the range of eigenvalues for density estimation.\n\nReturns\n\nsse::Real: The sum of squared errors between the empirical and theoretical densities.\n\nRelated\n\nfind_max_eval\nDenoise\n\n\n\n\n\n","category":"function"},{"location":"004-Denoise/#PortfolioOptimisers.find_max_eval","page":"Denoise","title":"PortfolioOptimisers.find_max_eval","text":"find_max_eval(vals::AbstractVector, q::Real;\n              kernel::Any = AverageShiftedHistograms.Kernels.gaussian,\n              m::Integer = 10, n::Integer = 1000, args::Tuple = (),\n              kwargs::NamedTuple = (;))\n\nEstimate the upper edge of the Marčenko–Pastur (MP) distribution for a set of eigenvalues, used to separate signal from noise in random matrix denoising.\n\nThis function fits the MP distribution to the observed spectrum by minimizing the sum of squared errors between the empirical and theoretical densities, and returns the estimated maximum eigenvalue for noise.\n\nArguments\n\nvals: Observed eigenvalues (typically sorted in ascending order).\nq: Effective sample ratio (e.g., n_obs / n_assets).\nkernel: Kernel function for AverageShiftedHistograms.ash.\nm: Number of adjacent histograms to smooth over.\nn: Number of points in the range of eigenvalues for density estimation.\nargs: Additional positional arguments for Optim.optimize.\nkwargs: Additional keyword arguments for Optim.optimize.\n\nReturns\n\n(e_max::Real, x::Real): Tuple containing the estimated upper edge of the noise eigenvalue spectrum (e_max) and the fitted scale parameter (x).\n\nRelated\n\nerrPDF\nDenoise\n\n\n\n\n\n","category":"function"},{"location":"011-5-Phylogeny/#Phylogeny","page":"Phylogeny","title":"Phylogeny","text":"","category":"section"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.AbstractCentralityAlgorithm","page":"Phylogeny","title":"PortfolioOptimisers.AbstractCentralityAlgorithm","text":"AbstractCentralityAlgorithm <: AbstractPhylogenyAlgorithm\n\nAbstract supertype for all centrality algorithm types in PortfolioOptimisers.jl from Graphs.jl.\n\nAll concrete types implementing specific centrality algorithms (e.g., betweenness, closeness, degree, eigenvector, Katz, pagerank, radiality, stress) should subtype AbstractCentralityAlgorithm. This enables flexible extension and dispatch of centrality routines for network and phylogeny analysis.\n\nRelated\n\nBetweennessCentrality\nClosenessCentrality\nDegreeCentrality\nEigenvectorCentrality\nKatzCentrality\nPagerank\nRadialityCentrality\nStressCentrality\n\n\n\n\n\n","category":"type"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.BetweennessCentrality","page":"Phylogeny","title":"PortfolioOptimisers.BetweennessCentrality","text":"BetweennessCentrality{T1, T2} <: AbstractCentralityAlgorithm\n\nCentrality algorithm type for betweenness centrality in PortfolioOptimisers.jl.\n\nBetweennessCentrality computes the betweenness centrality of nodes in a graph, measuring the extent to which a node lies on shortest paths between other nodes.\n\nFields\n\nargs: Positional arguments for the centrality computation.\nkwargs: Keyword arguments for the centrality computation.\n\nConstructor\n\nBetweennessCentrality(; args::Tuple = (), kwargs::NamedTuple = (;))\n\nRelated\n\nAbstractCentralityAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.ClosenessCentrality","page":"Phylogeny","title":"PortfolioOptimisers.ClosenessCentrality","text":"ClosenessCentrality{T1, T2} <: AbstractCentralityAlgorithm\n\nCentrality algorithm type for closeness centrality in PortfolioOptimisers.jl.\n\nClosenessCentrality computes the closeness centrality of nodes in a graph, measuring how close a node is to all other nodes.\n\nFields\n\nargs: Positional arguments for the centrality computation.\nkwargs: Keyword arguments for the centrality computation.\n\nConstructor\n\nClosenessCentrality(; args::Tuple = (), kwargs::NamedTuple = (;))\n\nRelated\n\nAbstractCentralityAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.DegreeCentrality","page":"Phylogeny","title":"PortfolioOptimisers.DegreeCentrality","text":"DegreeCentrality{T1, T2} <: AbstractCentralityAlgorithm\n\nCentrality algorithm type for degree centrality in PortfolioOptimisers.jl.\n\nDegreeCentrality computes the degree centrality of nodes in a graph, measuring the number of edges connected to each node. The kind parameter specifies the type of degree (0: total, 1: in-degree, 2: out-degree).\n\nFields\n\nkind: Degree type (0: total, 1: in-degree, 2: out-degree).\nkwargs: Keyword arguments for the centrality computation.\n\nConstructor\n\nDegreeCentrality(; kind::Integer = 0, kwargs::NamedTuple = (;))\n\nRelated\n\nAbstractCentralityAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.EigenvectorCentrality","page":"Phylogeny","title":"PortfolioOptimisers.EigenvectorCentrality","text":"EigenvectorCentrality <: AbstractCentralityAlgorithm\n\nCentrality algorithm type for eigenvector centrality in PortfolioOptimisers.jl.\n\nEigenvectorCentrality computes the eigenvector centrality of nodes in a graph, measuring the influence of a node based on the centrality of its neighbors.\n\nRelated\n\nAbstractCentralityAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.KatzCentrality","page":"Phylogeny","title":"PortfolioOptimisers.KatzCentrality","text":"KatzCentrality{T1} <: AbstractCentralityAlgorithm\n\nCentrality algorithm type for Katz centrality in PortfolioOptimisers.jl.\n\nKatzCentrality computes the Katz centrality of nodes in a graph, measuring the influence of a node based on the number and length of walks between nodes, controlled by the attenuation factor alpha.\n\nFields\n\nalpha: Attenuation factor for Katz centrality.\n\nConstructor\n\nKatzCentrality(; alpha::Real = 0.3)\n\nRelated\n\nAbstractCentralityAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.Pagerank","page":"Phylogeny","title":"PortfolioOptimisers.Pagerank","text":"Pagerank{T1, T2, T3} <: AbstractCentralityAlgorithm\n\nCentrality algorithm type for PageRank in PortfolioOptimisers.jl.\n\nPagerank computes the PageRank of nodes in a graph, measuring the importance of nodes based on the structure of incoming links. The algorithm is controlled by the damping factor alpha, number of iterations n, and convergence tolerance epsilon.\n\nFields\n\nn: Number of iterations (must be > 0).\nalpha: Damping factor (must be in (0, 1)).\nepsilon: Convergence tolerance (must be > 0).\n\nConstructor\n\nPagerank(; alpha::Real = 0.85, n::Integer = 100, epsilon::Real = 1e-6)\n\nRelated\n\nAbstractCentralityAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.RadialityCentrality","page":"Phylogeny","title":"PortfolioOptimisers.RadialityCentrality","text":"RadialityCentrality <: AbstractCentralityAlgorithm\n\nCentrality algorithm type for radiality centrality in PortfolioOptimisers.jl.\n\nRadialityCentrality computes the radiality centrality of nodes in a graph, measuring how close a node is to all other nodes, adjusted for the maximum possible distance.\n\nRelated\n\nAbstractCentralityAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.StressCentrality","page":"Phylogeny","title":"PortfolioOptimisers.StressCentrality","text":"StressCentrality{T1, T2} <: AbstractCentralityAlgorithm\n\nCentrality algorithm type for stress centrality in PortfolioOptimisers.jl.\n\nStressCentrality computes the stress centrality of nodes in a graph, measuring the number of shortest paths passing through each node.\n\nFields\n\nargs: Positional arguments for the centrality computation.\nkwargs: Keyword arguments for the centrality computation.\n\nConstructor\n\nStressCentrality(; args::Tuple = (), kwargs::NamedTuple = (;))\n\nRelated\n\nAbstractCentralityAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.AbstractTreeType","page":"Phylogeny","title":"PortfolioOptimisers.AbstractTreeType","text":"AbstractTreeType <: AbstractPhylogenyAlgorithm\n\nAbstract supertype for all minimum spanning tree (MST) algorithm types in PortfolioOptimisers.jl.\n\nAll concrete types implementing specific MST algorithms (e.g., Kruskal, Boruvka, Prim) should subtype AbstractTreeType. This enables flexible extension and dispatch of tree-based routines for network and phylogeny analysis.\n\nRelated\n\nKruskalTree\nBoruvkaTree\nPrimTree\n\n\n\n\n\n","category":"type"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.KruskalTree","page":"Phylogeny","title":"PortfolioOptimisers.KruskalTree","text":"KruskalTree{T1, T2} <: AbstractTreeType\n\nAlgorithm type for Kruskal's minimum spanning tree (MST) in PortfolioOptimisers.jl.\n\nKruskalTree specifies the use of Kruskal's algorithm for constructing a minimum spanning tree from a graph.\n\nFields\n\nargs: Positional arguments for the MST computation.\nkwargs: Keyword arguments for the MST computation.\n\nConstructor\n\nKruskalTree(; args::Tuple = (), kwargs::NamedTuple = (;))\n\nRelated\n\nAbstractTreeType\n\n\n\n\n\n","category":"type"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.KruskalTree-Tuple{}","page":"Phylogeny","title":"PortfolioOptimisers.KruskalTree","text":"KruskalTree(; args::Tuple = (), kwargs::NamedTuple = (;))\n\nConstruct a KruskalTree algorithm.\n\nArguments\n\nargs: Positional arguments for the MST computation.\nkwargs: Keyword arguments for the MST computation.\n\nReturns\n\nKruskalTree: Algorithm object for Kruskal's MST.\n\nExamples\n\njulia> KruskalTree()\nKruskalTree\n    args | Tuple{}: ()\n  kwargs | @NamedTuple{}: NamedTuple()\n\n\n\n\n\n","category":"method"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.BoruvkaTree","page":"Phylogeny","title":"PortfolioOptimisers.BoruvkaTree","text":"BoruvkaTree{T1, T2} <: AbstractTreeType\n\nAlgorithm type for Boruvka's minimum spanning tree (MST) in PortfolioOptimisers.jl.\n\nBoruvkaTree specifies the use of Boruvka's algorithm for constructing a minimum spanning tree from a graph.\n\nFields\n\nargs: Positional arguments for the MST computation.\nkwargs: Keyword arguments for the MST computation.\n\nConstructor\n\nBoruvkaTree(; args::Tuple = (), kwargs::NamedTuple = (;))\n\nRelated\n\nAbstractTreeType\n\n\n\n\n\n","category":"type"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.BoruvkaTree-Tuple{}","page":"Phylogeny","title":"PortfolioOptimisers.BoruvkaTree","text":"BoruvkaTree(; args::Tuple = (), kwargs::NamedTuple = (;))\n\nConstruct a BoruvkaTree algorithm.\n\nArguments\n\nargs: Positional arguments for the MST computation.\nkwargs: Keyword arguments for the MST computation.\n\nReturns\n\nBoruvkaTree: Algorithm object for Boruvka's MST.\n\nExamples\n\njulia> BoruvkaTree()\nBoruvkaTree\n    args | Tuple{}: ()\n  kwargs | @NamedTuple{}: NamedTuple()\n\n\n\n\n\n","category":"method"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.PrimTree","page":"Phylogeny","title":"PortfolioOptimisers.PrimTree","text":"PrimTree{T1, T2} <: AbstractTreeType\n\nAlgorithm type for Prim's minimum spanning tree (MST) in PortfolioOptimisers.jl.\n\nPrimTree specifies the use of Prim's algorithm for constructing a minimum spanning tree from a graph.\n\nFields\n\nargs: Positional arguments for the MST computation.\nkwargs: Keyword arguments for the MST computation.\n\nConstructor\n\nPrimTree(; args::Tuple = (), kwargs::NamedTuple = (;))\n\nRelated\n\nAbstractTreeType\n\n\n\n\n\n","category":"type"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.PrimTree-Tuple{}","page":"Phylogeny","title":"PortfolioOptimisers.PrimTree","text":"PrimTree(; args::Tuple = (), kwargs::NamedTuple = (;))\n\nConstruct a PrimTree algorithm.\n\nArguments\n\nargs: Positional arguments for the MST computation.\nkwargs: Keyword arguments for the MST computation.\n\nReturns\n\nPrimTree: Algorithm object for Prim's MST.\n\nExamples\n\njulia> PrimTree()\nPrimTree\n    args | Tuple{}: ()\n  kwargs | @NamedTuple{}: NamedTuple()\n\n\n\n\n\n","category":"method"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.calc_mst","page":"Phylogeny","title":"PortfolioOptimisers.calc_mst","text":"calc_mst(alg::KruskalTree, g::AbstractGraph)\ncalc_mst(alg::BoruvkaTree, g::AbstractGraph)\ncalc_mst(alg::PrimTree, g::AbstractGraph)\n\nCompute the minimum spanning tree (MST) of a graph using the specified algorithm.\n\nThis function dispatches to the appropriate MST computation from Graphs.jl based on the type of alg. Supported algorithms include Kruskal, Boruvka, and Prim.\n\nArguments\n\nalg::KruskalTree: Computes the MST using Kruskal's algorithm (Graphs.kruskal_mst).\nalg::BoruvkaTree: Computes the MST using Boruvka's algorithm (Graphs.boruvka_mst).\nalg::PrimTree: Computes the MST using Prim's algorithm (Graphs.prim_mst).\ng::AbstractGraph: Graph to compute the MST on.\n\nReturns\n\ntree::Vector: Vector of edges representing the MST.\n\nRelated\n\nKruskalTree\nBoruvkaTree\nPrimTree\n\n\n\n\n\n","category":"function"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.AbstractNetworkEstimator","page":"Phylogeny","title":"PortfolioOptimisers.AbstractNetworkEstimator","text":"AbstractNetworkEstimator <: AbstractPhylogenyEstimator\n\nAbstract supertype for all network estimator types in PortfolioOptimisers.jl.\n\nAll concrete types implementing network-based estimation algorithms should subtype AbstractNetworkEstimator. This enables a consistent interface for network estimators throughout the package.\n\nRelated\n\nNetwork\nAbstractCentralityEstimator\n\n\n\n\n\n","category":"type"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.Network","page":"Phylogeny","title":"PortfolioOptimisers.Network","text":"Network{T1, T2, T3, T4} <: AbstractNetworkEstimator\n\nEstimator type for network-based phylogeny analysis in PortfolioOptimisers.jl.\n\nNetwork encapsulates the configuration for constructing a network from asset data, including the covariance estimator, distance estimator, tree or similarity algorithm, and the network depth parameter.\n\nFields\n\nce: Covariance estimator.\nde: Distance estimator.\nalg: Tree or similarity matrix algorithm.\nn: Network depth parameter.\n\nConstructor\n\nNetwork(; ce::StatsBase.CovarianceEstimator = PortfolioOptimisersCovariance(),\n         de::AbstractDistanceEstimator = Distance(; alg = CanonicalDistance()),\n         alg::Union{<:AbstractSimilarityMatrixAlgorithm, <:AbstractTreeType} = KruskalTree(),\n         n::Integer = 1)\n\nRelated\n\nAbstractNetworkEstimator\nAbstractTreeType\nAbstractSimilarityMatrixAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.Network-Tuple{}","page":"Phylogeny","title":"PortfolioOptimisers.Network","text":"Network(; ce::StatsBase.CovarianceEstimator = PortfolioOptimisersCovariance(),\n         de::AbstractDistanceEstimator = Distance(; alg = CanonicalDistance()),\n         alg::Union{<:AbstractSimilarityMatrixAlgorithm, <:AbstractTreeType} = KruskalTree(),\n         n::Integer = 1)\n\nConstruct a Network estimator for network-based phylogeny analysis.\n\nCreates a network estimator using the specified covariance estimator, distance estimator, tree or similarity algorithm, and network depth.\n\nArguments\n\nce: Covariance estimator.\nde: Distance estimator.\nalg: Tree or similarity matrix algorithm.\nn: Network depth parameter (integer).\n\nReturns\n\nNetwork: An estimator object for network-based phylogeny analysis.\n\nExamples\n\njulia> Network()\nNetwork\n   ce | PortfolioOptimisersCovariance\n      |   ce | Covariance\n      |      |    me | SimpleExpectedReturns\n      |      |       |   w | nothing\n      |      |    ce | GeneralWeightedCovariance\n      |      |       |   ce | StatsBase.SimpleCovariance: StatsBase.SimpleCovariance(true)\n      |      |       |    w | nothing\n      |      |   alg | Full()\n      |   mp | DefaultMatrixProcessing\n      |      |       pdm | Posdef\n      |      |           |   alg | UnionAll: NearestCorrelationMatrix.Newton\n      |      |   denoise | nothing\n      |      |    detone | nothing\n      |      |       alg | nothing\n   de | Distance\n      |   alg | CanonicalDistance()\n  alg | KruskalTree\n      |     args | Tuple{}: ()\n      |   kwargs | @NamedTuple{}: NamedTuple()\n    n | Int64: 1\n\nRelated\n\nNetwork\n\n\n\n\n\n","category":"method"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.AbstractCentralityEstimator","page":"Phylogeny","title":"PortfolioOptimisers.AbstractCentralityEstimator","text":"AbstractCentralityEstimator <: AbstractPhylogenyEstimator\n\nAbstract supertype for all centrality estimator types in PortfolioOptimisers.jl.\n\nAll concrete types implementing centrality-based estimation algorithms should subtype AbstractCentralityEstimator. This enables a consistent interface for centrality estimators throughout the package.\n\nRelated\n\nCentrality\nAbstractCentralityAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.Centrality","page":"Phylogeny","title":"PortfolioOptimisers.Centrality","text":"Centrality{T1, T2} <: AbstractCentralityEstimator\n\nEstimator type for centrality-based analysis in PortfolioOptimisers.jl.\n\nCentrality encapsulates the configuration for computing centrality measures on a network, including the network estimator and the centrality algorithm.\n\nFields\n\nne: Network estimator.\ncent: Centrality algorithm.\n\nConstructor\n\nCentrality(; ne::AbstractNetworkEstimator = Network(),\n            cent::AbstractCentralityAlgorithm = DegreeCentrality())\n\nRelated\n\nAbstractCentralityEstimator\nAbstractCentralityAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.Centrality-Tuple{}","page":"Phylogeny","title":"PortfolioOptimisers.Centrality","text":"Centrality(; ne::AbstractNetworkEstimator = Network(),\n            cent::AbstractCentralityAlgorithm = DegreeCentrality())\n\nConstruct a Centrality estimator for centrality-based analysis.\n\nCreates a centrality estimator using the specified network estimator and centrality algorithm.\n\nArguments\n\nne: Network estimator.\ncent: Centrality algorithm.\n\nReturns\n\nCentrality: An estimator object for centrality-based analysis.\n\nExamples\n\njulia> Centrality()\nCentrality\n    ne | Network\n       |    ce | PortfolioOptimisersCovariance\n       |       |   ce | Covariance\n       |       |      |    me | SimpleExpectedReturns\n       |       |      |       |   w | nothing\n       |       |      |    ce | GeneralWeightedCovariance\n       |       |      |       |   ce | StatsBase.SimpleCovariance: StatsBase.SimpleCovariance(true)\n       |       |      |       |    w | nothing\n       |       |      |   alg | Full()\n       |       |   mp | DefaultMatrixProcessing\n       |       |      |       pdm | Posdef\n       |       |      |           |   alg | UnionAll: NearestCorrelationMatrix.Newton\n       |       |      |   denoise | nothing\n       |       |      |    detone | nothing\n       |       |      |       alg | nothing\n       |    de | Distance\n       |       |   alg | CanonicalDistance()\n       |   alg | KruskalTree\n       |       |     args | Tuple{}: ()\n       |       |   kwargs | @NamedTuple{}: NamedTuple()\n       |     n | Int64: 1\n  cent | DegreeCentrality\n       |     kind | Int64: 0\n       |   kwargs | @NamedTuple{}: NamedTuple()\n\nRelated\n\nCentrality\n\n\n\n\n\n","category":"method"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.calc_adjacency","page":"Phylogeny","title":"PortfolioOptimisers.calc_adjacency","text":"calc_adjacency(ne::Network{<:Any, <:Any, <:AbstractTreeType, <:Any}, X::AbstractMatrix; dims::Int = 1, kwargs...)\ncalc_adjacency(ne::Network{<:Any, <:Any, <:AbstractSimilarityMatrixAlgorithm, <:Any}, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the adjacency matrix for a network estimator.\n\nArguments\n\nne::Network{<:Any, <:Any, <:AbstractTreeType, <:Any}: Constructs a weighted graph from the distance matrix and computes the minimum spanning tree, returning the adjacency matrix of the resulting graph.\nne::Network{<:Any, <:Any, <:AbstractSimilarityMatrixAlgorithm, <:Any}: Computes the similarity and distance matrices, applies the PMFG_T2s algorithm, and returns the adjacency matrix of the resulting graph..\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute (default: 1).\nkwargs...: Additional keyword arguments.\n\nReturns\n\nadj::Matrix{Int}: Adjacency matrix representing the network.\n\nRelated\n\nNetwork\ncalc_mst\nPMFG_T2s\n\n\n\n\n\n","category":"function"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.phylogeny_matrix-Tuple{Network, AbstractMatrix}","page":"Phylogeny","title":"PortfolioOptimisers.phylogeny_matrix","text":"phylogeny_matrix(ne::Network, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the phylogeny matrix for a network estimator.\n\nThis function constructs the adjacency matrix for the network, then computes the phylogeny matrix by summing powers of the adjacency matrix up to the network depth parameter n, clamping values to 0 or 1, and removing self-loops.\n\nArguments\n\nne: Network estimator.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute (default: 1).\nkwargs...: Additional keyword arguments.\n\nReturns\n\nP::Matrix{Int}: Phylogeny matrix representing asset relationships.\n\nRelated\n\nNetwork\ncalc_adjacency\n\n\n\n\n\n","category":"method"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.phylogeny_matrix-Tuple{Union{PortfolioOptimisers.AbstractClusteringResult, ClusteringEstimator}, AbstractMatrix}","page":"Phylogeny","title":"PortfolioOptimisers.phylogeny_matrix","text":"phylogeny_matrix(cle::Union{<:ClusteringEstimator, <:AbstractClusteringResult},\n                 X::AbstractMatrix; branchorder::Symbol = :optimal, dims::Int = 1, kwargs...)\n\nCompute the phylogeny matrix for a clustering estimator or result.\n\nThis function applies clustering to the data, assigns assets to clusters, and constructs a binary phylogeny matrix indicating shared cluster membership, with self-loops removed.\n\nArguments\n\ncle: Clustering estimator or result.\nX: Data matrix (observations × assets).\nbranchorder: Branch ordering strategy for hierarchical clustering (default: :optimal).\ndims: Dimension along which to compute (default: 1).\nkwargs...: Additional keyword arguments.\n\nReturns\n\nP::Matrix{Int}: Phylogeny matrix representing cluster relationships.\n\nRelated\n\nClusteringEstimator\nphylogeny_matrix\n\n\n\n\n\n","category":"method"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.calc_centrality","page":"Phylogeny","title":"PortfolioOptimisers.calc_centrality","text":"calc_centrality(cent::BetweennessCentrality, g::AbstractGraph)\ncalc_centrality(cent::ClosenessCentrality, g::AbstractGraph)\ncalc_centrality(cent::DegreeCentrality, g::AbstractGraph)\ncalc_centrality(::EigenvectorCentrality, g::AbstractGraph)\ncalc_centrality(cent::KatzCentrality, g::AbstractGraph)\ncalc_centrality(cent::Pagerank, g::AbstractGraph)\ncalc_centrality(::RadialityCentrality, g::AbstractGraph)\ncalc_centrality(cent::StressCentrality, g::AbstractGraph)\n\nCompute node centrality scores for a graph using the specified centrality algorithm.\n\nThis function dispatches to the appropriate centrality computation from Graphs.jl based on the type of cent. Supported algorithms include betweenness, closeness, degree, eigenvector, Katz, pagerank, radiality, and stress centrality.\n\nArguments\n\ncent::BetweennessCentrality: Computes betweenness centrality using Graphs.betweenness_centrality.\ncent::ClosenessCentrality: Computes closeness centrality using Graphs.closeness_centrality.\ncent::DegreeCentrality: Computes degree centrality using Graphs._degree_centrality.\ncent::EigenvectorCentrality: Computes eigenvector centrality using Graphs.eigenvector_centrality.\ncent::KatzCentrality: Computes Katz centrality using Graphs.katz_centrality.\ncent::Pagerank: Computes PageRank using Graphs.pagerank.\ncent::RadialityCentrality: Computes radiality centrality using Graphs.radiality_centrality.\ncent::StressCentrality: Computes stress centrality using Graphs.stress_centrality.\ng: Graph to compute centrality on.\n\nReturns\n\nVector{<:Real}: Centrality scores for each node in the graph.\n\nRelated\n\nBetweennessCentrality\nClosenessCentrality\nDegreeCentrality\nEigenvectorCentrality\nKatzCentrality\nPagerank\nRadialityCentrality\nStressCentrality\n\n\n\n\n\n","category":"function"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.centrality_vector-Tuple{Network, AbstractCentralityAlgorithm, AbstractMatrix}","page":"Phylogeny","title":"PortfolioOptimisers.centrality_vector","text":"centrality_vector(ne::Network, cent::AbstractCentralityAlgorithm,\n                  X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the centrality vector for a network and centrality algorithm.\n\nThis function constructs the phylogeny matrix for the network, builds a graph, and computes node centrality scores using the specified centrality algorithm.\n\nArguments\n\nne: Network estimator.\ncent: Centrality algorithm.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute (default: 1).\nkwargs...: Additional keyword arguments.\n\nReturns\n\ncv::Vector{<:Real}: Centrality scores for each asset.\n\nRelated\n\nNetwork\nCentrality\ncalc_centrality\n\n\n\n\n\n","category":"method"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.centrality_vector-Tuple{Centrality, AbstractMatrix}","page":"Phylogeny","title":"PortfolioOptimisers.centrality_vector","text":"centrality_vector(cte::Centrality, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the centrality vector for a centrality estimator.\n\nThis function applies the centrality algorithm in the estimator to the network constructed from the data.\n\nArguments\n\ncte: Centrality estimator.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute (default: 1).\nkwargs...: Additional keyword arguments.\n\nReturns\n\ncv::Vector{<:Real}: Centrality scores for each asset.\n\nRelated\n\nCentrality\ncentrality_vector\n\n\n\n\n\n","category":"method"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.average_centrality-Tuple{Network, AbstractCentralityAlgorithm, AbstractVector, AbstractMatrix}","page":"Phylogeny","title":"PortfolioOptimisers.average_centrality","text":"average_centrality(ne::Network, cent::AbstractCentralityAlgorithm,\n                   w::AbstractVector, X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the weighted average centrality for a network and centrality algorithm.\n\nThis function computes the centrality vector and returns the weighted average using the provided weights.\n\nArguments\n\nne: Network estimator.\ncent: Centrality algorithm.\nw: Weights vector.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute (default: 1).\nkwargs...: Additional keyword arguments.\n\nReturns\n\nac::Real: Average centrality.\n\nRelated\n\nNetwork\nCentrality\ncentrality_vector\n\n\n\n\n\n","category":"method"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.average_centrality-Tuple{Centrality, AbstractVector, AbstractMatrix}","page":"Phylogeny","title":"PortfolioOptimisers.average_centrality","text":"average_centrality(cte::Centrality, w::AbstractVector, X::AbstractMatrix;\n                   dims::Int = 1, kwargs...)\n\nCompute the weighted average centrality for a centrality estimator.\n\nThis function applies the centrality algorithm in the estimator to the network and returns the weighted average using the provided weights.\n\nArguments\n\ncte: Centrality estimator.\nw: Weights vector.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute (default: 1).\nkwargs...: Additional keyword arguments.\n\nReturns\n\nac::Real: Average centrality.\n\nRelated\n\nCentrality\naverage_centrality\n\n\n\n\n\n","category":"method"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.asset_phylogeny-Tuple{AbstractVector, AbstractMatrix}","page":"Phylogeny","title":"PortfolioOptimisers.asset_phylogeny","text":"asset_phylogeny(w::AbstractVector, X::AbstractMatrix)\n\nCompute the asset phylogeny score for a set of weights and a phylogeny matrix.\n\nThis function computes the weighted sum of the phylogeny matrix, normalised by the sum of absolute weights.\n\nArguments\n\nw: Weights vector.\nX: Phylogeny matrix.\n\nReturns\n\np::Real: Asset phylogeny score.\n\nRelated\n\nphylogeny_matrix\nasset_phylogeny\n\n\n\n\n\n","category":"method"},{"location":"011-5-Phylogeny/#PortfolioOptimisers.asset_phylogeny-Tuple{Union{ClusteringEstimator, Network}, AbstractVector, AbstractMatrix}","page":"Phylogeny","title":"PortfolioOptimisers.asset_phylogeny","text":"asset_phylogeny(cle::Union{<:Network, <:ClusteringEstimator}, w::AbstractVector,\n                X::AbstractMatrix; dims::Int = 1, kwargs...)\n\nCompute the asset phylogeny score for a set of weights and a network or clustering estimator.\n\nThis function computes the phylogeny matrix using the estimator and data, then computes the asset phylogeny score using the weights.\n\nArguments\n\ncle: Network or clustering estimator.\nw: Weights vector.\nX: Data matrix (observations × assets).\ndims: Dimension along which to compute (default: 1).\nkwargs...: Additional keyword arguments.\n\nReturns\n\np::Real: Asset phylogeny score.\n\nRelated\n\nphylogeny_matrix\nasset_phylogeny\n\n\n\n\n\n","category":"method"},{"location":"091-developer/#dev_docs","page":"Developer documentation","title":"Developer documentation","text":"","category":"section"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"note: Contributing guidelines\nIf you haven't, please read the Contributing guidelines first.","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"If you want to make contributions to this package that involves code, then this guide is for you.","category":"page"},{"location":"091-developer/#First-time-clone","page":"Developer documentation","title":"First time clone","text":"","category":"section"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"tip: If you have writing rights\nIf you have writing rights, you don't have to fork. Instead, simply clone and skip ahead. Whenever upstream is mentioned, use origin instead.","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"If this is the first time you work with this repository, follow the instructions below to clone the repository.","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"Fork this repo\nClone your repo (this will create a git remote called origin)\nAdd this repo as a remote:","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"git remote add upstream https://github.com/dcelisgarza/PortfolioOptimisers.jl","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"This will ensure that you have two remotes in your git: origin and upstream. You will create branches and push to origin, and you will fetch and update your local main branch from upstream.","category":"page"},{"location":"091-developer/#Linting-and-formatting","page":"Developer documentation","title":"Linting and formatting","text":"","category":"section"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"Install a plugin on your editor to use EditorConfig. This will ensure that your editor is configured with important formatting settings.","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"We use https://pre-commit.com to run the linters and formatters. In particular, the Julia code is formatted using JuliaFormatter.jl, so please install it globally first:","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"julia> # Press ]\npkg> activate\npkg> add JuliaFormatter","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"To install pre-commit, we recommend using pipx as follows:","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"# Install pipx following the link\npipx install pre-commit","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"With pre-commit installed, activate it as a pre-commit hook:","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"pre-commit install","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"To run the linting and formatting manually, enter the command below:","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"pre-commit run -a","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"Now, you can only commit if all the pre-commit tests pass.","category":"page"},{"location":"091-developer/#Testing","page":"Developer documentation","title":"Testing","text":"","category":"section"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"As with most Julia packages, you can just open Julia in the repository folder, activate the environment, and run test:","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"julia> # press ]\npkg> activate .\npkg> test","category":"page"},{"location":"091-developer/#Working-on-a-new-issue","page":"Developer documentation","title":"Working on a new issue","text":"","category":"section"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"We try to keep a linear history in this repo, so it is important to keep your branches up-to-date.","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"Fetch from the remote and fast-forward your local main\ngit fetch upstream\ngit switch main\ngit merge --ff-only upstream/main\nBranch from main to address the issue (see below for naming)\ngit switch -c 42-add-answer-universe\nPush the new local branch to your personal remote repository\ngit push -u origin 42-add-answer-universe\nCreate a pull request to merge your remote branch into the org main.","category":"page"},{"location":"091-developer/#Branch-naming","page":"Developer documentation","title":"Branch naming","text":"","category":"section"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"If there is an associated issue, add the issue number.\nIf there is no associated issue, and the changes are small, add a prefix such as \"typo\", \"hotfix\", \"small-refactor\", according to the type of update.\nIf the changes are not small and there is no associated issue, then create the issue first, so we can properly discuss the changes.\nUse dash separated imperative wording related to the issue (e.g., 14-add-tests, 15-fix-model, 16-remove-obsolete-files).","category":"page"},{"location":"091-developer/#Commit-message","page":"Developer documentation","title":"Commit message","text":"","category":"section"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"Use imperative or present tense, for instance: Add feature or Fix bug.\nHave informative titles.\nWhen necessary, add a body with details.\nIf there are breaking changes, add the information to the commit message.","category":"page"},{"location":"091-developer/#Before-creating-a-pull-request","page":"Developer documentation","title":"Before creating a pull request","text":"","category":"section"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"tip: Atomic git commits\nTry to create \"atomic git commits\" (recommended reading: The Utopic Git History).","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"Make sure the tests pass.\nMake sure the pre-commit tests pass.\nFetch any main updates from upstream and rebase your branch, if necessary:\ngit fetch upstream\ngit rebase upstream/main BRANCH_NAME\nThen you can open a pull request and work with the reviewer to address any issues.","category":"page"},{"location":"091-developer/#Writing-documentation","page":"Developer documentation","title":"Writing documentation","text":"","category":"section"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"Please document new features. The documentation must include:\nLinks to related functions and types.\nExhaustive descriptions of the arguments, keyword arguments, type information, and data validation.\nExhaustive usage examples as REPL-style jldoctest blocks, they should maximize code coverage.","category":"page"},{"location":"091-developer/#Building-and-viewing-the-documentation-locally","page":"Developer documentation","title":"Building and viewing the documentation locally","text":"","category":"section"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"Following the latest suggestions, we recommend using LiveServer to build the documentation. Here is how you do it:","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"Run julia --project=docs to open Julia in the environment of the docs.\nIf this is the first time building the docs\nPress ] to enter pkg mode\nRun pkg> dev . to use the development version of your package\nPress backspace to leave pkg mode\nRun julia> using LiveServer\nRun julia> servedocs()","category":"page"},{"location":"091-developer/#Making-a-new-release","page":"Developer documentation","title":"Making a new release","text":"","category":"section"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"To create a new release, you can follow these simple steps:","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"Create a branch release-x.y.z\nUpdate version in Project.toml\nUpdate the CHANGELOG.md:\nRename the section \"Unreleased\" to \"[x.y.z] - yyyy-mm-dd\" (i.e., version under brackets, dash, and date in ISO format)\nAdd a new section on top of it named \"Unreleased\"\nAdd a new link in the bottom for version \"x.y.z\"\nChange the \"[unreleased]\" link to use the latest version - end of line, vx.y.z ... HEAD.\nCreate a commit \"Release vx.y.z\", push, create a PR, wait for it to pass, merge the PR.\nGo back to main screen and click on the latest commit (link: https://github.com/dcelisgarza/PortfolioOptimisers.jl/commit/main)\nAt the bottom, write @JuliaRegistrator register","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"After that, you only need to wait and verify:","category":"page"},{"location":"091-developer/","page":"Developer documentation","title":"Developer documentation","text":"Wait for the bot to comment (should take < 1m) with a link to a PR to the registry\nFollow the link and wait for a comment on the auto-merge\nThe comment should said all is well and auto-merge should occur shortly\nAfter the merge happens, TagBot will trigger and create a new GitHub tag. Check on https://github.com/dcelisgarza/PortfolioOptimisers.jl/releases\nAfter the release is create, a \"docs\" GitHub action will start for the tag.\nAfter it passes, a deploy action will run.\nAfter that runs, the stable docs should be updated. Check them and look for the version number.","category":"page"},{"location":"011-1-Base-Phylogeny/#Base-Phylogeny","page":"Base Phylogeny","title":"Base Phylogeny","text":"","category":"section"},{"location":"011-1-Base-Phylogeny/#PortfolioOptimisers.AbstractPhylogenyEstimator","page":"Base Phylogeny","title":"PortfolioOptimisers.AbstractPhylogenyEstimator","text":"AbstractPhylogenyEstimator <: AbstractEstimator\n\nAbstract supertype for all phylogeny estimator types in PortfolioOptimisers.jl.\n\nAll concrete types implementing phylogeny-based estimation algorithms should subtype AbstractPhylogenyEstimator. This enables a consistent interface for phylogeny estimators throughout the package.\n\nRelated\n\nAbstractPhylogenyAlgorithm\nAbstractPhylogenyResult\n\n\n\n\n\n","category":"type"},{"location":"011-1-Base-Phylogeny/#PortfolioOptimisers.AbstractPhylogenyAlgorithm","page":"Base Phylogeny","title":"PortfolioOptimisers.AbstractPhylogenyAlgorithm","text":"AbstractPhylogenyAlgorithm <: AbstractAlgorithm\n\nAbstract supertype for all phylogeny algorithm types in PortfolioOptimisers.jl.\n\nAll concrete types implementing specific phylogeny algorithms should subtype AbstractPhylogenyAlgorithm. This enables flexible extension and dispatch of phylogeny routines.\n\nRelated\n\nAbstractPhylogenyEstimator\nAbstractPhylogenyResult\n\n\n\n\n\n","category":"type"},{"location":"011-1-Base-Phylogeny/#PortfolioOptimisers.AbstractPhylogenyResult","page":"Base Phylogeny","title":"PortfolioOptimisers.AbstractPhylogenyResult","text":"AbstractPhylogenyResult <: AbstractResult\n\nAbstract supertype for all phylogeny result types in PortfolioOptimisers.jl.\n\nAll concrete types representing the result of a phylogeny estimation should subtype AbstractPhylogenyResult. This enables a consistent interface for phylogeny results throughout the package.\n\nRelated\n\nAbstractPhylogenyEstimator\nAbstractPhylogenyAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"011-3-Hierarchical/#Hierarchical","page":"Hierarchical","title":"Hierarchical","text":"","category":"section"},{"location":"011-3-Hierarchical/#PortfolioOptimisers.ClusterNode","page":"Hierarchical","title":"PortfolioOptimisers.ClusterNode","text":"ClusterNode{tid, tl, tr, td, tcnt} <: AbstractResult\n\nNode type for representing clusters in a hierarchical clustering tree.\n\nClusterNode encapsulates the structure of a node in a clustering tree, including its unique identifier, left and right child nodes, height, and level in the tree. Leaf nodes have left and right set to nothing.\n\nFields\n\nid: Unique identifier for the node.\nleft: Left child node.\nright: Right child node.\nheight: Height of the node in the tree.\nlevel: Level of the node in the tree.\n\nConstructor\n\nClusterNode(id, left::Union{Nothing, <:ClusterNode} = nothing,\n            right::Union{Nothing, <:ClusterNode} = nothing,\n            height::Real = 0.0, level::Int = 1)\n\nCreates a new ClusterNode with the specified properties. If left is nothing, the node is a leaf and level is set to the provided value; otherwise, level is computed as the sum of the levels of the left and right children.\n\nExamples\n\njulia> ClusterNode(1)\nClusterNode\n      id | Int64: 1\n    left | nothing\n   right | nothing\n  height | Float64: 0.0\n   level | Int64: 1\n\nRelated\n\nis_leaf\npre_order\n\n\n\n\n\n","category":"type"},{"location":"011-3-Hierarchical/#PortfolioOptimisers.is_leaf","page":"Hierarchical","title":"PortfolioOptimisers.is_leaf","text":"is_leaf(a::ClusterNode)\n\nDetermine if a ClusterNode is a leaf node.\n\nReturns true if the node has no left child (left == nothing), indicating it is a leaf in the clustering tree.\n\nArguments\n\na: The node to check.\n\nReturns\n\nBool: true if the node is a leaf, false otherwise.\n\nExamples\n\njulia> PortfolioOptimisers.is_leaf(ClusterNode(1))\ntrue\n\nRelated\n\nClusterNode\n\n\n\n\n\n","category":"function"},{"location":"011-3-Hierarchical/#PortfolioOptimisers.AbstractPreorderBy","page":"Hierarchical","title":"PortfolioOptimisers.AbstractPreorderBy","text":"AbstractPreorderBy <: AbstractAlgorithm\n\nAbstract supertype for all preorder traversal strategies in PortfolioOptimisers.jl.\n\nConcrete types implementing specific preorder traversal logic should subtype AbstractPreorderBy. This enables flexible extension and dispatch of preorder routines for hierarchical clustering trees.\n\nRelated\n\nPreorderTreeByID\npre_order\n\n\n\n\n\n","category":"type"},{"location":"011-3-Hierarchical/#PortfolioOptimisers.PreorderTreeByID","page":"Hierarchical","title":"PortfolioOptimisers.PreorderTreeByID","text":"PreorderTreeByID <: AbstractPreorderBy\n\nPreorder traversal strategy that visits nodes by their identifier.\n\nPreorderTreeByID is used to specify that preorder traversal should be performed using the node's id property.\n\nRelated\n\nAbstractPreorderBy\nget_node_property\npre_order\n\n\n\n\n\n","category":"type"},{"location":"011-3-Hierarchical/#PortfolioOptimisers.get_node_property","page":"Hierarchical","title":"PortfolioOptimisers.get_node_property","text":"get_node_property(preorder_by::PreorderTreeByID, a::ClusterNode)\n\nGet the property of a node used for preorder traversal.\n\nFor PreorderTreeByID, this returns the node's id.\n\nArguments\n\npreorder_by: Preorder traversal strategy.\na: The node.\n\nReturns\n\nThe node's identifier.\n\nRelated\n\nPreorderTreeByID\npre_order\n\n\n\n\n\n","category":"function"},{"location":"011-3-Hierarchical/#PortfolioOptimisers.pre_order","page":"Hierarchical","title":"PortfolioOptimisers.pre_order","text":"pre_order(a::ClusterNode, preorder_by::AbstractPreorderBy = PreorderTreeByID())\n\nPerform a preorder traversal of a hierarchical clustering tree.\n\nReturns a vector of node properties (by default, node IDs) in preorder (root, left, right) order. The traversal strategy can be customised by providing a subtype of AbstractPreorderBy.\n\nArguments\n\na: The root node of the tree.\npreorder_by: Traversal strategy (default: PreorderTreeByID()).\n\nReturns\n\nVector{Int}: Vector of node properties in preorder.\n\nRelated\n\nClusterNode\nAbstractPreorderBy\nPreorderTreeByID\nget_node_property\n\n\n\n\n\n","category":"function"},{"location":"011-3-Hierarchical/#PortfolioOptimisers.to_tree","page":"Hierarchical","title":"PortfolioOptimisers.to_tree","text":"to_tree(a::Hclust)\n\nConvert a hierarchical clustering result to a tree of ClusterNode objects.\n\nThis function takes a hierarchical clustering object (from Clustering.jl) and constructs a tree representation using ClusterNode nodes. It returns the root node and a vector of all nodes in the tree.\n\nArguments\n\na: Hierarchical clustering object.\n\nReturns\n\nroot::ClusterNode: The root node of the clustering tree.\nnodes::Vector{ClusterNode}: Vector containing all nodes in the tree.\n\nRelated\n\nClusterNode\npre_order\n\n\n\n\n\n","category":"function"},{"location":"011-3-Hierarchical/#PortfolioOptimisers.clusterise-Tuple{ClusteringEstimator{<:Any, <:Any, <:HClustAlgorithm}, AbstractMatrix{<:Real}}","page":"Hierarchical","title":"PortfolioOptimisers.clusterise","text":"clusterise(cle::ClusteringEstimator{<:Any, <:Any, <:HClustAlgorithm, <:Any},\n           X::AbstractMatrix{<:Real}; branchorder::Symbol = :optimal,\n           dims::Int = 1, kwargs...)\n\nRun hierarchical clustering and return the result as a HierarchicalClustering object.\n\nThis function applies the specified clustering estimator to the input data matrix, computes the similarity and distance matrices, performs hierarchical clustering, and selects the optimal number of clusters. The result is returned as a HierarchicalClustering object.\n\nArguments\n\ncle: Clustering estimator.\nX: Data matrix (observations × assets).\nbranchorder: Branch ordering strategy for hierarchical clustering (default: :optimal).\ndims: Dimension along which to cluster (default: 1).\nkwargs...: Additional keyword arguments.\n\nReturns\n\nHierarchicalClustering: Result object containing clustering, similarity, distance matrices, and number of clusters.\n\nRelated\n\nHierarchicalClustering\nClusteringEstimator\n\n\n\n\n\n","category":"method"},{"location":"011-3-Hierarchical/#PortfolioOptimisers.validate_k_value","page":"Hierarchical","title":"PortfolioOptimisers.validate_k_value","text":"validate_k_value(clustering::Hclust, nodes::AbstractVector{<:ClusterNode},\n                 k::Integer)\n\nValidate whether a given number of clusters k is consistent with the hierarchical clustering tree.\n\nThis function checks if the clustering assignment for k clusters is compatible with the tree structure, ensuring that each non-leaf node's children correspond to valid clusters.\n\nArguments\n\nclustering: Hierarchical clustering object.\nnodes: Vector of nodes in the clustering tree.\nk: Number of clusters to validate.\n\nReturns\n\nBool: true if k is a valid number of clusters, false otherwise.\n\nRelated\n\noptimal_number_clusters\nClusterNode\n\n\n\n\n\n","category":"function"},{"location":"011-3-Hierarchical/#PortfolioOptimisers.valid_k_clusters","page":"Hierarchical","title":"PortfolioOptimisers.valid_k_clusters","text":"valid_k_clusters(clustering::Hclust, arr::AbstractVector)\n\nFind a valid number of clusters for a hierarchical clustering tree given a scoring array.\n\nThis function iteratively searches for a valid k (number of clusters) by checking the scoring array (e.g., silhouette scores, second-order differences) and validating each candidate using validate_k_value. Returns the first valid k found, or 1 if none are valid.\n\nArguments\n\nclustering: Hierarchical clustering object.\narr: Array of scores for each possible number of clusters.\n\nReturns\n\nInteger: Valid number of clusters.\n\nRelated\n\nvalidate_k_value\noptimal_number_clusters\n\n\n\n\n\n","category":"function"},{"location":"011-3-Hierarchical/#PortfolioOptimisers.optimal_number_clusters","page":"Hierarchical","title":"PortfolioOptimisers.optimal_number_clusters","text":"optimal_number_clusters(onc::OptimalNumberClusters{<:Any, <:PredefinedNumberClusters}, clustering::Hclust, args...)\noptimal_number_clusters(onc::OptimalNumberClusters{<:Any, <:SecondOrderDifference}, clustering::Hclust, dist::AbstractMatrix)\noptimal_number_clusters(onc::OptimalNumberClusters{<:Any, <:StandardisedSilhouetteScore}, clustering::Hclust, dist::AbstractMatrix)\n\nSelect the optimal number of clusters for a hierarchical clustering tree.\n\nThis function applies the specified optimal number of clusters estimator (onc) to a hierarchical clustering result and distance matrix, using the configured algorithm (e.g., SecondOrderDifference, StandardisedSilhouetteScore, PredefinedNumberClusters). The selection is based on cluster validity and scoring metrics.\n\nArguments\n\nonc::OptimalNumberClusters{<:Any, <:PredefinedNumberClusters}: Uses a user-specified fixed number of clusters (k). If k is not valid, searches above and below for the nearest valid cluster count.\nonc::OptimalNumberClusters{<:Any, <:SecondOrderDifference}: Computes the second-order difference of a clustering evaluation metric for each possible cluster count, and selects the first valid k that maximises the difference.\nonc::OptimalNumberClusters{<:Any, <:StandardisedSilhouetteScore}: Computes the standardised silhouette score for each possible cluster count, and selects the first valid k that maximises the score.\nclustering: Hierarchical clustering object.\ndist: Distance matrix used for clustering.\n\nReturns\n\nInteger: Selected optimal number of clusters.\n\nRelated\n\nOptimalNumberClusters\nvalid_k_clusters\nvalidate_k_value\n\n\n\n\n\n","category":"function"}]
}
